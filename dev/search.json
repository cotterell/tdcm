[{"path":[]},{"path":"/dev/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"/dev/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"/dev/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"/dev/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"/dev/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement mepcott@uga.edu. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"/dev/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"/dev/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"/dev/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"/dev/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"/dev/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"/dev/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired [Mozilla’s code conduct enforcement ladder][https://github.com/mozilla/inclusion]. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"/dev/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to tdcm","title":"Contributing to tdcm","text":"document outlines propose change tdcm.","code":""},{"path":"/dev/CONTRIBUTING.html","id":"bug-reports-and-feature-requests","dir":"","previous_headings":"","what":"Bug Reports and Feature Requests","title":"Contributing to tdcm","text":"encountered problem tdcm package idea new feature, please submit using project’s issue tracker.","code":""},{"path":"/dev/CONTRIBUTING.html","id":"pull-requests","dir":"","previous_headings":"","what":"Pull Requests","title":"Contributing to tdcm","text":"recommend create Git branch pull request (PR). Look Github Actions build status making changes. README contain badges continuous integration services used package. New code follow consistent style. can use styler package apply default style, please don’t restyle code nothing PR. use roxygen2, Markdown syntax, documentation. use testthat. Contributions test cases included easier accept. user-facing changes, add bullet top NEWS.md current development version header describing changes made followed GitHub username, links relevant issue(s)/PR(s).","code":""},{"path":"/dev/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"Contributing to tdcm","text":"Small typos grammatical errors documentation may edited directly using GitHub web interface, long changes made source file. YES: edit roxygen comment .R file R/. : edit .Rd file man/.","code":""},{"path":"/dev/CONTRIBUTING.html","id":"prerequisites","dir":"","previous_headings":"","what":"Prerequisites","title":"Contributing to tdcm","text":"make substantial pull request, always file issue make sure someone team agrees problem. found bug, create associated issue illustrate bug minimal reprex.","code":""},{"path":"/dev/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to tdcm","text":"Please note pkgdown project released Contributor Code Conduct. contributing project agree abide terms.","code":""},{"path":"/dev/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 TDCM authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/dev/articles/TDCM.html","id":"overview-of-the-tdcm-package","dir":"Articles","previous_headings":"","what":"Overview of the TDCM Package","title":"Introduction to the TDCM Package","text":"TDCM R package implements estimation longitudinal diagnostic classification models (DCMs) using transition diagnostic classification model (TDCM) framework described Madison & Bradshaw (2018). TDCM longitudinal extension log-linear cognitive diagnosis model (LCDM) developed Henson, Templin & Willse (2009). LCDM general DCM, many DCMs can embedded within TDCM. TDCM package includes functions estimate single group (TDCM::tdcm()) multigroup (TDCM::mg.tdcm()) TDCM summarize results interest, including: item parameter estimates, growth proportions, transition probabilities, transition reliability, attribute correlations, model fit, growth plots. Internally, TDCM package uses CDM::gdina() CDM package developed Robitzsch et al. (2022) estimate TDCMs using method described Madison et al. (2024). vignette provides overview package’s core functionality walking two examples. code can copied R console run. detailed video demonstrations package functionality, visit Matthew J. Madison’s Logitudinal DCMs page.","code":""},{"path":"/dev/articles/TDCM.html","id":"core-functionalities","dir":"Articles","previous_headings":"","what":"Core Functionalities","title":"Introduction to the TDCM Package","text":"estimate single group multigroup TDCM, use TDCM::tdcm() TDCM::mg.tdcm() functions, respectively. extract item, person, growth parameters TDCM estimates, use TDCM::tdcm.summary() TDCM::mg.tdcm.summary() functions single group multigroup analyses, respectively. summary functions produce list results include: item parameter estimates, growth proportions effect sizes, transition probability matrices, transition reliability, attribute correlations, model fit. compare models assess relative fit, use TDCM::tdcm.compare() function. plot results TDCM analysis, use TDCM::tdcm.plot() function. score responses using fixed item parameters previously calibrated model, use TDCM::tdcm.score() function.","code":""},{"path":"/dev/articles/TDCM.html","id":"extended-functionalities","dir":"Articles","previous_headings":"","what":"Extended Functionalities","title":"Introduction to the TDCM Package","text":"Different DCMs (e.g., LCDM, DINA, CRUM, GDINA) can modeled using TDCM::tdcm() function supplying argument rule linkfct parameters. DCM rule specification, package currently accepts “LCDM” (default), “DINA”, “DINO”, “CRUM”, “RRUM”, “LCDM2” LCDM two-way interactions, “LCDM3” LCDM three-way interactions, . Different link functions can specified linkfct parameter, including “logit” (default), “identity” obtain GDINA model, “log”. Using multiple Q-matrices time supported TDCM::tdcm() function. enable functionality, argument \\(>=\\) 2 must supplies num.q.matrix parameter, appropriately stacked Q-matrix must supplied q.matrix parameter. Anchor (common) items time points can specified anchor parameter. reduced transition space can implemented forget.att argument, attribute proficiency loss, forgetting, can constrained individual attributes. two time points, transitions can defined differently (e.g., first--last, first--, successive) transition.option parameter. Responses can scored using fixed item parameters previously calibrated model using TDCM::tdcm.score() function.","code":""},{"path":"/dev/articles/TDCM.html","id":"example-1-single-group-tdcm","dir":"Articles","previous_headings":"","what":"Example 1: Single Group TDCM","title":"Introduction to the TDCM Package","text":"Suppose sample 1000 fourth grade students. assessed unit covering 4 measurement data (MD) standards (attributes): students took 20-item assessment, five weeks apart. goal examine students transition proficiency four assessed attributes.","code":"standards <- paste0(\"4.MD.\", 1:4) standards [1] \"4.MD.1\" \"4.MD.2\" \"4.MD.3\" \"4.MD.4\""},{"path":"/dev/articles/TDCM.html","id":"step-1-load-the-package-and-sample-dataset","dir":"Articles","previous_headings":"Example 1: Single Group TDCM","what":"Step 1: Load the Package and Sample Dataset","title":"Introduction to the TDCM Package","text":"","code":"# Load the TDCM package and sample dataset library(TDCM) data(data.tdcm01, package = \"TDCM\")  # Get item responses from sample data. data <- data.tdcm01$data head(data) t1tem1 t1tem2 t1tem3 t1tem4 t1tem5 t1tem6 t1tem7 t1tem8 t1tem9 t1tem10 1      0      0      1      0      0      0      1      0      0       1 2      0      1      1      0      1      0      0      0      0       1 3      0      0      0      1      1      1      0      1      0       1 4      1      0      0      0      0      0      0      0      0       0 5      1      0      0      0      0      0      0      0      0       0 6      0      0      0      0      0      0      1      0      1       0   t1tem11 t1tem12 t1tem13 t1tem14 t1tem15 t1tem16 t1tem17 t1tem18 t1tem19 1       0       0       0       1       0       1       0       1       0 2       1       1       1       1       1       1       0       1       0 3       1       0       0       1       0       0       1       1       0 4       0       0       0       0       0       0       0       0       0 5       0       1       0       1       0       1       0       1       0 6       1       0       0       0       0       0       0       0       0   t1tem20 t2item1 t2item2 t2item3 t2item4 t2item5 t2item6 t2item7 t2item8 1       1       0       1       1       1       1       0       0       0 2       0       0       0       0       0       0       0       0       0 3       1       0       0       1       0       1       0       1       1 4       0       0       0       0       0       0       1       0       1 5       0       0       1       0       0       1       1       1       1 6       1       0       0       0       0       0       0       0       0   t2item9 t2item10 t2item11 t2item12 t2item13 t2item14 t2item15 t2item16 1       0        0        0        1        0        1        1        0 2       0        1        0        0        0        1        0        1 3       1        1        1        1        1        0        1        0 4       1        0        1        1        1        1        1        1 5       1        1        1        0        1        1        0        1 6       1        0        1        1        1        1        1        1   t2item17 t2item18 t2item19 t2item20 1        1        0        1        0 2        1        0        1        0 3        0        0        0        0 4        1        1        1        1 5        1        1        0        1 6        1        1        0        0 # Get Q-matrix from sample data and rename the attributes to match the standard. q.matrix <- data.tdcm01$q.matrix colnames(q.matrix) <- standards q.matrix 4.MD.1 4.MD.2 4.MD.3 4.MD.4 Item1       1      0      0      0 Item2       1      0      0      0 Item3       1      0      0      0 Item4       1      1      0      0 Item5       1      0      1      0 Item6       0      1      0      0 Item7       0      1      0      0 Item8       0      1      0      0 Item9       0      1      1      0 Item10      0      1      0      1 Item11      0      0      1      0 Item12      0      0      1      0 Item13      0      0      1      0 Item14      0      0      1      1 Item15      1      0      1      0 Item16      0      0      0      1 Item17      0      0      0      1 Item18      0      0      0      1 Item19      1      0      0      1 Item20      0      1      0      1"},{"path":"/dev/articles/TDCM.html","id":"step-2-estimate-the-tdcm","dir":"Articles","previous_headings":"Example 1: Single Group TDCM","what":"Step 2: Estimate the TDCM","title":"Introduction to the TDCM Package","text":"estimate TDCM, let’s make decisions. Q-matrix complex items measuring 2 attributes, initially estimate full LCDM two-way interactions (default). Since students took assessment, can assume measurement invariance test assumption later.","code":"# Calibrate TDCM with measurement invariance assumed, full LCDM model1 <- tdcm(data, q.matrix, num.time.points = 2) [1] Preparing data for tdcm()... [1] Estimating the multigroup TDCM in mg.tdcm()... [1] Depending on model complexity, estimation time may vary... [1] TDCM estimation complete. [1] Use tdcm.summary() to display results."},{"path":"/dev/articles/TDCM.html","id":"step-3-summarize-the-results","dir":"Articles","previous_headings":"Example 1: Single Group TDCM","what":"Step 3: Summarize the Results","title":"Introduction to the TDCM Package","text":"summarize results, use TDCM::tdcm.summary()function. running summary function, can examine item parameters, growth attribute proficiency, transition probability matrices, individual transitions, transitional reliability estimates. demonstrate interpretation, let’s discuss results. Item 1 measuring 4.MD.1 intercept estimate -1.905 main effect estimate -2.072. respect growth, see students exhibited amount growth 4.MD.1, 4.MD.2, 4.MD.3 (18.03% growth proficiency), showed larger gains 4.MD.4 (45.1%). Examining 4.MD.1 transition probability matrix, see students started non-proficiency, 32% transitioned proficiency. Examining individual transition posterior probabilities, see Examinee 1 mostly likely transition 0 → 1 (0.999 probability). Finally, transition reliability appears adequate, average maximum transition posteriors ranging .88 .92 four attributes.","code":"# Summarize the results results1 <- tdcm.summary(model1, attribute.names = standards) [1] Summarizing results... [1] Routine finished. Check results. item.parameters <- results1$item.parameters item.parameters λ0     λ1,1  λ1,2  λ1,3  λ1,4  λ2,12 λ2,13 λ2,14 λ2,23 λ2,24  λ2,34 Item 1  -1.905 2.599   --    --    --    --    --    --    --    --     --  Item 2  -2.072 2.536   --    --    --    --    --    --    --    --     --  Item 3  -1.934 2.517   --    --    --    --    --    --    --    --     --  Item 4  -1.892 1.091 1.499   --    --  1.057   --    --    --    --     --  Item 5  -2.17  1.456   --  1.794   --    --  1.018   --    --    --     --  Item 6  -1.843   --  2.199   --    --    --    --    --    --    --     --  Item 7  -1.825   --  2.259   --    --    --    --    --    --    --     --  Item 8  -1.967   --  2.497   --    --    --    --    --    --    --     --  Item 9  -2.009   --  1.079 1.511   --    --    --    --  1.818   --     --  Item 10 -2       --  1.849   --  1.324   --    --    --    --  1.065    --  Item 11 -1.845   --    --  2.329   --    --    --    --    --    --     --  Item 12 -2.033   --    --  2.539   --    --    --    --    --    --     --  Item 13 -2.071   --    --  2.55    --    --    --    --    --    --     --  Item 14 -2.093   --    --  1.739 2.031   --    --    --    --    --   0.496 Item 15 -1.785 0.307   --  1.295   --    --  2.374   --    --    --     --  Item 16 -2.218   --    --    --  2.837   --    --    --    --    --     --  Item 17 -2.084   --    --    --  2.69    --    --    --    --    --     --  Item 18 -2.101   --    --    --  2.521   --    --    --    --    --     --  Item 19 -2.1   2.653   --    --  1.432   --    --  0.098   --    --     --  Item 20 -2.061   --  2.545   --  1.53    --    --    --    --  -0.005   -- growth <- results1$growth growth T1[1] T2[1] 4.MD.1 0.190 0.370 4.MD.2 0.317 0.491 4.MD.3 0.392 0.579 4.MD.4 0.242 0.693 transition.probabilities <- results1$transition.probabilities transition.probabilities , , 4.MD.1: Time 1 to Time 2         T2 [0] T2 [1] T1 [0]  0.680  0.320 T1 [1]  0.417  0.583  , , 4.MD.2: Time 1 to Time 2         T2 [0] T2 [1] T1 [0]  0.581  0.419 T1 [1]  0.353  0.647  , , 4.MD.3: Time 1 to Time 2         T2 [0] T2 [1] T1 [0]  0.549  0.451 T1 [1]  0.221  0.779  , , 4.MD.4: Time 1 to Time 2         T2 [0] T2 [1] T1 [0]  0.371  0.629 T1 [1]  0.104  0.896 transition.posteriors <- results1$transition.posteriors head(transition.posteriors) , , 4.MD.1: T1 to T2       00    01    10    11 1 0.000 0.999 0.000 0.000 2 0.092 0.000 0.908 0.000 3 0.988 0.007 0.005 0.001 4 0.943 0.038 0.019 0.000 5 0.975 0.014 0.011 0.000 6 0.995 0.004 0.000 0.000  , , 4.MD.2: T1 to T2       00    01    10    11 1 0.068 0.000 0.928 0.004 2 0.988 0.007 0.005 0.000 3 0.000 0.001 0.001 0.998 4 0.100 0.899 0.000 0.002 5 0.000 0.999 0.000 0.001 6 0.454 0.003 0.540 0.003  , , 4.MD.3: T1 to T2       00    01    10    11 1 0.002 0.985 0.000 0.013 2 0.000 0.000 0.995 0.005 3 0.000 0.971 0.000 0.029 4 0.001 0.993 0.000 0.007 5 0.000 0.868 0.001 0.131 6 0.001 0.556 0.001 0.443  , , 4.MD.4: T1 to T2       00    01    10    11 1 0.000 0.015 0.063 0.922 2 0.000 0.049 0.001 0.950 3 0.001 0.000 0.967 0.031 4 0.001 0.996 0.000 0.004 5 0.000 0.157 0.000 0.843 6 0.003 0.997 0.000 0.000 results1$reliability pt bis info gain polychor ave max tr P(t>.6) P(t>.7) P(t>.8) P(t>.9) 4.MD.1  0.821     0.516    0.936      0.931   0.966   0.927   0.861   0.790 4.MD.2  0.792     0.552    0.916      0.908   0.939   0.893   0.839   0.731 4.MD.3  0.770     0.540    0.922      0.895   0.943   0.870   0.796   0.674 4.MD.4  0.771     0.494    0.914      0.913   0.952   0.894   0.829   0.748        wt pt bis wt info gain 4.MD.1     0.834        0.601 4.MD.2     0.809        0.591 4.MD.3     0.786        0.584 4.MD.4     0.798        0.602"},{"path":"/dev/articles/TDCM.html","id":"step-4-assess-measurement-invariance","dir":"Articles","previous_headings":"Example 1: Single Group TDCM","what":"Step 4: Assess Measurement Invariance","title":"Introduction to the TDCM Package","text":"assess measurement invariance, let’s estimate model without invariance assumed, compare first model. see AIC, BIC, likelihood ratio test prefer model invariance assumed. Therefore, item parameter invariance reasonable assumption can interpret results.","code":"# Estimate TDCM with measurement invariance not assumed. model2 <- tdcm(data, q.matrix, num.time.points = 2, invariance = FALSE) [1] Preparing data for tdcm()... [1] Estimating the multigroup TDCM in mg.tdcm()... [1] Depending on model complexity, estimation time may vary... [1] TDCM estimation complete. [1] Use tdcm.summary() to display results. # Compare Model 1 (longitudinal invariance assumed) to Model 2 (invariance not assumed). tdcm.compare(model1, model2) Model   loglike Deviance Npars      AIC      BIC Chisq df      p 1 model1 -21369.72 42739.44   311 43361.44 44887.75 64.68 56 0.1995 2 model2 -21337.38 42674.75   367 43408.75  45209.9    NA NA     NA"},{"path":"/dev/articles/TDCM.html","id":"step-5-estimate-other-dcms","dir":"Articles","previous_headings":"Example 1: Single Group TDCM","what":"Step 5: Estimate other DCMs","title":"Introduction to the TDCM Package","text":"estimate DCMs, change rule argument. specify one DCM across items, include one specification. specify different DCM item, use vector length equal number items. , specify DINA measurement model main effects model (ACDM). , see full LCDM fits better DINA model main effects model.","code":"# calibrate TDCM with measurement invariance assumed, DINA measurement model model3 <- tdcm(data, q.matrix, num.time.points = 2, rule = \"DINA\") [1] Preparing data for tdcm()... [1] Estimating the multigroup TDCM in mg.tdcm()... [1] Depending on model complexity, estimation time may vary... [1] TDCM estimation complete. [1] Use tdcm.summary() to display results. #calibrate TDCM with measurement invariance assumed, ACDM measurement model model4 <- tdcm(data, q.matrix, num.time.points = 2, rule = \"CRUM\") [1] Preparing data for tdcm()... [1] Estimating the multigroup TDCM in mg.tdcm()... [1] Depending on model complexity, estimation time may vary... [1] TDCM estimation complete. [1] Use tdcm.summary() to display results. #compare Model 1 (full LCDM) to Model 3 (DINA) tdcm.compare(model1, model3) Model   loglike Deviance Npars      AIC      BIC  Chisq df  p 1 model1 -21369.72 42739.44   311 43361.44 44887.75 502.22 16  0 2 model3 -21620.83 43241.67   295 43831.67 45279.46     NA NA NA #compare Model 1 (full LCDM) to Model 4 (CRUM) tdcm.compare(model1, model4) Model   loglike Deviance Npars      AIC      BIC Chisq df  p 1 model1 -21369.72 42739.44   311 43361.44 44887.75  60.3  8  0 2 model4 -21399.87 42799.74   303 43405.74 44892.79    NA NA NA"},{"path":"/dev/articles/TDCM.html","id":"step-6-assess-absolute-fit","dir":"Articles","previous_headings":"Example 1: Single Group TDCM","what":"Step 6: Assess Absolute Fit","title":"Introduction to the TDCM Package","text":"assess absolute fit, extract model fit statistics results summary.","code":"results1$model.fit$Global.Fit.Stats est MADcor          0.02257097 SRMSR           0.02834149 100*MADRESIDCOV 0.49363470 MADQ3           0.03199369 MADaQ3          0.03081550 results1$model.fit$Global.Fit.Tests type       value         p 1   max(X2) 10.06542439 1.0000000 2 abs(fcor)  0.09731844 0.8268709 results1$model.fit$Global.Fit.Stats2 maxX2 p_maxX2     MADcor      SRMSR 100*MADRESIDCOV      MADQ3    MADaQ3 1 10.06542       1 0.02257097 0.02834149       0.4936347 0.03199369 0.0308155 results1$model.fit$Item.RMSEA Item 1     Item 2     Item 3     Item 4     Item 5     Item 6     Item 7  0.09391612 0.12079524 0.10670311 0.10952611 0.11962801 0.13655715 0.13845978      Item 8     Item 9    Item 10    Item 11    Item 12    Item 13    Item 14  0.10811876 0.11353405 0.11115225 0.12981641 0.11323978 0.10265758 0.11435661     Item 15    Item 16    Item 17    Item 18    Item 19    Item 20    Item 21  0.12122112 0.12147005 0.10578848 0.11120378 0.09767873 0.13304620 0.10788168     Item 22    Item 23    Item 24    Item 25    Item 26    Item 27    Item 28  0.10949474 0.11713454 0.12149082 0.11334556 0.12767058 0.12317678 0.10590232     Item 29    Item 30    Item 31    Item 32    Item 33    Item 34    Item 35  0.11158355 0.11326936 0.11504822 0.11948474 0.11920146 0.09564141 0.12998822     Item 36    Item 37    Item 38    Item 39    Item 40  0.11363849 0.12522381 0.11581421 0.10939110 0.11244670 results1$model.fit$Mean.Item.RMSEA [1] 0.1153924"},{"path":"/dev/articles/TDCM.html","id":"step-7-visualize","dir":"Articles","previous_headings":"Example 1: Single Group TDCM","what":"Step 7: Visualize","title":"Introduction to the TDCM Package","text":"visual presentation results, run tdcm.plot() function:","code":"# plot results (check plot viewer for line plot and bar chart) tdcm.plot(results1, attribute.names = standards)"},{"path":"/dev/articles/TDCM.html","id":"example-2-multigroup-tdcm","dir":"Articles","previous_headings":"","what":"Example 2: Multigroup TDCM","title":"Introduction to the TDCM Package","text":"Suppose now sample 1700 fourth grade students. example, researchers wanted evaluate effects instructional intervention. randomly assigned students either control group (Group 1, N1 = 800) treatment group (Group 2, N2 = 900). goal see innovative instructional method resulted students transitioning proficiency. Similar Example #1, students assessed unit covering four measurement data (MD) standards (attributes; 4.MD.1 - 4.MD.4). students took 20-item assessment five weeks apart. Step 1: Load package Dataset #4 included package: Step 2: estimate multigroup TDCM, use mg.tdcm() function. initial model, assume time invariance group invariance. next step, test assumptions. Step 3: assess measurement invariance, let’s estimate three additional models: - model assuming time invariance (TRUE) assuming group invariance (FALSE) - model assuming time invariance (FALSE) assuming group invariance (TRUE) - model assuming either; time invariance (FALSE) group invariance (FALSE) model comparisons prefer model group time invariance. Therefore, can proceed interpreting Model 1. Step 4: summarize results, use mg.tdcm.summary() function. running summary function, can examine item parameters, growth attribute proficiency group, transition probability matrices group, individual transitions, transitional reliability estimates. demonstrate interpretation, let’s discuss results. Item 1 measuring 4.MD.1 intercept estimate -1.89 main effect estimate 2.39. respect growth, first see randomization appeared work, groups similar proficiency proportions first assessment. see 4.MD.4 attribute, treatment group showed increased growth attribute proficiency. Step 5: visual presentation results, run tdcm.plot() function:","code":"#load the TDCM library library(TDCM)  #read data, Q-matrix, and group labels dat4 <- data.tdcm04$data qmat4 <- data.tdcm04$q.matrix groups <- data.tdcm04$groups head(dat4) t1item1 t1item2 t1item3 t1item4 t1item5 t1item6 t1item7 t1item8 t1item9 1       0       0       0       0       0       0       0       0       0 2       0       0       0       0       0       0       0       0       0 3       0       1       0       0       0       0       0       1       0 4       0       0       0       1       0       0       0       0       0 5       1       0       0       1       1       0       1       1       1 6       1       1       1       0       1       0       1       1       0   t1item10 t1item11 t1item12 t1item13 t1item14 t1item15 t1item16 t1item17 1        0        0        0        0        0        0        0        0 2        1        0        0        0        0        0        0        0 3        0        0        0        1        0        0        0        0 4        0        1        0        0        0        0        1        1 5        0        0        0        0        0        0        0        0 6        1        0        1        1        1        1        1        0   t1item18 t1item19 t1item20 t2item1 t2item2 t2item3 t2item4 t2item5 t2item6 1        0        0        0       0       0       1       1       0       0 2        0        0        0       0       1       1       0       0       1 3        0        0        0       0       0       1       0       0       0 4        0        0        0       0       1       1       1       1       0 5        1        0        0       0       0       1       1       0       0 6        1        1        1       0       0       0       0       0       1   t2item7 t2item8 t2item9 t2item10 t2item11 t2item12 t2item13 t2item14 t2item15 1       0       0       0        0        1        1        0        1        1 2       0       0       0        0        0        0        0        0        0 3       0       0       0        0        1        1        1        0        0 4       1       1       0        1        0        1        0        1        1 5       1       0       0        1        0        0        0        1        0 6       1       1       1        1        1        0        1        1        0   t2item16 t2item17 t2item18 t2item19 t2item20 1        0        1        1        0        0 2        0        0        0        0        0 3        0        0        0        0        0 4        0        1        1        1        1 5        1        1        1        0        1 6        0        0        0        0        1 #calibrate mgTDCM with time and group invariance assumed, full LCDM mg1 <- mg.tdcm(data = dat4, q.matrix = qmat4, num.time.points = 2, rule = \"LCDM\", groups = groups, group.invariance = TRUE, time.invariance = TRUE) [1] Preparing data for mg.tdcm()... [1] Estimating the multigroup TDCM in mg.tdcm()... [1] Depending on model complexity, estimation time may vary... [1] Multigroup TDCM estimation complete. [1] Use mg.tdcm.summary() to display results. #calibrate mgTDCM with item invariance assumed, full LCDM mg2 <- mg.tdcm(data = dat4, q.matrix = qmat4, num.time.points = 2, groups = groups, group.invariance = FALSE, time.invariance = TRUE) [1] Preparing data for mg.tdcm()... [1] Estimating the multigroup TDCM in mg.tdcm()... [1] Depending on model complexity, estimation time may vary... [1] Multigroup TDCM estimation complete. [1] Use mg.tdcm.summary() to display results. #calibrate mgTDCM with group invariance assumed, full LCDM mg3 <- mg.tdcm(data = dat4, q.matrix = qmat4, num.time.points = 2, groups = groups, group.invariance = TRUE, time.invariance = FALSE) [1] Preparing data for mg.tdcm()... [1] Estimating the multigroup TDCM in mg.tdcm()... [1] Depending on model complexity, estimation time may vary... [1] Multigroup TDCM estimation complete. [1] Use mg.tdcm.summary() to display results. #calibrate mgTDCM with no invariance assumed, full LCDM mg4 <- mg.tdcm(data = dat4, q.matrix = qmat4, num.time.points = 2, groups = groups, group.invariance = FALSE, time.invariance = FALSE) [1] Preparing data for mg.tdcm()... [1] Estimating the multigroup TDCM in mg.tdcm()... [1] Depending on model complexity, estimation time may vary... [1] Multigroup TDCM estimation complete. [1] Use mg.tdcm.summary() to display results. #compare Model 1 (group/time invariance) to Model 2 (no group invariance) tdcm.compare(mg1, mg2) Model   loglike Deviance Npars      AIC      BIC Chisq df      p 1   mg1 -37248.15  74496.3   566  75628.3 78706.43 37.08 56 0.9759 2   mg2 -37229.61 74459.22   622 75703.22  79085.9    NA NA     NA #compare Model 1 (group/time invariance) to Model 3 (no time invariance) tdcm.compare(mg1, mg3) Model   loglike Deviance Npars      AIC      BIC Chisq df      p 1   mg1 -37248.15  74496.3   566  75628.3 78706.43 72.96 56 0.0635 2   mg3 -37211.67 74423.33   622 75667.33 79050.01    NA NA     NA #compare Model 1 (group/time invariance) to Model 4 (no invariance) tdcm.compare(mg1, mg4) Model   loglike Deviance Npars      AIC      BIC Chisq  df      p 1   mg1 -37248.15  74496.3   566  75628.3 78706.43 190.3 168 0.1146 2   mg4    -37153 74306.01   734 75774.01 79765.78    NA  NA     NA #summarize results resultsmg1 <- mg.tdcm.summary(mg1, attribute.names = c(\"4.MD.1\", \"4.MD.2\", \"4.MD.3\", \"4.MD.4\"), group.names = c(\"Control\", \"Treatment\")) [1] Summarizing results... [1] Routine finished. Check results. resultsmg1$item.parameters λ0     λ1,1  λ1,2  λ1,3  λ1,4  λ2,12 λ2,13 λ2,14 λ2,23 λ2,24 λ2,34 Item 1  -1.888 2.393   --    --    --    --    --    --    --    --    --  Item 2  -2.06  2.572   --    --    --    --    --    --    --    --    --  Item 3  -2.185 2.633   --    --    --    --    --    --    --    --    --  Item 4  -2.126 1.778 1.575   --    --  0.688   --    --    --    --    --  Item 5  -2.072 1.431   --  1.353   --    --  1.328   --    --    --    --  Item 6  -1.918   --  2.432   --    --    --    --    --    --    --    --  Item 7  -1.888   --  2.451   --    --    --    --    --    --    --    --  Item 8  -2.001   --  2.443   --    --    --    --    --    --    --    --  Item 9  -2.096   --  1.76  1.694   --    --    --    --  0.699   --    --  Item 10 -2.093   --  1.38    --  1.614   --    --    --    --  1.04    --  Item 11 -1.973   --    --  2.485   --    --    --    --    --    --    --  Item 12 -2.191   --    --  2.697   --    --    --    --    --    --    --  Item 13 -1.893   --    --  2.375   --    --    --    --    --    --    --  Item 14 -1.941   --    --  1.437 1.236   --    --    --    --    --  1.06  Item 15 -2.172 1.743   --  1.784   --    --  0.683   --    --    --    --  Item 16 -2.153   --    --    --  2.613   --    --    --    --    --    --  Item 17 -2.366   --    --    --  3.007   --    --    --    --    --    --  Item 18 -2.046   --    --    --  2.47    --    --    --    --    --    --  Item 19 -2.036 1.537   --    --  1.367   --    --  0.922   --    --    --  Item 20 -2.225   --  1.721   --  1.774   --    --    --    --  0.694   -- resultsmg1$growth , , Control         T1[1] T2[1] 4.MD.1 0.307 0.438 4.MD.2 0.402 0.500 4.MD.3 0.224 0.619 4.MD.4 0.424 0.737  , , Treatment         T1[1] T2[1] 4.MD.1 0.301 0.626 4.MD.2 0.382 0.737 4.MD.3 0.204 0.698 4.MD.4 0.448 0.712 resultsmg1$growth.effects , , Control         T1[1] T2[1] Growth Odds Ratio Cohen`s h 4.MD.1 0.307 0.438  0.131       1.76      0.27 4.MD.2 0.402 0.500  0.098       1.49      0.20 4.MD.3 0.224 0.619  0.395       5.63      0.83 4.MD.4 0.424 0.737  0.313       3.81      0.65  , , Treatment         T1[1] T2[1] Growth Odds Ratio Cohen`s h 4.MD.1 0.301 0.626  0.325       3.89      0.66 4.MD.2 0.382 0.737  0.355       4.53      0.73 4.MD.3 0.204 0.698  0.494       9.02      1.04 4.MD.4 0.448 0.712  0.264       3.05      0.54 resultsmg1$transition.probabilities , , 4.MD.1: Time 1 to Time 2, Control         T2 [0] T2 [1] T1 [0]  0.634  0.366 T1 [1]  0.399  0.601  , , 4.MD.2: Time 1 to Time 2, Control         T2 [0] T2 [1] T1 [0]  0.571  0.429 T1 [1]  0.393  0.607  , , 4.MD.3: Time 1 to Time 2, Control         T2 [0] T2 [1] T1 [0]  0.438  0.562 T1 [1]  0.185  0.815  , , 4.MD.4: Time 1 to Time 2, Control         T2 [0] T2 [1] T1 [0]  0.334  0.666 T1 [1]  0.166  0.834  , , 4.MD.1: Time 1 to Time 2, Treatment         T2 [0] T2 [1] T1 [0]  0.435  0.565 T1 [1]  0.231  0.769  , , 4.MD.2: Time 1 to Time 2, Treatment         T2 [0] T2 [1] T1 [0]  0.362  0.638 T1 [1]  0.104  0.896  , , 4.MD.3: Time 1 to Time 2, Treatment         T2 [0] T2 [1] T1 [0]  0.361  0.639 T1 [1]  0.073  0.927  , , 4.MD.4: Time 1 to Time 2, Treatment         T2 [0] T2 [1] T1 [0]  0.353  0.647 T1 [1]  0.208  0.792 head(resultsmg1$transition.posteriors) , , 4.MD.1: T1 to T2       00    01    10    11 1 0.657 0.343 0.000 0.000 2 0.991 0.009 0.000 0.000 3 0.965 0.006 0.029 0.000 4 0.001 0.979 0.000 0.020 5 0.204 0.135 0.659 0.002 6 0.001 0.000 0.999 0.001  , , 4.MD.2: T1 to T2       00    01    10    11 1 0.991 0.009 0.000 0.000 2 0.981 0.005 0.013 0.000 3 0.983 0.004 0.013 0.000 4 0.002 0.983 0.000 0.015 5 0.007 0.015 0.215 0.763 6 0.000 0.002 0.000 0.998  , , 4.MD.3: T1 to T2       00    01    10    11 1 0.039 0.961 0.000 0.000 2 0.999 0.001 0.000 0.000 3 0.152 0.848 0.000 0.000 4 0.027 0.967 0.000 0.006 5 0.974 0.024 0.001 0.002 6 0.000 0.001 0.010 0.989  , , 4.MD.4: T1 to T2       00    01    10    11 1 0.091 0.907 0.001 0.001 2 0.982 0.005 0.013 0.000 3 0.996 0.004 0.000 0.000 4 0.000 0.349 0.000 0.650 5 0.000 0.994 0.000 0.006 6 0.000 0.000 0.106 0.894 resultsmg1$reliability pt bis info gain polychor ave max tr P(t>.6) P(t>.7) P(t>.8) P(t>.9) 4.MD.1  0.809     0.552    0.914      0.906   0.935   0.891   0.834   0.717 4.MD.2  0.792     0.540    0.900      0.891   0.927   0.868   0.801   0.668 4.MD.3  0.823     0.505    0.924      0.925   0.959   0.919   0.862   0.784 4.MD.4  0.803     0.526    0.897      0.898   0.935   0.876   0.792   0.691        wt pt bis wt info gain 4.MD.1     0.826        0.574 4.MD.2     0.792        0.560 4.MD.3     0.845        0.597 4.MD.4     0.795        0.567 #plot results (check plot viewer for line plots and bar charts) tdcm.plot(resultsmg1, attribute.names = c(\"4.MD.1\", \"4.MD.2\", \"4.MD.3\", \"4.MD.4\"),            group.names = c(\"Control\", \"Treatment\")) [1] **Check the plots window for line and bar plots for group growth proportions."},{"path":"/dev/articles/TDCM.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Introduction to the TDCM Package","text":"Madison, M.J., Chung, S., Kim, J., Bradshaw, L.P. (2024). Approaches estimating longitudinal diagnostic classification models. Behaviormetrika 51, 7–19. doi:10.1007/s41237-023-00202-5 George, . C., Robitzsch, ., Kiefer, T., Gross, J., & Uenlue, . (2016). R Package CDM cognitive diagnosis models. Journal Statistical Software, 74(2), 1-24. doi:10.18637/jss.v074.i02 Robitzsch, ., Kiefer, T., George, . C., & Uenlue, . (2022). CDM: Cognitive Diagnosis Modeling. R package version 8.2-6. https://CRAN.R-project.org/package=CDM","code":""},{"path":"/dev/articles/developer.html","id":"types-of-contributions","dir":"Articles","previous_headings":"","what":"Types of Contributions","title":"Developer Guide","text":"like help contribute TDCM? happy work community improve user experience! ways team can contribute listed . can click contribution type learn . Issue Reporting: Report bugs issues come across can try fix Feature Requests: Let us know features like see added package. Code Contributions: Help us work package fixing bugs adding features !","code":""},{"path":"/dev/articles/developer.html","id":"issue-reporting","dir":"Articles","previous_headings":"Types of Contributions","what":"Issue Reporting","title":"Developer Guide","text":"notice errors, bugs, unexpected behaviors TDCM package, please use Issues feature GitHub. allow us respond promptly keep required fixes one place. , log GitHub account (create one already one), follow instructions : Navigate issues page GitHub. Use search area see issue encountered something similar already reported. existing issue report applies specific issue, open report read comment history. unable find solution comments, leave new comment let us know encountered issue something similar along enough details developer reproduce version issue. One first things development team attempt reproduce issue, additional details important including often leads quicker fixes. issue reported yet, submit new issue report: Click green “New Issue” button. Click “Get Started” next “Bug Report” Click “Submit New Issue” finished filling form. Whether commented existing issue report submitted new one, can track progress issue report visiting page GitHub. developers need reach information, mentioning name new comment add report. happens, GitHub notify . Replying developer help developers resolve issue quickly!","code":""},{"path":"/dev/articles/developer.html","id":"feature-request","dir":"Articles","previous_headings":"Types of Contributions","what":"Feature Request","title":"Developer Guide","text":"features like us add? Please let us know using Issues feature GitHub! Issues feature GitHub streamlines communication users developers consolidates project tasks one place. course includes bugs, often used managing feature requests improvements, allowing serve “-List” developers can use know focusing . create Issue report, log GitHub account (create one already one) follow instructions : Navigate issues page GitHub. Use search box see feature ’re thinking already requested. already request, please interact ! can use emoji icon add reaction, “thumbs ” show support! let us know features prioritize showing many people want particular feature.  Additionally, feel free voice opinions replies request page! can add additional details ’d like see implemented, simply express desire feature added! existing request feature, can make : Click green “New Issue” button Click “Get Started” next “Feature Request” Click “Submit New Issue” ’ve finished filling form! posted feature request, developers may reply request asking details. Please provide much information possible developers know looking .","code":""},{"path":"/dev/articles/developer.html","id":"code-contributions","dir":"Articles","previous_headings":"Types of Contributions","what":"Code Contributions","title":"Developer Guide","text":"contribution accepted, needs follow consistent style, well documented, include unit tests. can ensure code meets standards following steps outlined . package instructions written use RStudio. install necessary packages, run following commands: TODO finish section.","code":""},{"path":"/dev/articles/developer.html","id":"git-pull-requests","dir":"Articles","previous_headings":"","what":"Git & Pull Requests","title":"Developer Guide","text":"section describes Git use help contribute repository.","code":""},{"path":"/dev/articles/developer.html","id":"what-is-git","dir":"Articles","previous_headings":"Git & Pull Requests","what":"What is Git?","title":"Developer Guide","text":"Git version control system allows developers track changes code time. ’s like time machine project files, enabling save different versions (called “commits”) code. commit records changes made, , , making easy revert back older versions something goes wrong current code. breakdown key features concepts Git: Repository (repo): project’s files history stored. can located computer (local repository) remote server (remote repository). Commit: commit like snapshot project specific point time. make changes files, ‘commit’ changes, saves record altered, allowing track evolution project. Branch: Branches allow create separate versions project within repository. might use branch develop new feature keeping main project (usually called “master” “main” branch) stable. Merge: ’ve finished working branch, can merge changes back main branch. combines histories branches, integrating new features changes main project. Pull: Pulling refers downloading changes remote repository local one. useful working teams, lets see integrate changes made others. Push: Pushing refers uploading local repository changes remote repository. share work others back current state remote location. Using Git, multiple developers can work project simultaneously without interfering others’ work, can work different branches merge changes ready. collaborative feature, along ability track every change, makes Git essential tool modern software development.","code":""},{"path":"/dev/articles/developer.html","id":"git-vs--github","dir":"Articles","previous_headings":"Git & Pull Requests","what":"Git vs. GitHub","title":"Developer Guide","text":"Git version control system (VCS) helps track changes code files. allows multiple developers work together project effectively efficiently providing tools manage differing versions code. Git used create branches, handle merges, revert previous states, , directly local machine server without needing internet connection. Git operates primarily local system, managing local repository. However, can synchronize remote repositories. GitHub hosting service Git repositories. platform can upload Git repositories collaborate others. Beyond basic functionality Git, GitHub provides additional features bug tracking, feature requests, task management, wikis project documentation. GitHub designed facilitate easier collaboration among team members project. offers graphical tools managing pull requests, code reviews, even project management tools like issues project boards. essence, Git tool enables version control, GitHub service hosts repositories adds extra features enhance collaboration among team members. work hand--hand support development process, serve different roles within framework. Reading: Chacon, S., & Straub, B. (November 2014). “Getting Started: Git?” Pro Git. Second Edition. Apress. ISBN: 978-1484200773.","code":""},{"path":"/dev/articles/developer.html","id":"what-is-a-pull-request","dir":"Articles","previous_headings":"Git & Pull Requests","what":"What is a Pull Request?","title":"Developer Guide","text":"pull request (PR), also known merge request systems like GitLab, feature used Git repositories lets developers notify team members changes ’ve pushed branch repository platforms like GitHub, Bitbucket, GitLab. Essentially, ’s request review merge branch another branch, typically main project branch. ’s works simple terms: Branch Creation: First, developer creates branch main code base work new feature, bug fix, updates. separation ensures main code base remains unaffected new changes reviewed approved. Making Changes Committing: developer makes necessary changes new branch, commits changes, pushes branch remote repository. Opening Pull Request: branch updated remote repository, developer opens pull request. PR essentially request rest team review changes made branch gets merged main branch. Review Discussion: Team members review changes, discuss potential improvements, may request changes needed. process crucial maintaining code quality ensuring integration aligns project’s overall direction. Approval Merge: changes reviewed approved necessary team members according project’s guidelines, pull request can merged. means changes branch integrated target branch, usually main master branch. Closure Cleanup: merged, pull request closed, ’s common delete branch keep repository clean manageable. Pull Requests vital part collaborative development process, enabling transparency, improving code quality, helping manage contributions project efficiently. facilitate peer review system beneficial team cohesion project integrity.","code":""},{"path":"/dev/articles/developer.html","id":"using-rstudio-to-prepare-a-pull-request","dir":"Articles","previous_headings":"Git & Pull Requests","what":"Using RStudio to Prepare a Pull Request","title":"Developer Guide","text":"RStudio built-method creating pull request. However, built-terminal can used push changes forked repository GitHub remote origin. GitHub must used create pull request. GitHub: Click “Fork” button project make changes . RStudio: Create new project use Version Control Git. Copy paste repository URL fork project. Add original repository upstream version. done RStudio’s built-terminal. Type : Create checkout branch make changes. Commit changes using “Git” tab RStudio. Ensure branch changes. Push forked repository terminal: GitHub: Click green icon top left repository page create pull request message describing changes.","code":"git remote add upstream https://github.com/cotterell/tdcm.git git push origin <branch name>"},{"path":"/dev/articles/developer.html","id":"using-visual-studio-code-to-prepare-a-pull-request","dir":"Articles","previous_headings":"Git & Pull Requests","what":"Using Visual Studio Code to Prepare a Pull Request","title":"Developer Guide","text":"TODO write.","code":""},{"path":"/dev/articles/developer.html","id":"using-a-terminal-to-prepare-a-pull-request","dir":"Articles","previous_headings":"Git & Pull Requests","what":"Using a Terminal to Prepare a Pull Request","title":"Developer Guide","text":"can use GitHub’s CLI (downloadable) fork repository create pull request within . Fork original project using gh repo fork <repository>, commit changes separate branch. changes committed, create pull request using gh pr create","code":""},{"path":"/dev/articles/developer.html","id":"continuous-integration-and-pull-requests","dir":"Articles","previous_headings":"Git & Pull Requests > Using a Terminal to Prepare a Pull Request","what":"Continuous Integration and Pull Requests","title":"Developer Guide","text":"package utilizes continuous integration via GitHub Actions. means script within project automatically run various checks pull request notify problems GitHub profile. resolved, provided require inspection, pull request reviewed development team potential inclusion package.","code":""},{"path":"/dev/articles/developer.html","id":"policies","dir":"Articles","previous_headings":"","what":"Policies","title":"Developer Guide","text":"TODO write. example, modify DESCRIPTION file unless package maintainer.","code":""},{"path":"/dev/articles/developer.html","id":"guidelines","dir":"Articles","previous_headings":"","what":"Guidelines","title":"Developer Guide","text":"TODO write.","code":""},{"path":"/dev/articles/developer.html","id":"maintainer-notes","dir":"Articles","previous_headings":"","what":"Maintainer Notes","title":"Developer Guide","text":"section includes notes intended package maintainer . time writing, package maintainer Michael E. Cotterell based package’s DESCRIPTION file.","code":""},{"path":[]},{"path":"/dev/articles/developer.html","id":"r-cmd-check","dir":"Articles","previous_headings":"Maintainer Notes > GitHub Actions","what":"R-CMD-check","title":"Developer Guide","text":"workflow runs R-CMD-check using three major operating systems (linux, macOS Windows) current, development, previous versions R.","code":""},{"path":"/dev/articles/developer.html","id":"pkgdown","dir":"Articles","previous_headings":"Maintainer Notes > GitHub Actions","what":"pkgdown","title":"Developer Guide","text":"workflow builds package website using pkgdown::build_site_github_pages(), pushes built package website GitHub Pages. inclusion workflow_dispatch means workflow can run manually triggered via GitHub REST API. Release website: https://cotterell.github.io/tdcm/ Development website: https://cotterell.github.io/tdcm/dev/","code":""},{"path":"/dev/articles/developer.html","id":"pr-commands","dir":"Articles","previous_headings":"Maintainer Notes > GitHub Actions","what":"pr-commands","title":"Developer Guide","text":"workflow adds /document /style commands pull requests.","code":""},{"path":"/dev/articles/developer.html","id":"test-coverage","dir":"Articles","previous_headings":"Maintainer Notes > GitHub Actions","what":"test-coverage","title":"Developer Guide","text":"workflow uses covr::codecov() query test coverage package upload result https://app.codecov.io/gh/cotterell/tdcm.","code":""},{"path":"/dev/articles/developer.html","id":"prepare-a-release","dir":"Articles","previous_headings":"Maintainer Notes","what":"Prepare a Release","title":"Developer Guide","text":"TODO write.","code":""},{"path":"/dev/articles/developer.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Developer Guide","text":"Chacon, S., & Straub, B. (November 2014). Pro Git. Second Edition. Apress. ISBN: 978-1484200773. https://git-scm.com/book/en/v2 Wickham, H., & Bryan, J. (July 2023). R Packages: Organize, Test, Document, Share Code. Second Edition. O’Reilly Media. ISBN: 9781098134945. https://r-pkgs.org/ Wickham, H., Hester, J., Chang. W., & Bryan, J. (2022). devtools: Tools Make Developing R Packages Easier. https://devtools.r-lib.org/, https://github.com/r-lib/devtools","code":""},{"path":"/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Matthew J. Madison. Author, copyright holder. Sergio Haab. Author. Minjeong Jeon. Author, copyright holder. Michael E. Cotterell. Author, maintainer, copyright holder. University Georgia. Copyright holder.           content opinions expressed material necessarily         reflect views endorsed University Georgia         University System Georgia. Institute Education Sciences. Funder.           work supported U.S. Department Education Institute         Education Sciences IES Award Number R305D220020. National Science Foundation. Funder.           work supported National Science Foundation NSF         Award Number 1921373.","code":""},{"path":"/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Madison M, Haab S, Jeon M, Cotterell M (2024). TDCM: Transition Diagnostic Classification Model Framework. R package version 0.2.0.9000, https://github.com/cotterell/tdcm, https://cotterell.github.io/tdcm/.","code":"@Manual{,   title = {TDCM: The Transition Diagnostic Classification Model Framework},   author = {Matthew J. Madison and Sergio Haab and Minjeong Jeon and Michael E. Cotterell},   year = {2024},   note = {R package version 0.2.0.9000, https://github.com/cotterell/tdcm},   url = {https://cotterell.github.io/tdcm/}, }"},{"path":"/dev/index.html","id":"tdcm","dir":"","previous_headings":"","what":"The Transition Diagnostic Classification Model Framework","title":"The Transition Diagnostic Classification Model Framework","text":"‘TDCM’ R package lets users estimate transition diagnostic classification model (TDCM) described Madison & Bradshaw (2018), longitudinal extension log-linear cognitive diagnosis model (LCDM) Henson, Templin & Willse (2009). LCDM subsumes many diagnostic classification models (DCMs), many DCMs can estimated longitudinally via TDCM framework. ‘TDCM’ package includes functions estimate single-group multigroup TDCM, summarize results interest including item parameters, growth proportions, transition probabilities, transitional reliability, attribute correlations, model fit, growth plots.","code":""},{"path":"/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"The Transition Diagnostic Classification Model Framework","text":"can install ‘TDCM’ package like :","code":"# Install the latest development version of TDCM from GitHub: if (!require(\"devtools\")) install.packages(\"devtools\") devtools::install_github(\"cotterell/tdcm\")"},{"path":"/dev/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting Started","title":"The Transition Diagnostic Classification Model Framework","text":"See vignette(\"TDCM\", package = \"TDCM\") overview ‘TDCM’ package.","code":""},{"path":"/dev/reference/TDCM-package.html","id":null,"dir":"Reference","previous_headings":"","what":"The Transition Diagnostic Classification Model Framework — TDCM-package","title":"The Transition Diagnostic Classification Model Framework — TDCM-package","text":"R package TDCM enables longitudinal diagnostic classification model (DCM) analyses within transition diagnostic classification model (TDCM) framework.","code":""},{"path":"/dev/reference/TDCM-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The Transition Diagnostic Classification Model Framework — TDCM-package","text":"Diagnostic classification models (DCMs) psychometric models designed classify examinees according proficiency set categorical latent traits, known attributes. Longitudinal DCMs developed psychometric options modeling changes attribute proficiency time. TDCM implements estimation transition DCM (TDCM; Madison & Bradshaw, 2018a), longitudinal extension log-linear cognitive diagnosis model (LCDM; Henson, Templin, & Willse, 2009). LCDM subsumes many DCMs, many DCMs can estimated longitudinally via TDCM. package includes functions estimate single-group multigroup TDCM, summarize results interest including item parameters, growth proportions, transition probabilities, transitional reliability, attribute correlations, model fit, growth plots. details examples, see vignette(\"TDCM\", package = \"TDCM\").","code":""},{"path":"/dev/reference/TDCM-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"The Transition Diagnostic Classification Model Framework — TDCM-package","text":"de la Torre, J. (2011). Generalized DINA Model Framework. Psychometrika 76, 179–199. doi:10.1007/s11336-011-9207-7 George, . C., Robitzsch, ., Kiefer, T., Gross, J., & Ünlü , . (2016). R package CDM Cognitive Diagnosis Models. Journal Statistical Software, 74(2), 1-24. doi:10.18637/jss.v074.i02 Henson, R., Templin, J., & Willse, J. (2009). Defining Family Cognitive Diagnosis Models Using Log-Linear Models Latent Variables. Psychometrika, 74, 191-21. doi:10.1007/s11336-008-9089-5 Johnson, M. S., & Sinharay, S. (2020). Reliability Posterior Probability Skill Attainment Diagnostic Classification Models. Journal Educational Measurement, 47(1), 5–31. doi:10.3102/1076998619864550 Kaya, Y., & Leite, W. (2017). Assessing Change Latent Skills Across Time Longitudinal Cognitive Diagnosis Modeling: Evaluation Model Performance. Educational Psychological Measurement, 77(3), 369–388. doi:10.1177/0013164416659314 Li, F., Cohen, ., Bottge, B., & Templin, J. (2015). Latent Transition Analysis Model Assessing Change Cognitive Skills. Educational Psychological Measurement, 76(2), 181–204. doi:10.1177/0013164415588946 Madison, M. J. (2019). Reliably Assessing Growth Longitudinal Diagnostic Classification Models. Educational Measurement: Issues Practice, 38(2), 68-78. doi:10.1111/emip.12243 Madison, M. J., & Bradshaw, L. (2018a). Assessing Growth Diagnostic Classification Model Framework. Psychometrika, 83(4), 963-990. doi:10.1007/s11336-018-9638-5 Madison, M. J., & Bradshaw, L. (2018b). Evaluating Intervention Effects Diagnostic Classification Model Framework. Journal Educational Measurement, 55(1), 32-51. doi:10.1111/jedm.12162 Madison, M.J., Chung, S., Kim, J., & Bradshaw, L.P. (2024) Approaches estimating longitudinal diagnostic classification models. Behaviormetrika, 51(7), 7-19. doi:10.1007/s41237-023-00202-5 Rupp, . ., Templin, J., & Henson, R. (2010). Diagnostic Measurement: Theory, Methods, Applications. New York: Guilford. ISBN: 9781606235430. Schellman, M., & Madison, M. J. (2024). Estimating reliability skill transition longitudinal DCMs. Journal Educational Behavioral Statistics. Templin, J., & Bradshaw, L. (2013). Measuring Reliability Diagnostic Classification Model Examinee Estimates. Journal Classification, 30, 251-275. doi:10.1007/s00357-013-9129-4 Wang. S., Yang. Y., Culpepper, S. ., & Douglas, J. (2018). Tracking Skill Acquisition Cognitive Diagnosis Models: Higher-Order, Hidden Markov Model Covariates. Journal Educational Behavioral Statistics, 43(1), 57-87. doi:10.3102/1076998617719727","code":""},{"path":[]},{"path":"/dev/reference/TDCM-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"The Transition Diagnostic Classification Model Framework — TDCM-package","text":"TDCM package created : Matthew J. Madison, University Georgia, mjmadison@uga.edu Sergio Haab, University Iowa, sergio-haab@uiowa.edu Minjeong Jeon, University California - Los Angeles, mjjeon@ucla.edu Michael E. Cotterell, University Georgia, mepcott@uga.edu information TDCM package authors, copyright holders, funders, etc. available package's DESCRIPTION file. can see information executing utils::packageDescription(\"TDCM\").","code":""},{"path":"/dev/reference/data.tdcm.html","id":null,"dir":"Reference","previous_headings":"","what":"Several data sets for the TDCM package. — data.tdcm","title":"Several data sets for the TDCM package. — data.tdcm","text":"Several data sets TDCM package.","code":""},{"path":"/dev/reference/data.tdcm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Several data sets for the TDCM package. — data.tdcm","text":"","code":"data.tdcm01  data.tdcm02  data.tdcm03  data.tdcm04  data.tdcm05"},{"path":"/dev/reference/data.tdcm.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Several data sets for the TDCM package. — data.tdcm","text":"data.tdcm01 simulated dataset two time points, four attributes, twenty items, one group size 1000, single Q-matrix. format list two: data: data frame binary item responses q.matrix: data frame specifying Q-matrix data.tdcm02 simulated dataset three time points, two attributes, ten items, one group size 2500, single Q-matrix. format list two: data: data frame binary item responses q.matrix: data frame specifying Q-matrix data.tdcm03 simulated dataset three time points, two attributes, one group size 1500, three different ten-item Q-matrices time point. Anchor items specified items 1/11/21 items 14/24. format list five: data: data frame binary item responses q.matrix.1: data frame specifying Q-matrix first time point q.matrix.2: data frame specifying Q-matrix second time point q.matrix.3: data frame specifying Q-matrix third time point q.matrix.stacked: data frame specifying combined Q-matrix time points data.tdcm04 simulated dataset two time points, four attributes, twenty items, two group size 800 900, respectively, single Q-matrix. format list three: data: data frame binary item responses q.matrix: data frame specifying Q-matrix groups: vector specifying examinee group membership data.tdcm05 simulated dataset one time point, four attributes, twenty items. use 1-PLCDM. format list two: data: data frame binary item responses q.matrix: data frame specifying Q-matrix","code":""},{"path":"/dev/reference/data.tdcm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Several data sets for the TDCM package. — data.tdcm","text":"","code":"# \\donttest{  ############################# ## Example 1: T = 2, A = 4 ## data(data.tdcm01, package = \"TDCM\") data <- data.tdcm01$data q.matrix <- data.tdcm01$q.matrix model <- TDCM::tdcm(data, q.matrix, num.time.points = 2) #> [1] Preparing data for tdcm()... #> [1] Estimating the multigroup TDCM in mg.tdcm()... #> [1] Depending on model complexity, estimation time may vary... #> [1] TDCM estimation complete. #> [1] Use tdcm.summary() to display results. results <- TDCM::tdcm.summary(model) #> [1] Summarizing results... #> [1] Routine finished. Check results. results$item.parameters #>         λ0     λ1,1  λ1,2  λ1,3  λ1,4  λ2,12 λ2,13 λ2,14 λ2,23 λ2,24  λ2,34 #> Item 1  -1.905 2.599   --    --    --    --    --    --    --    --     --  #> Item 2  -2.072 2.536   --    --    --    --    --    --    --    --     --  #> Item 3  -1.934 2.517   --    --    --    --    --    --    --    --     --  #> Item 4  -1.892 1.091 1.499   --    --  1.057   --    --    --    --     --  #> Item 5  -2.17  1.456   --  1.794   --    --  1.018   --    --    --     --  #> Item 6  -1.843   --  2.199   --    --    --    --    --    --    --     --  #> Item 7  -1.825   --  2.259   --    --    --    --    --    --    --     --  #> Item 8  -1.967   --  2.497   --    --    --    --    --    --    --     --  #> Item 9  -2.009   --  1.079 1.511   --    --    --    --  1.818   --     --  #> Item 10 -2       --  1.849   --  1.324   --    --    --    --  1.065    --  #> Item 11 -1.845   --    --  2.329   --    --    --    --    --    --     --  #> Item 12 -2.033   --    --  2.539   --    --    --    --    --    --     --  #> Item 13 -2.071   --    --  2.55    --    --    --    --    --    --     --  #> Item 14 -2.093   --    --  1.739 2.031   --    --    --    --    --   0.496 #> Item 15 -1.785 0.307   --  1.295   --    --  2.374   --    --    --     --  #> Item 16 -2.218   --    --    --  2.837   --    --    --    --    --     --  #> Item 17 -2.084   --    --    --  2.69    --    --    --    --    --     --  #> Item 18 -2.101   --    --    --  2.521   --    --    --    --    --     --  #> Item 19 -2.1   2.653   --    --  1.432   --    --  0.098   --    --     --  #> Item 20 -2.061   --  2.545   --  1.53    --    --    --    --  -0.005   --  results$growth.effects #>             T1[1] T2[1] Growth Odds Ratio Cohen`s h #> Attribute 1 0.190 0.370  0.180       2.50      0.41 #> Attribute 2 0.317 0.491  0.174       2.08      0.36 #> Attribute 3 0.392 0.579  0.187       2.13      0.38 #> Attribute 4 0.242 0.693  0.451       7.07      0.94  ############################# ## Example 3: T = 3, A = 2 ## data <- data.tdcm03$data q1 <- data.tdcm03$q.matrix.1 q2 <- data.tdcm03$q.matrix.2 q3 <- data.tdcm03$q.matrix.3 q <- data.tdcm03$q.matrix.stacked  #TDCM with anchor items constrained m1 <- tdcm(data, q, num.time.points = 3, num.q.matrix = 3, anchor = c(1,11,1,21,14,24), num.items = c(10,10,10)) #> [1] Preparing data for tdcm()... #> [1] Estimating the TDCM in tdcm()... #> [1] Depending on model complexity, estimation time may vary... #> [1] TDCM estimation complete. #> [1] Use tdcm.summary() to display results.  #TDCM without anchor items m2 <- tdcm(data, q, num.time.points = 3, num.q.matrix = 3, num.items = c(10,10,10)) #> [1] Preparing data for tdcm()... #> [1] Estimating the TDCM in tdcm()... #> [1] Depending on model complexity, estimation time may vary... #> [1] TDCM estimation complete. #> [1] Use tdcm.summary() to display results.  #Compare models to assess measurement invariance tdcm.compare(m1, m2) #>   Model   loglike Deviance Npars      AIC      BIC Chisq df     p #> 1    m1 -27900.69 55801.39    98 55997.39 56518.08 10.16  8 0.254 #> 2    m2 -27895.61 55791.23   106 56003.23 56566.43    NA NA    NA  #Summarize model 1 r1 = tdcm.summary(m1, transition.option = 3) #> [1] Summarizing results... #> [1] Routine finished. Check results. r1$item.parameters #>         λ0     λ1,1  λ1,2  λ2,12  #> Item 1  -1.324 2.175   --    --   #> Item 2  -1.556 2.337   --    --   #> Item 3  -1.556 2.56    --    --   #> Item 4  -1.085 2.393   --    --   #> Item 5  -0.997 1.608   --    --   #> Item 6  -1.423   --  1.835   --   #> Item 7  -0.823   --  1.566   --   #> Item 8  -0.847   --  2.421   --   #> Item 9  -1.027   --  3.253   --   #> Item 10 -0.949   --  3.086   --   #> Item 11 -1.324 2.175   --    --   #> Item 12 -1.132 1.874   --    --   #> Item 13 -0.979 1.576   --    --   #> Item 14 -1.34  0.59  0.442 1.407  #> Item 15 -1.503 0.395 0.58  1.417  #> Item 16 -1.292 0.889 0.595 0.751  #> Item 17 -1.788 1.802 1.155 0.233  #> Item 18 -1.123   --  2.784   --   #> Item 19 -1.144   --  3.226   --   #> Item 20 -1.271   --  3.253   --   #> Item 21 -1.324 2.175   --    --   #> Item 22 -1.248 0.745 1.556 0.005  #> Item 23 -0.994 0.825 0.709 0.474  #> Item 24 -1.34  0.59  0.442 1.407  #> Item 25 -1.647 0.833 1.033 1.191  #> Item 26 -1.747 1.402 0.951 0.383  #> Item 27 -3.139 3.3   3.177 -1.758 #> Item 28 -1.284 0.555 1.419 0.888  #> Item 29 -1.358 0.719 1.194 0.49   #> Item 30 -1.379   --  3.249   --   r1$growth #>             T1[1] T2[1] T3[1] #> Attribute 1 0.306 0.506 0.790 #> Attribute 2 0.311 0.581 0.705 r1$growth.effects #> , , Time 1 to Time 2 #>  #>             Growth Odds Ratio Cohen`s h #> Attribute 1   0.20       2.32      0.41 #> Attribute 2   0.27       3.07      0.55 #>  #> , , Time 2 to Time 3 #>  #>             Growth Odds Ratio Cohen`s h #> Attribute 1  0.284       3.67      0.61 #> Attribute 2  0.124       1.72      0.26 #>   # }"},{"path":"/dev/reference/item.influence.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimating item influence measures. — item.influence","title":"Estimating item influence measures. — item.influence","text":"Function estimate estimate item influence measures. Code adapted (Jurich & Madison, 2023). function available longitudinal DCMs.","code":""},{"path":"/dev/reference/item.influence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimating item influence measures. — item.influence","text":"","code":"item.influence(model, data, fullcorrelation = FALSE, progress = TRUE)"},{"path":"/dev/reference/item.influence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimating item influence measures. — item.influence","text":"model previously calibrated model; object class gdina. data required \\(N \\times \\) matrix. Binary item responses columns. fullcorrelation optional logical argument indicating full reduced response-classification correlation matrix. progress optional logical indicating whether function print progress estimation.","code":""},{"path":"/dev/reference/item.influence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimating item influence measures. — item.influence","text":"list containing several item influence measures.","code":""},{"path":"/dev/reference/item.influence.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimating item influence measures. — item.influence","text":"DCMs, item influence quantifies much item impacts classifications. Given estimated DCM item response data, function estimates five item influence measures, including item pull, item override, proportion attribute information, response-classification correlation (corr1), response-posterior correlation (corr2).","code":""},{"path":"/dev/reference/item.influence.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimating item influence measures. — item.influence","text":"Currently, function currently runs DCMs estimated single time point. run properly TDCM objects.","code":""},{"path":"/dev/reference/item.influence.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimating item influence measures. — item.influence","text":"Jurich, D. & Madison, M. J. (2023). Measuring item influence diagnostic classification models. Educational Assessment.","code":""},{"path":"/dev/reference/item.influence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimating item influence measures. — item.influence","text":"","code":"# \\donttest{ ## Item influence illustration #load data (simulated based on Jurich and Bradshaw (2014)) qmatrix <- CDM::data.sda6$q.matrix responses <- CDM::data.sda6$data  #Estimate the full LCDM model1 <- CDM::gdina(responses, qmatrix, linkfct = \"logit\", method = \"ML\") #> ----------------------------------------------------------------- #> CDM 8.2-6 (2022-08-25 15:43:23)  #> GDINA Model  #>  Link function: logit  #>   ** 2024-11-26 05:57:41.473641  #> ----------------------------------------------------------------- #> ........................................................... #> Iteration 1     2024-11-26 05:57:41.491959  #> Deviance = 41250.26 #> Maximum parameter change: 0.255116  #> ........................................................... #> Iteration 2     2024-11-26 05:57:41.531137  #> Deviance = 37307.05 | Deviance change = 3943.205 #> Maximum parameter change: 0.237804  #> ........................................................... #> Iteration 3     2024-11-26 05:57:41.553789  #> Deviance = 36844.82 | Deviance change = 462.2331 #> Maximum parameter change: 0.058056  #> ........................................................... #> Iteration 4     2024-11-26 05:57:41.581902  #> Deviance = 36784.82 | Deviance change = 60.00074 #> Maximum parameter change: 0.037476  #> ........................................................... #> Iteration 5     2024-11-26 05:57:41.606224  #> Deviance = 36765.74 | Deviance change = 19.07726 #> Maximum parameter change: 0.134754  #> ........................................................... #> Iteration 6     2024-11-26 05:57:41.636054  #> Deviance = 36639.5 | Deviance change = 126.237 #> Maximum parameter change: 0.052503  #> ........................................................... #> Iteration 7     2024-11-26 05:57:41.659905  #> Deviance = 36619.88 | Deviance change = 19.628 #> Maximum parameter change: 0.058732  #> ........................................................... #> Iteration 8     2024-11-26 05:57:41.699624  #> Deviance = 36562.93 | Deviance change = 56.9458 #> Maximum parameter change: 0.028076  #> ........................................................... #> Iteration 9     2024-11-26 05:57:41.717801  #> Deviance = 36557.01 | Deviance change = 5.918638 #> Maximum parameter change: 0.069777  #> ........................................................... #> Iteration 10     2024-11-26 05:57:41.743855  #> Deviance = 36533.7 | Deviance change = 23.31049 #> Maximum parameter change: 0.006856  #> ........................................................... #> Iteration 11     2024-11-26 05:57:41.758407  #> Deviance = 36535.91 | Deviance change = -2.21303 #> **** Deviances decreases! Check for nonconvergence.   **** #> Maximum parameter change: 0.034248  #> ........................................................... #> Iteration 12     2024-11-26 05:57:41.783262  #> Deviance = 36529.54 | Deviance change = 6.379348 #> Maximum parameter change: 0.005495  #> ........................................................... #> Iteration 13     2024-11-26 05:57:41.803516  #> Deviance = 36528.75 | Deviance change = 0.7851916 #> Maximum parameter change: 0.003748  #> ........................................................... #> Iteration 14     2024-11-26 05:57:41.823071  #> Deviance = 36528.29 | Deviance change = 0.4589058 #> Maximum parameter change: 0.00302  #> ........................................................... #> Iteration 15     2024-11-26 05:57:41.837292  #> Deviance = 36527.71 | Deviance change = 0.5760876 #> Maximum parameter change: 0.009911  #> ........................................................... #> Iteration 16     2024-11-26 05:57:41.863605  #> Deviance = 36527.23 | Deviance change = 0.4854475 #> Maximum parameter change: 0.00118  #> ........................................................... #> Iteration 17     2024-11-26 05:57:41.877564  #> Deviance = 36526.96 | Deviance change = 0.2715357 #> Maximum parameter change: 0.010884  #> ........................................................... #> Iteration 18     2024-11-26 05:57:41.903717  #> Deviance = 36526.76 | Deviance change = 0.2015728 #> Maximum parameter change: 0.001425  #> ........................................................... #> Iteration 19     2024-11-26 05:57:41.917657  #> Deviance = 36526.66 | Deviance change = 0.1012999 #> Maximum parameter change: 0.00123  #> ........................................................... #> Iteration 20     2024-11-26 05:57:41.931863  #> Deviance = 36526.58 | Deviance change = 0.0787773 #> Maximum parameter change: 0.001022  #> ........................................................... #> Iteration 21     2024-11-26 05:57:41.945603  #> Deviance = 36526.51 | Deviance change = 0.0670459 #> Maximum parameter change: 0.000859  #> ........................................................... #> Iteration 22     2024-11-26 05:57:41.95927  #> Deviance = 36526.45 | Deviance change = 0.0594842 #> Maximum parameter change: 0.00073  #> ........................................................... #> Iteration 23     2024-11-26 05:57:41.972949  #> Deviance = 36526.4 | Deviance change = 0.0540514 #> Maximum parameter change: 0.000624  #> ........................................................... #> Iteration 24     2024-11-26 05:57:41.99234  #> Deviance = 36526.35 | Deviance change = 0.0498587 #> Maximum parameter change: 0.000537  #> ........................................................... #> Iteration 25     2024-11-26 05:57:42.006168  #> Deviance = 36526.3 | Deviance change = 0.0464631 #> Maximum parameter change: 0.000465  #> ........................................................... #> Iteration 26     2024-11-26 05:57:42.020023  #> Deviance = 36526.26 | Deviance change = 0.0436157 #> Maximum parameter change: 0.000405  #> ........................................................... #> Iteration 27     2024-11-26 05:57:42.033869  #> Deviance = 36526.21 | Deviance change = 0.0411638 #> Maximum parameter change: 0.000355  #> ........................................................... #> Iteration 28     2024-11-26 05:57:42.047564  #> Deviance = 36526.18 | Deviance change = 0.0390077 #> Maximum parameter change: 0.000312  #> ........................................................... #> Iteration 29     2024-11-26 05:57:42.061424  #> Deviance = 36526.14 | Deviance change = 0.0370793 #> Maximum parameter change: 0.000277  #> ........................................................... #> Iteration 30     2024-11-26 05:57:42.075258  #> Deviance = 36526.1 | Deviance change = 0.0353313 #> Maximum parameter change: 0.000246  #> ........................................................... #> Iteration 31     2024-11-26 05:57:42.089456  #> Deviance = 36526.07 | Deviance change = 0.0337297 #> Maximum parameter change: 0.00022  #> ........................................................... #> Iteration 32     2024-11-26 05:57:42.103182  #> Deviance = 36526.04 | Deviance change = 0.0322497 #> Maximum parameter change: 0.000212  #> ........................................................... #> Iteration 33     2024-11-26 05:57:42.116772  #> Deviance = 36526.01 | Deviance change = 0.0308728 #> Maximum parameter change: 0.000207  #> ........................................................... #> Iteration 34     2024-11-26 05:57:42.130362  #> Deviance = 36525.98 | Deviance change = 0.0295852 #> Maximum parameter change: 0.000202  #> ........................................................... #> Iteration 35     2024-11-26 05:57:42.143957  #> Deviance = 36525.95 | Deviance change = 0.028376 #> Maximum parameter change: 0.000197  #> ........................................................... #> Iteration 36     2024-11-26 05:57:42.163302  #> Deviance = 36525.92 | Deviance change = 0.0272367 #> Maximum parameter change: 0.000192  #> ........................................................... #> Iteration 37     2024-11-26 05:57:42.176825  #> Deviance = 36525.9 | Deviance change = 0.0261606 #> Maximum parameter change: 0.000187  #> ........................................................... #> Iteration 38     2024-11-26 05:57:42.190328  #> Deviance = 36525.87 | Deviance change = 0.025142 #> Maximum parameter change: 0.000183  #> ........................................................... #> Iteration 39     2024-11-26 05:57:42.203589  #> Deviance = 36525.85 | Deviance change = 0.0241762 #> Maximum parameter change: 0.000178  #> ........................................................... #> Iteration 40     2024-11-26 05:57:42.216835  #> Deviance = 36525.82 | Deviance change = 0.0232592 #> Maximum parameter change: 0.000174  #> ........................................................... #> Iteration 41     2024-11-26 05:57:42.230202  #> Deviance = 36525.8 | Deviance change = 0.0223876 #> Maximum parameter change: 0.00017  #> ........................................................... #> Iteration 42     2024-11-26 05:57:42.243275  #> Deviance = 36525.78 | Deviance change = 0.0215582 #> Maximum parameter change: 0.000166  #> ........................................................... #> Iteration 43     2024-11-26 05:57:42.256581  #> Deviance = 36525.76 | Deviance change = 0.0207684 #> Maximum parameter change: 0.000162  #> ........................................................... #> Iteration 44     2024-11-26 05:57:42.269851  #> Deviance = 36525.74 | Deviance change = 0.0200156 #> Maximum parameter change: 0.000158  #> ........................................................... #> Iteration 45     2024-11-26 05:57:42.282969  #> Deviance = 36525.72 | Deviance change = 0.0192977 #> Maximum parameter change: 0.000154  #> ........................................................... #> Iteration 46     2024-11-26 05:57:42.296089  #> Deviance = 36525.7 | Deviance change = 0.0186127 #> Maximum parameter change: 0.00015  #> ........................................................... #> Iteration 47     2024-11-26 05:57:42.309236  #> Deviance = 36525.68 | Deviance change = 0.0179586 #> Maximum parameter change: 0.000147  #> ........................................................... #> Iteration 48     2024-11-26 05:57:42.331584  #> Deviance = 36525.66 | Deviance change = 0.0173337 #> Maximum parameter change: 0.000143  #> ........................................................... #> Iteration 49     2024-11-26 05:57:42.344657  #> Deviance = 36525.65 | Deviance change = 0.0167363 #> Maximum parameter change: 0.00014  #> ........................................................... #> Iteration 50     2024-11-26 05:57:42.357724  #> Deviance = 36525.63 | Deviance change = 0.0161651 #> Maximum parameter change: 0.000137  #> ........................................................... #> Iteration 51     2024-11-26 05:57:42.370257  #> Deviance = 36525.62 | Deviance change = 0.0156186 #> Maximum parameter change: 0.000134  #> ........................................................... #> Iteration 52     2024-11-26 05:57:42.382771  #> Deviance = 36525.6 | Deviance change = 0.0150956 #> Maximum parameter change: 0.000131  #> ........................................................... #> Iteration 53     2024-11-26 05:57:42.395106  #> Deviance = 36525.59 | Deviance change = 0.0145947 #> Maximum parameter change: 0.000128  #> ........................................................... #> Iteration 54     2024-11-26 05:57:42.407457  #> Deviance = 36525.57 | Deviance change = 0.0141148 #> Maximum parameter change: 0.000125  #> ........................................................... #> Iteration 55     2024-11-26 05:57:42.419848  #> Deviance = 36525.56 | Deviance change = 0.0136549 #> Maximum parameter change: 0.000122  #> ........................................................... #> Iteration 56     2024-11-26 05:57:42.432102  #> Deviance = 36525.55 | Deviance change = 0.013214 #> Maximum parameter change: 0.000119  #> ........................................................... #> Iteration 57     2024-11-26 05:57:42.444453  #> Deviance = 36525.53 | Deviance change = 0.0127911 #> Maximum parameter change: 0.000117  #> ........................................................... #> Iteration 58     2024-11-26 05:57:42.45656  #> Deviance = 36525.52 | Deviance change = 0.0123853 #> Maximum parameter change: 0.000114  #> ........................................................... #> Iteration 59     2024-11-26 05:57:42.46864  #> Deviance = 36525.51 | Deviance change = 0.0119958 #> Maximum parameter change: 0.000112  #> ........................................................... #> Iteration 60     2024-11-26 05:57:42.480751  #> Deviance = 36525.5 | Deviance change = 0.0116218 #> Maximum parameter change: 0.000109  #> ........................................................... #> Iteration 61     2024-11-26 05:57:42.499587  #> Deviance = 36525.49 | Deviance change = 0.0112625 #> Maximum parameter change: 0.000107  #> ........................................................... #> Iteration 62     2024-11-26 05:57:42.511722  #> Deviance = 36525.47 | Deviance change = 0.0109173 #> Maximum parameter change: 0.000105  #> ........................................................... #> Iteration 63     2024-11-26 05:57:42.523792  #> Deviance = 36525.46 | Deviance change = 0.0105854 #> Maximum parameter change: 0.000102  #> ........................................................... #> Iteration 64     2024-11-26 05:57:42.535826  #> Deviance = 36525.45 | Deviance change = 0.0102663 #> Maximum parameter change: 1e-04  #> ........................................................... #> Iteration 65     2024-11-26 05:57:42.547818  #> Deviance = 36525.44 | Deviance change = 0.0099593 #> Maximum parameter change: 9.8e-05  #> ----------------------------------------------------------------- #> Time difference of 1.151081 secs  #Estimate item influence measures influence <- TDCM::item.influence(model1, responses) #> [1] Calclating item influence measures. Progress = 0%. #> [1] Calclating item influence measures. Progress = 24%. #> [1] Calclating item influence measures. Progress = 47%. #> [1] Calclating item influence measures. Progress = 71%. #> [1] Calclating item influence measures. Progress = 94%. #> [1] Routine finished. Check results.  #Summarize influence statistics influence$Pull #item pull #>    Item Attribute pull0 pull1 #> 1     1         1  0.65  0.65 #> 2     2         1  0.68  0.74 #> 3     3         1  0.60  0.69 #> 4     4         1  0.86  0.68 #> 5     5         2  0.50  0.70 #> 6     6         2  0.47  0.81 #> 7     7         2  0.52  0.76 #> 8     8         2  0.59  0.76 #> 9     9         3  0.60  0.63 #> 10   10         3  0.58  0.71 #> 11   11         3  0.50  0.71 #> 12   12         3  0.55  0.68 #> 13   13         3  1.00  0.82 #> 14   14         3  0.86  0.75 #> 15   15         4  0.58  0.77 #> 16   16         4  0.63  0.86 #> 17   17         4  0.75  0.75 influence$Override #item override #>    Item Attribute override #> 1     1         1     0.07 #> 2     2         1     0.10 #> 3     3         1     0.04 #> 4     4         1     0.11 #> 5     5         2     0.03 #> 6     6         2     0.07 #> 7     7         2     0.07 #> 8     8         2     0.09 #> 9     9         3     0.02 #> 10   10         3     0.04 #> 11   11         3     0.02 #> 12   12         3     0.03 #> 13   13         3     0.16 #> 14   14         3     0.09 #> 15   15         4     0.10 #> 16   16         4     0.22 #> 17   17         4     0.09 influence$Information #proportion of attribute information #>    Item Attribute propinfo #> 1     1         1     0.16 #> 2     2         1     0.24 #> 3     3         1     0.13 #> 4     4         1     0.48 #> 5     5         2     0.12 #> 6     6         2     0.25 #> 7     7         2     0.27 #> 8     8         2     0.37 #> 9     9         3     0.03 #> 10   10         3     0.08 #> 11   11         3     0.04 #> 12   12         3     0.04 #> 13   13         3     0.59 #> 14   14         3     0.22 #> 15   15         4     0.22 #> 16   16         4     0.40 #> 17   17         4     0.38 influence$Correlation1 #correlation of responses and classifications #>    Item Attribute Correl1 #> 1     1         1    0.30 #> 2     2         1    0.41 #> 3     3         1    0.27 #> 4     4         1    0.52 #> 5     5         2    0.19 #> 6     6         2    0.29 #> 7     7         2    0.29 #> 8     8         2    0.34 #> 9     9         3    0.19 #> 10   10         3    0.30 #> 11   11         3    0.21 #> 12   12         3    0.23 #> 13   13         3    0.76 #> 14   14         3    0.56 #> 15   15         4    0.36 #> 16   16         4    0.50 #> 17   17         4    0.47 influence$Correlation2 #correlation of responses and posterior probabilities #>    Item Attribute Correl2 #> 1     1         1    0.36 #> 2     2         1    0.44 #> 3     3         1    0.33 #> 4     4         1    0.60 #> 5     5         2    0.22 #> 6     6         2    0.31 #> 7     7         2    0.33 #> 8     8         2    0.39 #> 9     9         3    0.21 #> 10   10         3    0.36 #> 11   11         3    0.25 #> 12   12         3    0.27 #> 13   13         3    0.82 #> 14   14         3    0.58 #> 15   15         4    0.44 #> 16   16         4    0.58 #> 17   17         4    0.58  # }"},{"path":"/dev/reference/mg.tdcm.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimating the multigroup transition diagnostic classification model (TDCM) — mg.tdcm","title":"Estimating the multigroup transition diagnostic classification model (TDCM) — mg.tdcm","text":"function estimates multigroup TDCM (Madison & Bradshaw, 2018).","code":""},{"path":"/dev/reference/mg.tdcm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimating the multigroup transition diagnostic classification model (TDCM) — mg.tdcm","text":"","code":"mg.tdcm(   data,   q.matrix,   num.time.points,   rule = \"LCDM\",   linkfct = \"logit\",   groups,   forget.att = c(),   group.invariance = TRUE,   time.invariance = TRUE,   progress = TRUE )"},{"path":"/dev/reference/mg.tdcm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimating the multigroup transition diagnostic classification model (TDCM) — mg.tdcm","text":"data required \\(N \\times T \\times \\) matrix. time point, binary item responses columns. q.matrix required \\(\\times \\) matrix indicating items measure attributes. num.time.points number time points (.e., measurement/testing occasions), integer \\(\\ge 2\\). rule string vector specific DCM employed. Currently accepts values rule tdcm(): \"LCDM\", \"DINA\", \"DINO\", \"CRUM\", \"RRUM\", \"LCDM1\" LCDM main effects, \"LCDM2\" LCDM two-way interactions, \"LCDM3\", . rule supplied single string, DCM assumed item. entered vector, rule can specified item. linkfct string indicating LCDM link function. Currently accepts \"logit\" (default) estimate LCDM. Can specified \"identity\" estimate GDINA model. Also accepts \"log\" link function. groups required vector integer group identifiers (e.g., 1, 2, 3) multiple group estimation. forget.att optional vector allowing constraining individual attribute proficiency loss, forgetting. default allows forgetting measured attribute (e.g., \\(P(1 \\rightarrow 0) \\neq 0\\)). vector specified indicate attributes forgetting permitted. group.invariance logical. TRUE (default), item parameters assumed equal groups. FALSE, item parameters assumed equal groups. time.invariance logical. TRUE (default), item parameters assumed equal time points. FALSE, item parameters assumed equal time points. progress logical. FALSE, function print progress estimation. TRUE (default), progress information printed.","code":""},{"path":"/dev/reference/mg.tdcm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimating the multigroup transition diagnostic classification model (TDCM) — mg.tdcm","text":"object class gdina entries indicated CDM package. TDCM-specific results (e.g., growth, transitions), use TDCM::mg.tdcm.summary().","code":""},{"path":"/dev/reference/mg.tdcm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimating the multigroup transition diagnostic classification model (TDCM) — mg.tdcm","text":"Currently, TDCM::mg.tdcm() function accepts single Q-matrix.","code":""},{"path":"/dev/reference/mg.tdcm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimating the multigroup transition diagnostic classification model (TDCM) — mg.tdcm","text":"de la Torre, J. (2011). Generalized DINA Model Framework. Psychometrika 76, 179–199. doi:10.1007/s11336-011-9207-7 George, . C., Robitzsch, ., Kiefer, T., Gross, J., & Ünlü , . (2016). R package CDM Cognitive Diagnosis Models. Journal Statistical Software, 74(2), 1-24. doi:10.18637/jss.v074.i02 Henson, R., Templin, J., & Willse, J. (2009). Defining Family Cognitive Diagnosis Models Using Log-Linear Models Latent Variables. Psychometrika, 74, 191-21. doi:10.1007/s11336-008-9089-5 Johnson, M. S., & Sinharay, S. (2020). Reliability Posterior Probability Skill Attainment Diagnostic Classification Models. Journal Educational Measurement, 47(1), 5–31. doi:10.3102/1076998619864550 Kaya, Y., & Leite, W. (2017). Assessing Change Latent Skills Across Time Longitudinal Cognitive Diagnosis Modeling: Evaluation Model Performance. Educational Psychological Measurement, 77(3), 369–388. doi:10.1177/0013164416659314 Li, F., Cohen, ., Bottge, B., & Templin, J. (2015). Latent Transition Analysis Model Assessing Change Cognitive Skills. Educational Psychological Measurement, 76(2), 181–204. doi:10.1177/0013164415588946 Madison, M. J. (2019). Reliably Assessing Growth Longitudinal Diagnostic Classification Models. Educational Measurement: Issues Practice, 38(2), 68-78. doi:10.1111/emip.12243 Madison, M. J., & Bradshaw, L. (2018a). Assessing Growth Diagnostic Classification Model Framework. Psychometrika, 83(4), 963-990. doi:10.1007/s11336-018-9638-5 Madison, M. J., & Bradshaw, L. (2018b). Evaluating Intervention Effects Diagnostic Classification Model Framework. Journal Educational Measurement, 55(1), 32-51. doi:10.1111/jedm.12162 Madison, M.J., Chung, S., Kim, J., & Bradshaw, L.P. (2024) Approaches estimating longitudinal diagnostic classification models. Behaviormetrika, 51(7), 7-19. doi:10.1007/s41237-023-00202-5 Rupp, . ., Templin, J., & Henson, R. (2010). Diagnostic Measurement: Theory, Methods, Applications. New York: Guilford. ISBN: 9781606235430. Schellman, M., & Madison, M. J. (2024). Estimating reliability skill transition longitudinal DCMs. Journal Educational Behavioral Statistics. Templin, J., & Bradshaw, L. (2013). Measuring Reliability Diagnostic Classification Model Examinee Estimates. Journal Classification, 30, 251-275. doi:10.1007/s00357-013-9129-4 Wang. S., Yang. Y., Culpepper, S. ., & Douglas, J. (2018). Tracking Skill Acquisition Cognitive Diagnosis Models: Higher-Order, Hidden Markov Model Covariates. Journal Educational Behavioral Statistics, 43(1), 57-87. doi:10.3102/1076998617719727","code":""},{"path":"/dev/reference/mg.tdcm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimating the multigroup transition diagnostic classification model (TDCM) — mg.tdcm","text":"","code":"# \\donttest{ ## Example 4: G = 2, T = 2, A = 4 data(data.tdcm04, package = \"TDCM\") data <- data.tdcm04$data q.matrix <- data.tdcm04$q.matrix groups <- data.tdcm04$groups  # Estimate full multigroup TDCM with invariance assumed. mg.model <- TDCM::mg.tdcm(data, q.matrix, num.time.points = 2, groups = groups) #> [1] Preparing data for mg.tdcm()... #> [1] Estimating the multigroup TDCM in mg.tdcm()... #> [1] Depending on model complexity, estimation time may vary... #> [1] Multigroup TDCM estimation complete. #> [1] Use mg.tdcm.summary() to display results.  # summarize results results <- TDCM::mg.tdcm.summary(mg.model) #> [1] Summarizing results... #> [1] Routine finished. Check results.  # plot results TDCM::tdcm.plot(results)         #> [1] **Check the plots window for line and bar plots for group growth proportions. # }"},{"path":"/dev/reference/mg.tdcm.summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Multigroup TDCM results compiler and summarizer. — mg.tdcm.summary","title":"Multigroup TDCM results compiler and summarizer. — mg.tdcm.summary","text":"function compile results calibration multigroup TDCM (Madison & Bradshaw, 2018).","code":""},{"path":"/dev/reference/mg.tdcm.summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multigroup TDCM results compiler and summarizer. — mg.tdcm.summary","text":"","code":"mg.tdcm.summary(   model,   transition.option = 1,   classthreshold = 0.5,   attribute.names = c(),   group.names = c() )"},{"path":"/dev/reference/mg.tdcm.summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multigroup TDCM results compiler and summarizer. — mg.tdcm.summary","text":"model gdina object returned mg.tdcm function. transition.option option reporting results. = 1 compares first time point last. = 2 compares first time point every time point. = 3 compares successive time points. Default = 1. classthreshold probability threshold establishing proficiency examinee posterior probabilities. Default .50, maximizes overall classification accuracy. can set lower value minimize false negatives (.e., misclassifying proficient examinees non-proficient) set higher value minimize false positives (.e., misclassifying non-proficient examinees proficient). attribute.names optional vector attribute names include plots. group.names optional vector group names include plots. Enter order corresponding integer labels groups vector specified mg.tdcm function.","code":""},{"path":"/dev/reference/mg.tdcm.summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multigroup TDCM results compiler and summarizer. — mg.tdcm.summary","text":"list following items: $item.parameters: item parameter estimates specified DCM. $growth: proficiency proportions time point attribute $growth.effects: growth effect size estimates attribute specified transitions including growth proficiency proportion, odds ratio = odds proficiency later time point divided odds proficiency earlier time point, Cohen's h (arcsine-transformed difference proportions; Cohen, 1988) $transition.probabilities: conditional attribute proficiency transition probability matrices $posterior.probabilities: examinee marginal attribute posterior probabilities proficiency $transition.posteriors: examinee marginal attribute transition posterior probabilities $.likely.transitions: examinee likely transitions attribute transition $classifications: examinee classifications determined specified threshold applied posterior probabilities $reliability: estimated transition reliability metrics attribute specified transitions. “pt bis” = longitudinal point biserial metric; “info gain” = longitudinal information gain metric; “polychor” = longitudinal tetrachoric metric; “ave max tr” = average maximum transition posterior metric; “P(t>k)” = proportion examinee marginal attribute transition posteriors greater k; “wt pt bis” = weighted longitudinal point biserial; “wt info gain” = weighted longitudinal information gain. $att.corr: estimated attribute correlation matrix $model.fit: Several model fit indices tests output including item root mean square error approximation (RMSEA; von Davier, 2005), mean RMSEA, bivariate item fit statistics (Chen et al., 2013), absolute fit statistics mean absolute deviation observed expected item correlations (MADcor; DiBello, Roussos, & Stout, 2007), standardized root mean square root squared residuals (SRMSR; Maydeu-Olivares, 2013)","code":""},{"path":"/dev/reference/mg.tdcm.summary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multigroup TDCM results compiler and summarizer. — mg.tdcm.summary","text":"Provides summary multigroup TDCM results including item parameters, attribute posterior probabilities, transition posterior probabilities, classifications, group-wise growth, group-wise transition probabilities, attribute correlations, several transition reliability metrics, model fit. Includes longitudinal versions reliability metrics developed Templin Bradshaw (2013) Johnson Sinharay (2020).","code":""},{"path":"/dev/reference/mg.tdcm.summary.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multigroup TDCM results compiler and summarizer. — mg.tdcm.summary","text":"Chen, J., de la Torre, J. ,& Zhang, Z. (2013). Relative absolute fit evaluation cognitive diagnosis modeling. Journal Educational Measurement, 50, 123-140. DiBello, L. V., Roussos, L. ., & Stout, W. F. (2007). Review cognitively diagnostic assessment summary psychometric models. C. R. Rao S. Sinharay (Eds.), Handbook Statistics, Vol. 26 (pp.979–1030). Amsterdam: Elsevier. Johnson, M. S., & Sinharay, S. (2020). reliability posterior probability skill attainment diagnostic classification models. Journal Educational Measurement, 47(1), 5 – 31. Madison, M. J. (2019). Reliably assessing growth longitudinal diagnostic classification models. Educational Measurement: Issues Practice, 38(2), 68-78. Madison, M. J., & Bradshaw, L. (2018). Evaluating intervention effects diagnostic classification model framework. Journal Educational Measurement, 55(1), 32-51. Maydeu-Olivares, . (2013). Goodness--fit assessment item response theory models (discussion). Measurement: Interdisciplinary Research Perspectives, 11, 71-137. Schellman, M., & Madison, M. J. (2024). Estimating reliability skill transition longitudinal DCMs. Journal Educational Behavioral Statistics. Templin, J., & Bradshaw, L. (2013). Measuring reliability diagnostic classification model examinee estimates. Journal Classification, 30, 251-275. von Davier M. (2008). general diagnostic model applied language testing data. British journal mathematical statistical psychology, 61(2), 287–307.","code":""},{"path":"/dev/reference/mg.tdcm.summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multigroup TDCM results compiler and summarizer. — mg.tdcm.summary","text":"","code":"# \\donttest{ ## Example 4: G = 2, T = 2, A = 4 data(data.tdcm04, package = \"TDCM\") dat4 <- data.tdcm04$data qmat4 <- data.tdcm04$q.matrix group4 <- data.tdcm04$groups  # estimate mgTDCM with invariance assumed and full LCDM mg1 <- TDCM::mg.tdcm(dat4, qmat4, rule = \"LCDM\", num.time.points = 2,   group = group4, group.invariance = TRUE, time.invariance = TRUE) #> [1] Preparing data for mg.tdcm()... #> [1] Estimating the multigroup TDCM in mg.tdcm()... #> [1] Depending on model complexity, estimation time may vary... #> [1] Multigroup TDCM estimation complete. #> [1] Use mg.tdcm.summary() to display results.  # summarize results results1 <- TDCM::mg.tdcm.summary(mg1) #> [1] Summarizing results... #> [1] Routine finished. Check results.  # plot results TDCM::tdcm.plot(results1)         #> [1] **Check the plots window for line and bar plots for group growth proportions.  # estimate mgTDCM without group invariance mg2 <- TDCM::mg.tdcm(dat4, qmat4, rule = \"LCDM\",num.time.points = 2,   group = group4, group.invariance = FALSE, time.invariance = TRUE) #> [1] Preparing data for mg.tdcm()... #> [1] Estimating the multigroup TDCM in mg.tdcm()... #> [1] Depending on model complexity, estimation time may vary... #> [1] Multigroup TDCM estimation complete. #> [1] Use mg.tdcm.summary() to display results.   # compare models to assess group invariance TDCM::tdcm.compare(mg1, mg2) #>   Model   loglike Deviance Npars      AIC      BIC Chisq df      p #> 1   mg1 -37248.15  74496.3   566  75628.3 78706.43 37.08 56 0.9759 #> 2   mg2 -37229.61 74459.22   622 75703.22  79085.9    NA NA     NA # }"},{"path":"/dev/reference/oneplcdm.html","id":null,"dir":"Reference","previous_headings":"","what":"One-parameter log-linear cognitive diagnosis model. — oneplcdm","title":"One-parameter log-linear cognitive diagnosis model. — oneplcdm","text":"Function estimate 1-PLCDM (Madison et al., 2023; Maas et al., 2023).","code":""},{"path":"/dev/reference/oneplcdm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"One-parameter log-linear cognitive diagnosis model. — oneplcdm","text":"","code":"oneplcdm(data, q.matrix, progress = TRUE)"},{"path":"/dev/reference/oneplcdm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"One-parameter log-linear cognitive diagnosis model. — oneplcdm","text":"data required \\(N \\times \\) matrix. Binary item responses columns. q.matrix required \\(\\times \\) matrix indicating items measure attributes. progress optional logical indicating whether function print progress estimation.","code":""},{"path":"/dev/reference/oneplcdm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"One-parameter log-linear cognitive diagnosis model. — oneplcdm","text":"object class gdina entries indicated CDM package.","code":""},{"path":"/dev/reference/oneplcdm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"One-parameter log-linear cognitive diagnosis model. — oneplcdm","text":"Estimates single-attribute multi-attribute 1-PLCDM described Madison et al. (2024). Example shows attribute subscores sufficient statistics classifications.","code":""},{"path":"/dev/reference/oneplcdm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"One-parameter log-linear cognitive diagnosis model. — oneplcdm","text":"Currently, model embedded within TDCM via rule argument.","code":""},{"path":"/dev/reference/oneplcdm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"One-parameter log-linear cognitive diagnosis model. — oneplcdm","text":"George, . C., Robitzsch, ., Kiefer, T., Gross, J., & Ünlü , . (2016). R package CDM cognitive diagnosis models. Journal Statistical Software, 74(2), 1-24. Henson, R., Templin, J., & Willse, J. (2009). Defining family cognitive diagnosis models using log linear models latent variables. Psychometrika, 74, 191-21. Madison, M.J., Wind, S., Maas, L., Yamaguchi, K. & Haab, S. (2024). one-parameter diagnostic classification model familiar measurement properties. Journal Educational Measurement. Maas, L., Madison, M. J., & Brinkhuis, M. J. (2024). Properties performance one-parameter log-linear cognitive diagnosis model. Frontiers.","code":""},{"path":"/dev/reference/oneplcdm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"One-parameter log-linear cognitive diagnosis model. — oneplcdm","text":"","code":"# \\donttest{ ## Example 1: A = 4 data(data.tdcm05) dat5 <- data.tdcm05$data qmat5 <- data.tdcm05$q.matrix  # calibrate LCDM m1 <- CDM::gdina(dat5, qmat5, linkfct = \"logit\", method = \"ML\") #> ----------------------------------------------------------------- #> CDM 8.2-6 (2022-08-25 15:43:23)  #> GDINA Model  #>  Link function: logit  #>   ** 2024-11-26 05:58:33.45753  #> ----------------------------------------------------------------- #> ........................................................... #> Iteration 1     2024-11-26 05:58:33.47759  #> Deviance = 19770.5 #> Maximum parameter change: 0.084303  #> ........................................................... #> Iteration 2     2024-11-26 05:58:33.519078  #> Deviance = 17905.28 | Deviance change = 1865.213 #> Maximum parameter change: 0.05588  #> ........................................................... #> Iteration 3     2024-11-26 05:58:33.543976  #> Deviance = 17666.32 | Deviance change = 238.9634 #> Maximum parameter change: 0.074029  #> ........................................................... #> Iteration 4     2024-11-26 05:58:33.574222  #> Deviance = 17522.41 | Deviance change = 143.912 #> Maximum parameter change: 0.02881  #> ........................................................... #> Iteration 5     2024-11-26 05:58:33.593771  #> Deviance = 17509.64 | Deviance change = 12.76482 #> Maximum parameter change: 0.021972  #> ........................................................... #> Iteration 6     2024-11-26 05:58:33.614803  #> Deviance = 17503.68 | Deviance change = 5.9658 #> Maximum parameter change: 0.004612  #> ........................................................... #> Iteration 7     2024-11-26 05:58:33.63388  #> Deviance = 17500.71 | Deviance change = 2.966632 #> Maximum parameter change: 0.014631  #> ........................................................... #> Iteration 8     2024-11-26 05:58:33.664361  #> Deviance = 17491.82 | Deviance change = 8.893127 #> Maximum parameter change: 0.003278  #> ........................................................... #> Iteration 9     2024-11-26 05:58:33.683191  #> Deviance = 17494.42 | Deviance change = -2.603457 #> **** Deviances decreases! Check for nonconvergence.   **** #> Maximum parameter change: 0.021912  #> ........................................................... #> Iteration 10     2024-11-26 05:58:33.707562  #> Deviance = 17484.83 | Deviance change = 9.589414 #> Maximum parameter change: 0.003986  #> ........................................................... #> Iteration 11     2024-11-26 05:58:33.725781  #> Deviance = 17484.8 | Deviance change = 0.0370989 #> Maximum parameter change: 0.010959  #> ........................................................... #> Iteration 12     2024-11-26 05:58:33.747551  #> Deviance = 17482.69 | Deviance change = 2.110455 #> Maximum parameter change: 0.00172  #> ........................................................... #> Iteration 13     2024-11-26 05:58:33.763122  #> Deviance = 17482.63 | Deviance change = 0.0551816 #> Maximum parameter change: 0.003247  #> ........................................................... #> Iteration 14     2024-11-26 05:58:33.782414  #> Deviance = 17482.5 | Deviance change = 0.1285058 #> Maximum parameter change: 0.000442  #> ........................................................... #> Iteration 15     2024-11-26 05:58:33.80487  #> Deviance = 17482.5 | Deviance change = 0.0050662 #> Maximum parameter change: 0.000736  #> ........................................................... #> Iteration 16     2024-11-26 05:58:33.823315  #> Deviance = 17482.5 | Deviance change = -0.0019762 #> **** Deviances decreases! Check for nonconvergence.   **** #> Maximum parameter change: 0.00023  #> ........................................................... #> Iteration 17     2024-11-26 05:58:33.837762  #> Deviance = 17482.5 | Deviance change = -0.0017578 #> **** Deviances decreases! Check for nonconvergence.   **** #> Maximum parameter change: 0.000182  #> ........................................................... #> Iteration 18     2024-11-26 05:58:33.85347  #> Deviance = 17482.5 | Deviance change = -0.0020594 #> **** Deviances decreases! Check for nonconvergence.   **** #> Maximum parameter change: 0.000145  #> ........................................................... #> Iteration 19     2024-11-26 05:58:33.866941  #> Deviance = 17482.5 | Deviance change = -0.0020351 #> **** Deviances decreases! Check for nonconvergence.   **** #> Maximum parameter change: 0.000118  #> ........................................................... #> Iteration 20     2024-11-26 05:58:33.880122  #> Deviance = 17482.51 | Deviance change = -0.001883 #> **** Deviances decreases! Check for nonconvergence.   **** #> Maximum parameter change: 9.9e-05  #> ----------------------------------------------------------------- #> Time difference of 0.4852643 secs  # calibrate 1-PLCDM m2 <- TDCM::oneplcdm(dat5, qmat5) #> [1] Estimating 1-PLCDM... #> [1] Estimation is complete. Use the CDM summary function to display results. summary(m2) #> ----------------------------------------------------------------- #> CDM 8.2-6 (2022-08-25 15:43:23)  #>  #> Call: #> CDM::gdina(data = data, q.matrix = q.matrix, linkfct = \"logit\",  #>     method = \"ML\", delta.designmatrix = delta.designmatrix, HOGDINA = 0,  #>     progress = FALSE) #>  #> Date of Analysis: 2024-11-26 05:58:36.217338  #> Time difference of 1.5764 secs #> Computation Time: 1.5764  #>  #> Higher Order Generalized DINA Model  #>  #> Number of iterations = 47 #> Iteration with minimal deviance = 4  #>  #> Estimation method: ML #> Optimizer: CDM #> Monotonicity constraints: FALSE #> Number of items at boundary monotonicity constraint: NA #>  #> Parameter regularization: FALSE #>  #> Deviance = 18247.97  | Log likelihood = -9123.99  #>  #> Number of persons = 750  #> Number of groups = 1  #> Number of items = 20  #> Number of estimated parameters = 28  #> Number of estimated item parameters = 24  #> Number of estimated skill class parameters = 4 ( 16 latent skill classes) #>  #> AIC = 18304  | penalty = 56    | AIC = -2*LL + 2*p   #> BIC = 18433  | penalty = 185.36    | BIC = -2*LL + log(n)*p    #> CAIC = 18461  | penalty = 213.36    | CAIC = -2*LL + [log(n)+1]*p  (consistent AIC)    #>  #> ----------------------------------------------------------------- #> Used Q-matrix  #>  #>        Att1 Att2 Att3 Att4 #> Item1     1    0    0    0 #> Item2     1    0    0    0 #> Item3     1    0    0    0 #> Item4     1    0    0    0 #> Item5     1    0    0    0 #> Item6     0    1    0    0 #> Item7     0    1    0    0 #> Item8     0    1    0    0 #> Item9     0    1    0    0 #> Item10    0    1    0    0 #> Item11    0    0    1    0 #> Item12    0    0    1    0 #> Item13    0    0    1    0 #> Item14    0    0    1    0 #> Item15    0    0    1    0 #> Item16    0    0    0    1 #> Item17    0    0    0    1 #> Item18    0    0    0    1 #> Item19    0    0    0    1 #> Item20    0    0    0    1 #>  #> ----------------------------------------------------------------- #>  #> Item Parameter Estimates  #>  #>     link   item itemno partype  rule     est     se partype.attr #> 1  logit  Item1      1       0 GDINA -1.5972 0.1281              #> 2  logit  Item1      1       1 GDINA  1.7928 0.1710         Att1 #> 3  logit  Item2      2       0 GDINA -1.8484 0.1398              #> 4  logit  Item2      2       1 GDINA  1.7928 0.1796         Att1 #> 5  logit  Item3      3       0 GDINA -1.2660 0.1157              #> 6  logit  Item3      3       1 GDINA  1.7928 0.1643         Att1 #> 7  logit  Item4      4       0 GDINA -1.4336 0.1216              #> 8  logit  Item4      4       1 GDINA  1.7928 0.1670         Att1 #> 9  logit  Item5      5       0 GDINA -1.5713 0.1270              #> 10 logit  Item5      5       1 GDINA  1.7928 0.1703         Att1 #> 11 logit  Item6      6       0 GDINA -1.4673 0.1418              #> 12 logit  Item6      6       1 GDINA  2.4114 0.1784         Att2 #> 13 logit  Item7      7       0 GDINA -1.5011 0.1434              #> 14 logit  Item7      7       1 GDINA  2.4114 0.1791         Att2 #> 15 logit  Item8      8       0 GDINA -0.9655 0.1238              #> 16 logit  Item8      8       1 GDINA  2.4114 0.1750         Att2 #> 17 logit  Item9      9       0 GDINA -1.0838 0.1274              #> 18 logit  Item9      9       1 GDINA  2.4114 0.1746         Att2 #> 19 logit Item10     10       0 GDINA -1.2169 0.1318              #> 20 logit Item10     10       1 GDINA  2.4114 0.1750         Att2 #> 21 logit Item11     11       0 GDINA -1.2240 0.1131              #> 22 logit Item11     11       1 GDINA  2.9666 0.1967         Att3 #> 23 logit Item12     12       0 GDINA -1.6220 0.1277              #> 24 logit Item12     12       1 GDINA  2.9666 0.1906         Att3 #> 25 logit Item13     13       0 GDINA -1.4200 0.1197              #> 26 logit Item13     13       1 GDINA  2.9666 0.1924         Att3 #> 27 logit Item14     14       0 GDINA -1.1768 0.1117              #> 28 logit Item14     14       1 GDINA  2.9666 0.1981         Att3 #> 29 logit Item15     15       0 GDINA -1.4495 0.1208              #> 30 logit Item15     15       1 GDINA  2.9666 0.1919         Att3 #> 31 logit Item16     16       0 GDINA -1.2130 0.1774              #> 32 logit Item16     16       1 GDINA  2.7803 0.2092         Att4 #> 33 logit Item17     17       0 GDINA -1.6921 0.2057              #> 34 logit Item17     17       1 GDINA  2.7803 0.2272         Att4 #> 35 logit Item18     18       0 GDINA -1.3103 0.1823              #> 36 logit Item18     18       1 GDINA  2.7803 0.2116         Att4 #> 37 logit Item19     19       0 GDINA -1.5943 0.1990              #> 38 logit Item19     19       1 GDINA  2.7803 0.2223         Att4 #> 39 logit Item20     20       0 GDINA -1.3030 0.1819              #> 40 logit Item20     20       1 GDINA  2.7803 0.2114         Att4 #>  #> Note: Standard errors are not (yet) correctly implemented! #>  #> RMSD (RMSEA) Item Fit Statistics #>  Item1  Item2  Item3  Item4  Item5  Item6  Item7  Item8  Item9 Item10 Item11  #>  0.161  0.144  0.184  0.160  0.192  0.196  0.121  0.143  0.137  0.160  0.078  #> Item12 Item13 Item14 Item15 Item16 Item17 Item18 Item19 Item20  #>  0.077  0.070  0.065  0.069  0.254  0.173  0.147  0.112  0.125  #>  #> Mean of RMSEA item fit: 0.138  #> ----------------------------------------------------------------- #> Model Implied Conditional Item Probabilities  #>  #>      item  rule nessskill itemno skillcomb   prob #> 1   Item1 GDINA      Att1      1        A0 0.1684 #> 2   Item1 GDINA      Att1      1        A1 0.5487 #> 3   Item2 GDINA      Att1      2        A0 0.1361 #> 4   Item2 GDINA      Att1      2        A1 0.4861 #> 5   Item3 GDINA      Att1      3        A0 0.2200 #> 6   Item3 GDINA      Att1      3        A1 0.6287 #> 7   Item4 GDINA      Att1      4        A0 0.1925 #> 8   Item4 GDINA      Att1      4        A1 0.5888 #> 9   Item5 GDINA      Att1      5        A0 0.1720 #> 10  Item5 GDINA      Att1      5        A1 0.5551 #> 11  Item6 GDINA      Att2      6        A0 0.1874 #> 12  Item6 GDINA      Att2      6        A1 0.7199 #> 13  Item7 GDINA      Att2      7        A0 0.1823 #> 14  Item7 GDINA      Att2      7        A1 0.7131 #> 15  Item8 GDINA      Att2      8        A0 0.2758 #> 16  Item8 GDINA      Att2      8        A1 0.8094 #> 17  Item9 GDINA      Att2      9        A0 0.2528 #> 18  Item9 GDINA      Att2      9        A1 0.7904 #> 19 Item10 GDINA      Att2     10        A0 0.2285 #> 20 Item10 GDINA      Att2     10        A1 0.7675 #> 21 Item11 GDINA      Att3     11        A0 0.2272 #> 22 Item11 GDINA      Att3     11        A1 0.8510 #> 23 Item12 GDINA      Att3     12        A0 0.1649 #> 24 Item12 GDINA      Att3     12        A1 0.7932 #> 25 Item13 GDINA      Att3     13        A0 0.1947 #> 26 Item13 GDINA      Att3     13        A1 0.8244 #> 27 Item14 GDINA      Att3     14        A0 0.2356 #> 28 Item14 GDINA      Att3     14        A1 0.8569 #> 29 Item15 GDINA      Att3     15        A0 0.1901 #> 30 Item15 GDINA      Att3     15        A1 0.8201 #> 31 Item16 GDINA      Att4     16        A0 0.2292 #> 32 Item16 GDINA      Att4     16        A1 0.8274 #> 33 Item17 GDINA      Att4     17        A0 0.1555 #> 34 Item17 GDINA      Att4     17        A1 0.7480 #> 35 Item18 GDINA      Att4     18        A0 0.2124 #> 36 Item18 GDINA      Att4     18        A1 0.8131 #> 37 Item19 GDINA      Att4     19        A0 0.1688 #> 38 Item19 GDINA      Att4     19        A1 0.7660 #> 39 Item20 GDINA      Att4     20        A0 0.2137 #> 40 Item20 GDINA      Att4     20        A1 0.8142 #> ----------------------------------------------------------------- #>  #> Skill Probabilities  #>  #>      skill.prob0 skill.prob1 #> Att1      0.5803      0.4197 #> Att2      0.4352      0.5648 #> Att3      0.5938      0.4062 #> Att4      0.2399      0.7601 #> ----------------------------------------------------------------- #>  #> Polychoric Correlations  #>  #> Group 1 #>      Att1 Att2 Att3 Att4 #> Att1    1    0    0    0 #> Att2    0    1    0    0 #> Att3    0    0    1    0 #> Att4    0    0    0    1 #>  #>  ----------------------------------------------------------------- #>  #> Skill Pattern Probabilities  #>  #>   0000   1000   0100   1100   0010   1010   0110   1110   0001   1001   0101  #> 0.0360 0.0260 0.0467 0.0338 0.0246 0.0178 0.0319 0.0231 0.1140 0.0824 0.1479  #>   1101   0011   1011   0111   1111  #> 0.1070 0.0780 0.0564 0.1012 0.0732  #>  #>  ----------------------------------------------------------------- #> Higher Order GDINA Model  #>   Attribute Response Function Parameters  #>  #>       b.Gr1 a.Gr1 int.Gr1 #> Att1  0.744     0    -Inf #> Att2 -0.047     0     Inf #> Att3  0.190     0    -Inf #> Att4 -0.698     0     Inf #demonstrate 1-PLCDM sum score sufficiency for each attribute subscores <- cbind(rowSums(dat5[, 1:5]), rowSums(dat5[, 6:10]), rowSums(dat5[, 11:15]), rowSums(dat5[, 16:20])) colnames(subscores) <- c(\"Att1\", \"Att2\", \"Att3\", \"Att4\") proficiency <- cbind(m2$pattern[, 6] > .50, m2$pattern[, 7] > .50, m2$pattern[, 8] > .50, m2$pattern[, 9] > .5) * 1 table(subscores[, 1], proficiency[, 1]) #>     #>       0   1 #>   0 150   0 #>   1 250   0 #>   2   0 156 #>   3   0  95 #>   4   0  71 #>   5   0  28 table(subscores[, 2], proficiency[, 2]) #>     #>       0   1 #>   0  88   0 #>   1 149   0 #>   2 106   0 #>   3   0 138 #>   4   0 163 #>   5   0 106 table(subscores[, 3], proficiency[, 3]) #>     #>       0   1 #>   0 136   0 #>   1 209   0 #>   2  74   0 #>   3   0  86 #>   4   0 131 #>   5   0 114 table(subscores[, 4], proficiency[, 4]) #>     #>       0   1 #>   0  68   0 #>   1  76   0 #>   2   0  62 #>   3   0 127 #>   4   0 254 #>   5   0 163  #plot sum score sufficiency for each attribute posterior1pl <- m2$pattern[, 6:9] posteriorlcdm <- m1$pattern[, 6:9] oldpar <- par(mfrow = c(2, 2)) for (i in 1:4) {  plot(subscores[, i], posteriorlcdm[, i], pch = 19,las = 1, cex.lab = 1.5,  xlab = \"Sum Scores\", ylab = \"P(proficiency)\",  cex.main = 1.5, col = \"grey\", xaxt = \"n\", yaxt = \"n\", cex = 1.2,  main = paste(\"Attribute \", i, sep = \"\"))  graphics::axis(side = 1, at = c(0, 1, 2, 3, 4, 5), )  graphics::axis(side = 2, at = c(0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1.0), las = 1)  graphics::points(subscores[, i], posterior1pl[, i], col = \"black\", pch = 18, cex = 1.5)  graphics::abline(a = .50, b = 0, col = \"red\")  graphics::legend(\"bottomright\", c(\"1-PLCDM\", \"LCDM\"), col = c(\"black\", \"grey\"),  pch = c(18 ,19), box.lwd = 0, box.col = \"white\", bty = 'n') }  par(oldpar) # }"},{"path":"/dev/reference/tdcm.compare.html","id":null,"dir":"Reference","previous_headings":"","what":"Comparing the fit of two TDCMs — tdcm.compare","title":"Comparing the fit of two TDCMs — tdcm.compare","text":"Provides comparison two TDCMs. Can used compare different measurement models assess measurement invariance time groups multigroup TDCM case. accepts two models.","code":""},{"path":"/dev/reference/tdcm.compare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Comparing the fit of two TDCMs — tdcm.compare","text":"","code":"tdcm.compare(model1, model2)"},{"path":"/dev/reference/tdcm.compare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Comparing the fit of two TDCMs — tdcm.compare","text":"model1 gdina object returned tdcm mg.tdcm function. model2 second gdina object returned tdcm mg.tdcm function","code":""},{"path":"/dev/reference/tdcm.compare.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Comparing the fit of two TDCMs — tdcm.compare","text":"function returns data frame model fit statistics (AIC/BIC) results likelihood ratio deviance test.","code":""},{"path":"/dev/reference/tdcm.compare.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Comparing the fit of two TDCMs — tdcm.compare","text":"Currently, function currently accepts two models comparison. models must fit item responses Q-matrix. function provide results two non-nested models. Please ensure models nested interpreting likelihood ratio test nested models. likelihood ratio test valid model comparisons (e.g., LCDM vs DINA) model constraints.","code":""},{"path":"/dev/reference/tdcm.compare.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Comparing the fit of two TDCMs — tdcm.compare","text":"","code":"# \\donttest{ ## Example 1: T = 2, A = 4 data(data.tdcm01, package = \"TDCM\") dat1 <- data.tdcm01$data qmat1 <- data.tdcm01$q.matrix  # estimate TDCM with invariance assumed and full LCDM m1 <- TDCM::tdcm(dat1, qmat1, num.time.points = 2, invariance = TRUE, rule = \"LCDM\") #> [1] Preparing data for tdcm()... #> [1] Estimating the multigroup TDCM in mg.tdcm()... #> [1] Depending on model complexity, estimation time may vary... #> [1] TDCM estimation complete. #> [1] Use tdcm.summary() to display results.  # estimate TDCM with invariance not assumed m2 <- TDCM::tdcm(dat1, qmat1, num.time.points = 2, invariance = FALSE, rule = \"LCDM\") #> [1] Preparing data for tdcm()... #> [1] Estimating the multigroup TDCM in mg.tdcm()... #> [1] Depending on model complexity, estimation time may vary... #> [1] TDCM estimation complete. #> [1] Use tdcm.summary() to display results.  # compare models to assess measurement invariance. TDCM::tdcm.compare(m1, m2) #>   Model   loglike Deviance Npars      AIC      BIC Chisq df      p #> 1    m1 -21369.72 42739.44   311 43361.44 44887.75 64.68 56 0.1995 #> 2    m2 -21337.38 42674.75   367 43408.75  45209.9    NA NA     NA # }"},{"path":"/dev/reference/tdcm.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimating the Transition Diagnostic Classification Model (TDCM) — tdcm","title":"Estimating the Transition Diagnostic Classification Model (TDCM) — tdcm","text":"tdcm() used estimate transition diagnostic classification model (TDCM; Madison & Bradshaw, 2018a), longitudinal extension log-linear cognitive diagnosis model (LCDM; Henson, Templin, & Willse, 2009). multigroup TDCM, see mg.tdcm().  allows specification many specific DCMs via rule option. default DCM rule link function specifies LCDM. rule can changed estimate DINA model, DINO model, CRUM (.e., ACDM, main effects model), reduced interaction versions LCDM. link function can changed specify GDINA model.","code":""},{"path":"/dev/reference/tdcm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimating the Transition Diagnostic Classification Model (TDCM) — tdcm","text":"","code":"tdcm(   data,   q.matrix,   num.time.points,   invariance = TRUE,   rule = \"LCDM\",   linkfct = \"logit\",   num.q.matrix = 1,   num.items = c(),   anchor = c(),   forget.att = c(),   progress = TRUE )"},{"path":"/dev/reference/tdcm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimating the Transition Diagnostic Classification Model (TDCM) — tdcm","text":"data required \\(N \\times T \\times \\) data matrix containing binary item responses.  time point, binary item responses columns. q.matrix required \\(\\times \\) matrix indicating items measure attributes. multiple Q-matrices, must number attributes must stacked top estimation (specify multiple Q-matrices, see num.q.matrix, num.items, anchor). num.time.points required integer \\(\\ge 2\\) specifying number time points (.e., measurement occasions). invariance logical. TRUE (default), item parameters constrained equal time point. FALSE, item parameters assumed equal time. rule string vector indicating specific DCM employed. vector supported rule values provided tdcm.rules. rule supplied single string, DCM assumed item. entered vector, rule can specified item. linkfct string vector indicating LCDM link function. Currently accepts \"logit\" (default) estimate LCDM. Can specified \"identity\" estimate GDINA model. Also accepts \"log\" link function. num.q.matrix optional integer specifying number Q-matrices. many applications, assessment administered time point number 1 (default). different Q-matrices time point, argument must specified equal number time points. example, three time points, Q-matrix time point different, num.q.matrix = 3. three time points, Q-matrix different time point 3, num.q.matrix still specified 3. num.items integer specifying number items. multiple Q-matrices, number items Q-matrix specified vector. example, three time points, Q-matrices time point 8, 10, 12 items, respectively, num.items = c(8, 10, 12). anchor different tests time point, optional argument vector pairs item numbers indicating items across time points held invariant. example, three Q-matrices 10 items , Items 1, 11, 21 , Items 14 24 , anchor = c(1,11,1,21,14,24). Default empty vector indicate absence anchor items. Note: anchor specified, invariance automatically set false non-anchor items. forget.att optional vector allowing constraining individual attribute proficiency loss, forgetting. default allows forgetting measured attribute (e.g., \\(P(1 \\rightarrow 0) \\neq 0\\)). vector specified indicate attributes forgetting permitted. progress logical. FALSE, function print progress estimation. TRUE (default), progress information printed.","code":""},{"path":"/dev/reference/tdcm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimating the Transition Diagnostic Classification Model (TDCM) — tdcm","text":"object class gdina entries described CDM::gdina(). see TDCM-specific summary object (e.g., growth, transitions), use tdcm.summary().","code":""},{"path":"/dev/reference/tdcm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimating the Transition Diagnostic Classification Model (TDCM) — tdcm","text":"Estimation TDCM via CDM package (George, et al., 2016), based EM algorithm described de la Torre (2011). estimation approach detailed Madison et al. (2023).","code":""},{"path":"/dev/reference/tdcm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimating the Transition Diagnostic Classification Model (TDCM) — tdcm","text":"de la Torre, J. (2011). Generalized DINA Model Framework. Psychometrika 76, 179–199. doi:10.1007/s11336-011-9207-7 George, . C., Robitzsch, ., Kiefer, T., Gross, J., & Ünlü , . (2016). R package CDM Cognitive Diagnosis Models. Journal Statistical Software, 74(2), 1-24. doi:10.18637/jss.v074.i02 Henson, R., Templin, J., & Willse, J. (2009). Defining Family Cognitive Diagnosis Models Using Log-Linear Models Latent Variables. Psychometrika, 74, 191-21. doi:10.1007/s11336-008-9089-5 Johnson, M. S., & Sinharay, S. (2020). Reliability Posterior Probability Skill Attainment Diagnostic Classification Models. Journal Educational Measurement, 47(1), 5–31. doi:10.3102/1076998619864550 Kaya, Y., & Leite, W. (2017). Assessing Change Latent Skills Across Time Longitudinal Cognitive Diagnosis Modeling: Evaluation Model Performance. Educational Psychological Measurement, 77(3), 369–388. doi:10.1177/0013164416659314 Li, F., Cohen, ., Bottge, B., & Templin, J. (2015). Latent Transition Analysis Model Assessing Change Cognitive Skills. Educational Psychological Measurement, 76(2), 181–204. doi:10.1177/0013164415588946 Madison, M. J. (2019). Reliably Assessing Growth Longitudinal Diagnostic Classification Models. Educational Measurement: Issues Practice, 38(2), 68-78. doi:10.1111/emip.12243 Madison, M. J., & Bradshaw, L. (2018a). Assessing Growth Diagnostic Classification Model Framework. Psychometrika, 83(4), 963-990. doi:10.1007/s11336-018-9638-5 Madison, M. J., & Bradshaw, L. (2018b). Evaluating Intervention Effects Diagnostic Classification Model Framework. Journal Educational Measurement, 55(1), 32-51. doi:10.1111/jedm.12162 Madison, M.J., Chung, S., Kim, J., & Bradshaw, L.P. (2024) Approaches estimating longitudinal diagnostic classification models. Behaviormetrika, 51(7), 7-19. doi:10.1007/s41237-023-00202-5 Rupp, . ., Templin, J., & Henson, R. (2010). Diagnostic Measurement: Theory, Methods, Applications. New York: Guilford. ISBN: 9781606235430. Schellman, M., & Madison, M. J. (2024). Estimating reliability skill transition longitudinal DCMs. Journal Educational Behavioral Statistics. Templin, J., & Bradshaw, L. (2013). Measuring Reliability Diagnostic Classification Model Examinee Estimates. Journal Classification, 30, 251-275. doi:10.1007/s00357-013-9129-4 Wang. S., Yang. Y., Culpepper, S. ., & Douglas, J. (2018). Tracking Skill Acquisition Cognitive Diagnosis Models: Higher-Order, Hidden Markov Model Covariates. Journal Educational Behavioral Statistics, 43(1), 57-87. doi:10.3102/1076998617719727","code":""},{"path":"/dev/reference/tdcm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimating the Transition Diagnostic Classification Model (TDCM) — tdcm","text":"","code":"# \\donttest{ ## Example 1: T = 2, A = 4 data(data.tdcm01, package = \"TDCM\") data <- data.tdcm01$data q.matrix <- data.tdcm01$q.matrix  # Estimate full TDCM with invariance assumed. model1 <- TDCM::tdcm(data, q.matrix, num.time.points = 2) #> [1] Preparing data for tdcm()... #> [1] Estimating the multigroup TDCM in mg.tdcm()... #> [1] Depending on model complexity, estimation time may vary... #> [1] TDCM estimation complete. #> [1] Use tdcm.summary() to display results.  # Summarize results with tdcm.summary(). results <- TDCM::tdcm.summary(model1) #> [1] Summarizing results... #> [1] Routine finished. Check results. results$item.parameters #>         λ0     λ1,1  λ1,2  λ1,3  λ1,4  λ2,12 λ2,13 λ2,14 λ2,23 λ2,24  λ2,34 #> Item 1  -1.905 2.599   --    --    --    --    --    --    --    --     --  #> Item 2  -2.072 2.536   --    --    --    --    --    --    --    --     --  #> Item 3  -1.934 2.517   --    --    --    --    --    --    --    --     --  #> Item 4  -1.892 1.091 1.499   --    --  1.057   --    --    --    --     --  #> Item 5  -2.17  1.456   --  1.794   --    --  1.018   --    --    --     --  #> Item 6  -1.843   --  2.199   --    --    --    --    --    --    --     --  #> Item 7  -1.825   --  2.259   --    --    --    --    --    --    --     --  #> Item 8  -1.967   --  2.497   --    --    --    --    --    --    --     --  #> Item 9  -2.009   --  1.079 1.511   --    --    --    --  1.818   --     --  #> Item 10 -2       --  1.849   --  1.324   --    --    --    --  1.065    --  #> Item 11 -1.845   --    --  2.329   --    --    --    --    --    --     --  #> Item 12 -2.033   --    --  2.539   --    --    --    --    --    --     --  #> Item 13 -2.071   --    --  2.55    --    --    --    --    --    --     --  #> Item 14 -2.093   --    --  1.739 2.031   --    --    --    --    --   0.496 #> Item 15 -1.785 0.307   --  1.295   --    --  2.374   --    --    --     --  #> Item 16 -2.218   --    --    --  2.837   --    --    --    --    --     --  #> Item 17 -2.084   --    --    --  2.69    --    --    --    --    --     --  #> Item 18 -2.101   --    --    --  2.521   --    --    --    --    --     --  #> Item 19 -2.1   2.653   --    --  1.432   --    --  0.098   --    --     --  #> Item 20 -2.061   --  2.545   --  1.53    --    --    --    --  -0.005   --  results$growth #>             T1[1] T2[1] #> Attribute 1 0.190 0.370 #> Attribute 2 0.317 0.491 #> Attribute 3 0.392 0.579 #> Attribute 4 0.242 0.693 results$transition.probabilities #> , , Attribute 1: Time 1 to Time 2 #>  #>        T2 [0] T2 [1] #> T1 [0]  0.680  0.320 #> T1 [1]  0.417  0.583 #>  #> , , Attribute 2: Time 1 to Time 2 #>  #>        T2 [0] T2 [1] #> T1 [0]  0.581  0.419 #> T1 [1]  0.353  0.647 #>  #> , , Attribute 3: Time 1 to Time 2 #>  #>        T2 [0] T2 [1] #> T1 [0]  0.549  0.451 #> T1 [1]  0.221  0.779 #>  #> , , Attribute 4: Time 1 to Time 2 #>  #>        T2 [0] T2 [1] #> T1 [0]  0.371  0.629 #> T1 [1]  0.104  0.896 #>  # }"},{"path":"/dev/reference/tdcm.plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plotting TDCM Results — tdcm.plot","title":"Plotting TDCM Results — tdcm.plot","text":"tdcm.plot() visualizes results TDCM analyses.","code":""},{"path":"/dev/reference/tdcm.plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plotting TDCM Results — tdcm.plot","text":"","code":"tdcm.plot(results, attribute.names = c(), group.names = c(), type = \"both\")"},{"path":"/dev/reference/tdcm.plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plotting TDCM Results — tdcm.plot","text":"results results tdcm.summary mg.tdcm.summary attribute.names optional vector attribute names include plots. group.names optional vector group names include plots. type option specify type plot single group cases; \"\" default produce line plot bar chart; \"line\" produce line plot; \"bar\" produce bar chart.","code":""},{"path":"/dev/reference/tdcm.plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plotting TDCM Results — tdcm.plot","text":"return value, called side effects.","code":""},{"path":"/dev/reference/tdcm.plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plotting TDCM Results — tdcm.plot","text":"","code":"# \\donttest{ ## Example 1: T = 2, A = 4 data(data.tdcm01, package = \"TDCM\") dat1 = data.tdcm01$data qmat1 = data.tdcm01$q.matrix  #estimate TDCM with invariance assumed and full LCDM m1 = TDCM::tdcm(dat1, qmat1, num.time.points = 2, invariance = TRUE, rule = \"LCDM\") #> [1] Preparing data for tdcm()... #> [1] Estimating the multigroup TDCM in mg.tdcm()... #> [1] Depending on model complexity, estimation time may vary... #> [1] TDCM estimation complete. #> [1] Use tdcm.summary() to display results.  #summarize results with tdcm.summary function results1 = TDCM::tdcm.summary(m1) #> [1] Summarizing results... #> [1] Routine finished. Check results.  #plot results TDCM::tdcm.plot(results1, attribute.names = c(\"Addition\", \"Subtraction\", \"Multiplication\", \"Division\"))   #> [1] **Check the plots window for line and bar plots of growth proportions. # }"},{"path":"/dev/reference/tdcm.rules.html","id":null,"dir":"Reference","previous_headings":"","what":"TDCM Condensation Rules — tdcm.rules","title":"TDCM Condensation Rules — tdcm.rules","text":"condensation rule formula states different attributes combine form observed latent response (Rupp, Templin, & Henson, 2010). TDCM package includes support \"LCDM\", \"DINA\", \"DINO\", \"CRUM\", \"RRUM\", \"LCDM1\" LCDM main effects, \"LCDM2\" LCDM two-way interactions, \"LCDM3\", . Evaluate TDCM::tdcm.rules$TDCM complete list condensation rules supported TDCM package.","code":""},{"path":"/dev/reference/tdcm.rules.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"TDCM Condensation Rules — tdcm.rules","text":"","code":"tdcm.rules"},{"path":"/dev/reference/tdcm.rules.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"TDCM Condensation Rules — tdcm.rules","text":"object class data.frame 15 rows 2 columns.","code":""},{"path":"/dev/reference/tdcm.rules.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"TDCM Condensation Rules — tdcm.rules","text":"Rupp, . ., Templin, J., & Henson, R. (2010). Diagnostic Measurement: Theory, Methods, Applications. New York: Guilford. ISBN: 9781606235430.","code":""},{"path":"/dev/reference/tdcm.rules.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"TDCM Condensation Rules — tdcm.rules","text":"","code":"TDCM::tdcm.rules$TDCM #>  [1] \"LCDM\"   \"CRUM\"   \"DINA\"   \"DINO\"   \"RRUM\"   \"LCDM1\"  \"LCDM2\"  \"LCDM3\"  #>  [9] \"LCDM4\"  \"LCDM5\"  \"LCDM6\"  \"LCDM7\"  \"LCDM8\"  \"LCDM9\"  \"LCDM10\""},{"path":"/dev/reference/tdcm.score.html","id":null,"dir":"Reference","previous_headings":"","what":"DCM scoring function. — tdcm.score","title":"DCM scoring function. — tdcm.score","text":"Function score responses fixed item parameters previously calibrated LCDM.","code":""},{"path":"/dev/reference/tdcm.score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DCM scoring function. — tdcm.score","text":"","code":"tdcm.score(   calibration.model,   newdata,   q.matrix,   attr.prob.fixed = NULL,   progress = TRUE )"},{"path":"/dev/reference/tdcm.score.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"DCM scoring function. — tdcm.score","text":"calibration.model previously calibrated model; object class gdina. newdata required \\(N \\times \\) matrix. Binary item responses columns. q.matrix required \\(\\times \\) matrix indicating items measure attributes. attr.prob.fixed optional argument attribute profile proportions. Default uniform distribution profiles. progress optional logical indicating whether function print progress estimation.","code":""},{"path":"/dev/reference/tdcm.score.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"DCM scoring function. — tdcm.score","text":"object class gdina entries indicated CDM package.","code":""},{"path":"/dev/reference/tdcm.score.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"DCM scoring function. — tdcm.score","text":"Obtain classifications new responses items previously calibrated. calibrate--score approach detailed Madison et al. (2023).","code":""},{"path":"/dev/reference/tdcm.score.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"DCM scoring function. — tdcm.score","text":"George, . C., Robitzsch, ., Kiefer, T., Gross, J., & Ünlü , . (2016). R package CDM cognitive diagnosis models. Journal Statistical Software, 74(2), 1-24. Henson, R., Templin, J., & Willse, J. (2009). Defining family cognitive diagnosis models using log linear models latent variables. Psychometrika, 74, 191-21. Madison, M.J., Chung, S., Kim, J., & Bradshaw, L. (2023). Approaches estimating longitudinal diagnostic classification models. Behaviormetrika.","code":""},{"path":"/dev/reference/tdcm.score.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"DCM scoring function. — tdcm.score","text":"","code":"## Example 1: T = 2, A = 4 data(data.tdcm01, package = \"TDCM\") dat1 <- data.tdcm01$data qmat1 <- data.tdcm01$q.matrix pre <- dat1[, 1:20] post <- dat1[, 21:40]  # calibrate LCDM with post-test data m1 <- CDM::gdina(data = pre, q.matrix = qmat1, linkfct = \"logit\", method = \"ML\") #> ----------------------------------------------------------------- #> CDM 8.2-6 (2022-08-25 15:43:23)  #> GDINA Model  #>  Link function: logit  #>   ** 2024-11-26 05:59:08.914415  #> ----------------------------------------------------------------- #> ........................................................... #> Iteration 1     2024-11-26 05:59:08.93347  #> Deviance = 20762.07 #> Maximum parameter change: 0.13422  #> ........................................................... #> Iteration 2     2024-11-26 05:59:08.977476  #> Deviance = 20417.96 | Deviance change = 344.1115 #> Maximum parameter change: 0.096313  #> ........................................................... #> Iteration 3     2024-11-26 05:59:09.004869  #> Deviance = 20323.3 | Deviance change = 94.65533 #> Maximum parameter change: 0.145515  #> ........................................................... #> Iteration 4     2024-11-26 05:59:09.046731  #> Deviance = 20189.72 | Deviance change = 133.5794 #> Maximum parameter change: 0.047143  #> ........................................................... #> Iteration 5     2024-11-26 05:59:09.07102  #> Deviance = 20174.5 | Deviance change = 15.22506 #> Maximum parameter change: 0.07731  #> ........................................................... #> Iteration 6     2024-11-26 05:59:09.098885  #> Deviance = 20157.81 | Deviance change = 16.68566 #> Maximum parameter change: 0.057223  #> ........................................................... #> Iteration 7     2024-11-26 05:59:09.121176  #> Deviance = 20155.97 | Deviance change = 1.846488 #> Maximum parameter change: 0.067062  #> ........................................................... #> Iteration 8     2024-11-26 05:59:09.147053  #> Deviance = 20154.75 | Deviance change = 1.219438 #> Maximum parameter change: 0.01798  #> ........................................................... #> Iteration 9     2024-11-26 05:59:09.166297  #> Deviance = 20154.56 | Deviance change = 0.1853676 #> Maximum parameter change: 0.047088  #> ........................................................... #> Iteration 10     2024-11-26 05:59:09.192972  #> Deviance = 20154.45 | Deviance change = 0.1087729 #> Maximum parameter change: 0.00748  #> ........................................................... #> Iteration 11     2024-11-26 05:59:09.219694  #> Deviance = 20154.41 | Deviance change = 0.0422554 #> Maximum parameter change: 0.003983  #> ........................................................... #> Iteration 12     2024-11-26 05:59:09.240515  #> Deviance = 20154.39 | Deviance change = 0.0185635 #> Maximum parameter change: 0.002333  #> ........................................................... #> Iteration 13     2024-11-26 05:59:09.258507  #> Deviance = 20154.38 | Deviance change = 0.0067005 #> Maximum parameter change: 0.002951  #> ........................................................... #> Iteration 14     2024-11-26 05:59:09.28171  #> Deviance = 20154.38 | Deviance change = 0.0085245 #> Maximum parameter change: 0.000475  #> ........................................................... #> Iteration 15     2024-11-26 05:59:09.308052  #> Deviance = 20154.37 | Deviance change = 0.0010603 #> Maximum parameter change: 0.00037  #> ........................................................... #> Iteration 16     2024-11-26 05:59:09.329529  #> Deviance = 20154.37 | Deviance change = 0.000488 #> Maximum parameter change: 0.000289  #> ........................................................... #> Iteration 17     2024-11-26 05:59:09.347318  #> Deviance = 20154.37 | Deviance change = 0.0001966 #> Maximum parameter change: 0.000225  #> ........................................................... #> Iteration 18     2024-11-26 05:59:09.367476  #> Deviance = 20154.37 | Deviance change = 5.41e-05 #> Maximum parameter change: 0.000174  #> ........................................................... #> Iteration 19     2024-11-26 05:59:09.390573  #> Deviance = 20154.37 | Deviance change = -1.07e-05 #> **** Deviances decreases! Check for nonconvergence.   **** #> Maximum parameter change: 0.000135  #> ........................................................... #> Iteration 20     2024-11-26 05:59:09.406543  #> Deviance = 20154.37 | Deviance change = -3.59e-05 #> **** Deviances decreases! Check for nonconvergence.   **** #> Maximum parameter change: 0.000104  #> ........................................................... #> Iteration 21     2024-11-26 05:59:09.422093  #> Deviance = 20154.37 | Deviance change = -4.19e-05 #> **** Deviances decreases! Check for nonconvergence.   **** #> Maximum parameter change: 8e-05  #> ----------------------------------------------------------------- #> Time difference of 0.5791824 secs  # score pre-test responses m2 <- TDCM::tdcm.score(m1, newdata = post, q.matrix = qmat1) #> [1] Scoring responses with item parameters from previously calibrated model. #> [1] Scoring complete. Check results with the CDM summary function. summary(m2) #> ----------------------------------------------------------------- #> CDM 8.2-6 (2022-08-25 15:43:23)  #>  #> Call: #> CDM::gdina(data = newdata, q.matrix = q.matrix, linkfct = \"logit\",  #>     delta.fixed = calibration.model$delta, attr.prob.fixed = dist,  #>     progress = FALSE) #>  #> Date of Analysis: 2024-11-26 05:59:09.682162  #> Time difference of 0.1281056 secs #> Computation Time: 0.1281056  #>  #> Generalized DINA Model  #>  #> Number of iterations = 8 #> Iteration with minimal deviance = 8  #>  #> Estimation method: WLS #> Optimizer: CDM #> Monotonicity constraints: FALSE #> Number of items at boundary monotonicity constraint: NA #>  #> Parameter regularization: FALSE #>  #> Deviance = 22908.45  | Log likelihood = -11454.23  #>  #> Number of persons = 1000  #> Number of groups = 1  #> Number of items = 20  #> Number of estimated parameters = 0  #> Number of estimated item parameters = 0  #> Number of estimated skill class parameters = 0 ( 16 latent skill classes) #>  #> AIC = 22908  | penalty = 0    | AIC = -2*LL + 2*p   #> BIC = 22908  | penalty = 0    | BIC = -2*LL + log(n)*p    #> CAIC = 22908  | penalty = 0    | CAIC = -2*LL + [log(n)+1]*p  (consistent AIC)    #>  #> ----------------------------------------------------------------- #> Used Q-matrix  #>  #>          Att1 Att2 Att3 Att4 #> t2item1     1    0    0    0 #> t2item2     1    0    0    0 #> t2item3     1    0    0    0 #> t2item4     1    1    0    0 #> t2item5     1    0    1    0 #> t2item6     0    1    0    0 #> t2item7     0    1    0    0 #> t2item8     0    1    0    0 #> t2item9     0    1    1    0 #> t2item10    0    1    0    1 #> t2item11    0    0    1    0 #> t2item12    0    0    1    0 #> t2item13    0    0    1    0 #> t2item14    0    0    1    1 #> t2item15    1    0    1    0 #> t2item16    0    0    0    1 #> t2item17    0    0    0    1 #> t2item18    0    0    0    1 #> t2item19    1    0    0    1 #> t2item20    0    1    0    1 #>  #> ----------------------------------------------------------------- #>  #> Item Parameter Estimates  #>  #>     link     item itemno partype  rule     est se partype.attr #> 1  logit  t2item1      1       0 GDINA -1.9297  0              #> 2  logit  t2item1      1       1 GDINA  2.6775  0         Att1 #> 3  logit  t2item2      2       0 GDINA -2.0497  0              #> 4  logit  t2item2      2       1 GDINA  2.5256  0         Att1 #> 5  logit  t2item3      3       0 GDINA -1.9963  0              #> 6  logit  t2item3      3       1 GDINA  2.5748  0         Att1 #> 7  logit  t2item4      4       0 GDINA -2.0765  0              #> 8  logit  t2item4      4       1 GDINA  1.7806  0         Att1 #> 9  logit  t2item4      4       2 GDINA  1.7157  0         Att2 #> 10 logit  t2item4      4     1-2 GDINA  0.1825  0    Att1-Att2 #> 11 logit  t2item5      5       0 GDINA -2.1097  0              #> 12 logit  t2item5      5       1 GDINA  1.6541  0         Att1 #> 13 logit  t2item5      5       2 GDINA  1.6920  0         Att3 #> 14 logit  t2item5      5     1-2 GDINA  1.0151  0    Att1-Att3 #> 15 logit  t2item6      6       0 GDINA -1.8876  0              #> 16 logit  t2item6      6       1 GDINA  2.3028  0         Att2 #> 17 logit  t2item7      7       0 GDINA -1.8652  0              #> 18 logit  t2item7      7       1 GDINA  2.3479  0         Att2 #> 19 logit  t2item8      8       0 GDINA -1.9970  0              #> 20 logit  t2item8      8       1 GDINA  2.5685  0         Att2 #> 21 logit  t2item9      9       0 GDINA -2.3755  0              #> 22 logit  t2item9      9       1 GDINA  1.8963  0         Att2 #> 23 logit  t2item9      9       2 GDINA  1.9994  0         Att3 #> 24 logit  t2item9      9     1-2 GDINA  0.7824  0    Att2-Att3 #> 25 logit t2item10     10       0 GDINA -2.0269  0              #> 26 logit t2item10     10       1 GDINA  1.7797  0         Att2 #> 27 logit t2item10     10       2 GDINA  1.3338  0         Att4 #> 28 logit t2item10     10     1-2 GDINA  0.9936  0    Att2-Att4 #> 29 logit t2item11     11       0 GDINA -1.9972  0              #> 30 logit t2item11     11       1 GDINA  2.5400  0         Att3 #> 31 logit t2item12     12       0 GDINA -2.1304  0              #> 32 logit t2item12     12       1 GDINA  2.7077  0         Att3 #> 33 logit t2item13     13       0 GDINA -1.9054  0              #> 34 logit t2item13     13       1 GDINA  2.3818  0         Att3 #> 35 logit t2item14     14       0 GDINA -1.9668  0              #> 36 logit t2item14     14       1 GDINA  1.6140  0         Att3 #> 37 logit t2item14     14       2 GDINA  1.9376  0         Att4 #> 38 logit t2item14     14     1-2 GDINA  0.9005  0    Att3-Att4 #> 39 logit t2item15     15       0 GDINA -1.9379  0              #> 40 logit t2item15     15       1 GDINA  0.7810  0         Att1 #> 41 logit t2item15     15       2 GDINA  1.4912  0         Att3 #> 42 logit t2item15     15     1-2 GDINA  1.8086  0    Att1-Att3 #> 43 logit t2item16     16       0 GDINA -2.0298  0              #> 44 logit t2item16     16       1 GDINA  2.6111  0         Att4 #> 45 logit t2item17     17       0 GDINA -2.0606  0              #> 46 logit t2item17     17       1 GDINA  2.5772  0         Att4 #> 47 logit t2item18     18       0 GDINA -2.0426  0              #> 48 logit t2item18     18       1 GDINA  2.4825  0         Att4 #> 49 logit t2item19     19       0 GDINA -2.1116  0              #> 50 logit t2item19     19       1 GDINA  2.4928  0         Att1 #> 51 logit t2item19     19       2 GDINA  1.4222  0         Att4 #> 52 logit t2item19     19     1-2 GDINA  0.4713  0    Att1-Att4 #> 53 logit t2item20     20       0 GDINA -2.1072  0              #> 54 logit t2item20     20       1 GDINA  1.7112  0         Att2 #> 55 logit t2item20     20       2 GDINA  1.7837  0         Att4 #> 56 logit t2item20     20     1-2 GDINA  0.7990  0    Att2-Att4 #>  #> RMSD (RMSEA) Item Fit Statistics #>  t2item1  t2item2  t2item3  t2item4  t2item5  t2item6  t2item7  t2item8  #>    0.043    0.046    0.043    0.072    0.041    0.050    0.036    0.048  #>  t2item9 t2item10 t2item11 t2item12 t2item13 t2item14 t2item15 t2item16  #>    0.056    0.054    0.047    0.061    0.044    0.046    0.063    0.057  #> t2item17 t2item18 t2item19 t2item20  #>    0.057    0.033    0.046    0.070  #>  #> Mean of RMSEA item fit: 0.051  #> ----------------------------------------------------------------- #> Model Implied Conditional Item Probabilities  #>  #>        item  rule nessskill itemno skillcomb   prob #> 1   t2item1 GDINA      Att1      1        A0 0.1268 #> 2   t2item1 GDINA      Att1      1        A1 0.6787 #> 3   t2item2 GDINA      Att1      2        A0 0.1141 #> 4   t2item2 GDINA      Att1      2        A1 0.6168 #> 5   t2item3 GDINA      Att1      3        A0 0.1196 #> 6   t2item3 GDINA      Att1      3        A1 0.6407 #> 7   t2item4 GDINA Att1-Att2      4       A00 0.1114 #> 8   t2item4 GDINA Att1-Att2      4       A10 0.4266 #> 9   t2item4 GDINA Att1-Att2      4       A01 0.4108 #> 10  t2item4 GDINA Att1-Att2      4       A11 0.8323 #> 11  t2item5 GDINA Att1-Att3      5       A00 0.1082 #> 12  t2item5 GDINA Att1-Att3      5       A10 0.3880 #> 13  t2item5 GDINA Att1-Att3      5       A01 0.3970 #> 14  t2item5 GDINA Att1-Att3      5       A11 0.9048 #> 15  t2item6 GDINA      Att2      6        A0 0.1315 #> 16  t2item6 GDINA      Att2      6        A1 0.6023 #> 17  t2item7 GDINA      Att2      7        A0 0.1341 #> 18  t2item7 GDINA      Att2      7        A1 0.6184 #> 19  t2item8 GDINA      Att2      8        A0 0.1195 #> 20  t2item8 GDINA      Att2      8        A1 0.6391 #> 21  t2item9 GDINA Att2-Att3      9       A00 0.0851 #> 22  t2item9 GDINA Att2-Att3      9       A10 0.3824 #> 23  t2item9 GDINA Att2-Att3      9       A01 0.4071 #> 24  t2item9 GDINA Att2-Att3      9       A11 0.9091 #> 25 t2item10 GDINA Att2-Att4     10       A00 0.1164 #> 26 t2item10 GDINA Att2-Att4     10       A10 0.4385 #> 27 t2item10 GDINA Att2-Att4     10       A01 0.3334 #> 28 t2item10 GDINA Att2-Att4     10       A11 0.8890 #> 29 t2item11 GDINA      Att3     11        A0 0.1195 #> 30 t2item11 GDINA      Att3     11        A1 0.6325 #> 31 t2item12 GDINA      Att3     12        A0 0.1062 #> 32 t2item12 GDINA      Att3     12        A1 0.6404 #> 33 t2item13 GDINA      Att3     13        A0 0.1295 #> 34 t2item13 GDINA      Att3     13        A1 0.6169 #> 35 t2item14 GDINA Att3-Att4     14       A00 0.1227 #> 36 t2item14 GDINA Att3-Att4     14       A10 0.4127 #> 37 t2item14 GDINA Att3-Att4     14       A01 0.4927 #> 38 t2item14 GDINA Att3-Att4     14       A11 0.9231 #> 39 t2item15 GDINA Att1-Att3     15       A00 0.1259 #> 40 t2item15 GDINA Att1-Att3     15       A10 0.2392 #> 41 t2item15 GDINA Att1-Att3     15       A01 0.3901 #> 42 t2item15 GDINA Att1-Att3     15       A11 0.8950 #> 43 t2item16 GDINA      Att4     16        A0 0.1161 #> 44 t2item16 GDINA      Att4     16        A1 0.6414 #> 45 t2item17 GDINA      Att4     17        A0 0.1130 #> 46 t2item17 GDINA      Att4     17        A1 0.6264 #> 47 t2item18 GDINA      Att4     18        A0 0.1148 #> 48 t2item18 GDINA      Att4     18        A1 0.6082 #> 49 t2item19 GDINA Att1-Att4     19       A00 0.1080 #> 50 t2item19 GDINA Att1-Att4     19       A10 0.5942 #> 51 t2item19 GDINA Att1-Att4     19       A01 0.3342 #> 52 t2item19 GDINA Att1-Att4     19       A11 0.9068 #> 53 t2item20 GDINA Att2-Att4     20       A00 0.1084 #> 54 t2item20 GDINA Att2-Att4     20       A10 0.4023 #> 55 t2item20 GDINA Att2-Att4     20       A01 0.4198 #> 56 t2item20 GDINA Att2-Att4     20       A11 0.8991 #> ----------------------------------------------------------------- #>  #> Skill Probabilities  #>  #>      skill.prob0 skill.prob1 #> Att1      0.6355      0.3645 #> Att2      0.5149      0.4851 #> Att3      0.4266      0.5734 #> Att4      0.3045      0.6955 #> ----------------------------------------------------------------- #>  #> Polychoric Correlations  #>  #> Group 1 #>       Att1  Att2  Att3  Att4 #> Att1 1.000 0.665 0.737 0.806 #> Att2 0.665 1.000 0.772 0.804 #> Att3 0.737 0.772 1.000 0.736 #> Att4 0.806 0.804 0.736 1.000 #>  #>  ----------------------------------------------------------------- #>  #> Skill Pattern Probabilities  #>  #>   0000   1000   0100   1100   0010   1010   0110   1110   0001   1001   0101  #> 0.2285 0.0039 0.0115 0.0004 0.0425 0.0034 0.0121 0.0022 0.1044 0.0192 0.0416  #>   1101   0011   1011   0111   1111  #> 0.0171 0.0600 0.0530 0.1349 0.2653  m2$pattern #>       pattern mle.est  mle.post map.est  map.post   post.attr1   post.attr2 #> 1    P1000001    1011 0.5800233    1011 0.9273102 9.975238e-01 0.0036526732 #> 2    P1000002    0001 0.8830593    0001 0.9513603 1.206853e-02 0.0068327385 #> 3    P1000003    0110 0.6113058    0110 0.8077001 9.931883e-02 0.9227574667 #> 4    P1000004    0111 0.8307196    0111 0.8953984 3.447166e-02 0.9276782326 #> 5    P1000005    0111 0.9764246    0111 0.9725434 2.433694e-02 0.9995328435 #> 6    P1000006    0011 0.9861910    0011 0.9843224 1.872445e-03 0.0079644997 #> 7    P1000007    0111 0.7090145    0111 0.6798221 2.787507e-01 0.9431493176 #> 8    P1000008    1111 0.8589816    1111 0.9822490 9.893411e-01 0.9952414937 #> 9    P1000009    1111 0.9356803    1111 0.9985154 9.998854e-01 0.9992534874 #> 10   P1000010    0000 0.7037961    0000 0.8874160 2.222992e-04 0.0007618127 #> 11   P1000011    1111 0.6150994    1111 0.7839747 7.850799e-01 0.9992247177 #> 12   P1000012    1111 0.5589054    1111 0.8637309 9.985388e-01 0.8651136650 #> 13   P1000013    1000 0.8224664    1000 0.4519331 5.196445e-01 0.0048621003 #> 14   P1000014    1111 0.6936189    1111 0.9648678 9.984795e-01 0.9896481104 #> 15   P1000015    0001 0.3874386    0001 0.6427624 1.147412e-01 0.0055818639 #> 16   P1000016    0111 0.9489852    0111 0.9609396 2.572259e-02 0.9938881627 #> 17   P1000017    0000 0.7071272    0000 0.9646168 2.784396e-03 0.0053638483 #> 18   P1000018    0001 0.6698376    0001 0.5482484 4.373968e-04 0.0005881116 #> 19   P1000019    0100 0.8206429    0000 0.6534609 2.616721e-03 0.3143019128 #> 20   P1000020    1000 0.5948350    1001 0.4202860 6.776710e-01 0.0044593231 #> 21   P1000021    0111 0.4928693    0111 0.7326863 2.807835e-02 0.8741515731 #> 22   P1000022    1101 0.2067289    1111 0.6479788 7.871933e-01 0.8806594958 #> 23   P1000023    0110 0.3881405    0111 0.6964324 1.961771e-04 0.9120673462 #> 24   P1000024    1001 0.5369052    1011 0.6375783 9.819577e-01 0.0495753235 #> 25   P1000025    1111 0.9207766    1111 0.9721640 9.795930e-01 0.9925652002 #> 26   P1000026    1001 0.3090640    0001 0.2805732 2.392343e-01 0.2708967595 #> 27   P1000027    1010 0.3917038    1011 0.5501199 9.977642e-01 0.3857754799 #> 28   P1000028    0000 0.7404750    0000 0.9795192 2.426153e-03 0.0081115730 #> 29   P1000029    0000 0.3871319    0000 0.6932451 1.130656e-02 0.0067814479 #> 30   P1000030    1011 0.9045111    1011 0.9631613 9.991291e-01 0.0005318727 #> 31   P1000031    0101 0.6705921    0001 0.5148790 6.237095e-04 0.4694990084 #> 32   P1000032    1111 0.9095533    1111 0.9689922 9.785792e-01 0.9903223556 #> 33   P1000033    1001 0.5201583    1011 0.5164562 7.966929e-01 0.0051280617 #> 34   P1000034    0001 0.8197198    0001 0.9086545 1.394680e-03 0.0667124181 #> 35   P1000035    0101 0.7974242    0101 0.5855905 4.773887e-04 0.8818464532 #> 36   P1000036    0001 0.4550669    0001 0.6456211 3.421182e-03 0.1971825046 #> 37   P1000037    1011 0.8462188    1011 0.7795130 8.824431e-01 0.1109052005 #> 38   P1000038    1111 0.5194904    1111 0.9821907 9.984517e-01 0.9906337179 #> 39   P1000039    0111 0.8791683    0111 0.9582230 2.030428e-03 0.9936038529 #> 40   P1000040    0000 0.5341212    0000 0.8120172 3.766749e-03 0.0045005734 #> 41   P1000041    1111 0.9558343    1111 0.9795070 9.796252e-01 0.9999284483 #> 42   P1000042    0111 0.9867752    0111 0.9929308 1.988840e-03 0.9951579130 #> 43   P1000043    0001 0.6123087    0001 0.7390355 9.926198e-03 0.0004642245 #> 44   P1000044    1111 0.9880389    1111 0.9977029 9.985005e-01 0.9992542417 #> 45   P1000045    0100 0.6139029    0000 0.8254823 2.304299e-04 0.0893444327 #> 46   P1000046    0111 0.5609798    0111 0.7811489 2.218865e-04 0.9248613625 #> 47   P1000047    0000 0.7564130    0000 0.9631910 2.538522e-03 0.0046865228 #> 48   P1000048    1111 0.8787881    1111 0.9866510 9.998847e-01 0.9886800546 #> 49   P1000049    0011 0.5686638    0011 0.6250558 3.339451e-01 0.0005435631 #> 50   P1000050    0111 0.9079805    0111 0.8574363 1.405981e-01 0.9989306440 #> 51   P1000051    0000 0.6455779    0000 0.8854350 2.230088e-04 0.0079031985 #> 52   P1000052    1011 0.9696934    1011 0.9779193 9.895581e-01 0.0085073295 #> 53   P1000053    1010 0.7086789    1010 0.3313809 4.493923e-01 0.0116166825 #> 54   P1000054    0000 0.7076834    0000 0.9494582 2.473703e-03 0.0007892748 #> 55   P1000055    1101 0.6860033    1111 0.6556152 9.974786e-01 0.8951631328 #> 56   P1000056    0100 0.5996766    0000 0.8633862 1.881717e-04 0.0934481560 #> 57   P1000057    0000 0.7196887    0000 0.9649956 2.392756e-03 0.0053639686 #> 58   P1000058    1111 0.9107245    1111 0.9955140 9.984903e-01 0.9992841135 #> 59   P1000059    1101 0.6964412    1101 0.5026880 5.136198e-01 0.9850834279 #> 60   P1000060    1111 0.9626305    1111 0.9977491 9.998850e-01 0.9999284378 #> 61   P1000061    1111 0.9383276    1111 0.9992793 9.998854e-01 0.9999286189 #> 62   P1000062    0111 0.6566488    0111 0.8613462 2.972672e-03 0.9994209778 #> 63   P1000063    1000 0.7511365    0000 0.7284580 1.602550e-01 0.0059316614 #> 64   P1000064    0100 0.4997518    0000 0.9357214 1.163621e-03 0.0536702654 #> 65   P1000065    0110 0.5622125    0111 0.7261246 1.273175e-03 0.9981951694 #> 66   P1000066    0011 0.6850907    0011 0.5932037 3.193076e-02 0.0079820312 #> 67   P1000067    0111 0.8681976    0111 0.8312356 1.569196e-01 0.9893904577 #> 68   P1000068    0111 0.8815385    0111 0.9853823 1.996057e-03 0.9995227173 #> 69   P1000069    0010 0.5932104    0010 0.6557729 1.154851e-03 0.1084426475 #> 70   P1000070    0010 0.6257434    0000 0.6995814 1.596018e-04 0.0050420493 #> 71   P1000071    0101 0.9197252    0101 0.9266947 7.528226e-03 0.9832617596 #> 72   P1000072    1111 0.8701798    1111 0.9876394 9.998845e-01 0.9903133855 #> 73   P1000073    0111 0.9132479    0111 0.9554947 1.961220e-02 0.9889472419 #> 74   P1000074    0011 0.2930205    0001 0.4757700 1.656108e-01 0.0005075857 #> 75   P1000075    0010 0.8531769    0010 0.9500260 8.692797e-03 0.0141811405 #> 76   P1000076    0000 0.8251566    0000 0.9511244 2.102665e-04 0.0043608353 #> 77   P1000077    1011 0.9411103    1011 0.9773236 9.883909e-01 0.0077713839 #> 78   P1000078    1111 0.6000723    1111 0.8146894 8.654684e-01 0.9416816952 #> 79   P1000079    0111 0.7797602    0111 0.8106947 1.588003e-01 0.9884462418 #> 80   P1000080    1101 0.5118664    0101 0.4598907 4.343189e-01 0.8642551148 #> 81   P1000081    0000 0.8086928    0000 0.9576152 1.897796e-04 0.0007880088 #> 82   P1000082    0000 0.7157829    0000 0.9648792 2.513093e-03 0.0053639317 #> 83   P1000083    0101 0.8791798    0101 0.7356997 6.604933e-03 0.9918325164 #> 84   P1000084    1101 0.6182194    1101 0.4948310 5.924706e-01 0.8468987984 #> 85   P1000085    0000 0.9446598    0000 0.9889664 1.946025e-04 0.0007810027 #> 86   P1000086    0001 0.3825181    0001 0.6404541 1.128207e-01 0.0551103119 #> 87   P1000087    0010 0.3448259    0000 0.7032209 2.045994e-03 0.0691865814 #> 88   P1000088    0111 0.6783560    0111 0.7069089 2.760777e-01 0.9942025619 #> 89   P1000089    1111 0.6609023    1111 0.9917555 9.977598e-01 0.9992789335 #> 90   P1000090    0111 0.5980379    0111 0.7365720 1.535798e-01 0.8866217631 #> 91   P1000091    0000 0.3337445    0000 0.6852738 3.174580e-04 0.0521221970 #> 92   P1000092    0100 0.6139029    0000 0.8254823 2.304299e-04 0.0893444327 #> 93   P1000093    0001 0.7107614    0001 0.7891434 1.654863e-02 0.0047507864 #> 94   P1000094    1001 0.6392987    1001 0.6274362 9.260641e-01 0.3163969788 #> 95   P1000095    1111 0.9677487    1111 0.9976654 9.998852e-01 0.9992854381 #> 96   P1000096    1111 0.5710844    1111 0.8170288 8.708068e-01 0.9390397828 #> 97   P1000097    1111 0.8918169    1111 0.9779812 9.795667e-01 0.9991196027 #> 98   P1000098    0111 0.8979279    0111 0.8391443 1.588496e-01 0.9989335109 #> 99   P1000099    1011 0.9516766    1011 0.8789348 9.900845e-01 0.1111189330 #> 100  P1000100    0001 0.9630882    0001 0.9373699 6.175536e-04 0.0004492159 #> 101  P1000101    0000 0.4291364    0000 0.6938723 5.124408e-03 0.0046754869 #> 102  P1000102    1001 0.5276242    1011 0.6174717 9.791130e-01 0.0770363704 #> 103  P1000103    1111 0.7578191    1111 0.8696772 8.753397e-01 0.9938448256 #> 104  P1000104    0111 0.7755154    0111 0.6687559 3.257375e-01 0.9938989187 #> 105  P1000105    1111 0.9304339    1111 0.9774260 9.795184e-01 0.9999281715 #> 106  P1000106    1111 0.5783130    1111 0.9350518 9.806602e-01 0.9920556991 #> 107  P1000107    0010 0.4454506    0000 0.8239139 9.526390e-04 0.0084758753 #> 108  P1000108    1101 0.8988121    1111 0.6208088 9.987054e-01 0.9984381577 #> 109  P1000109    0111 0.8741429    0111 0.7835505 2.156412e-01 0.9991908789 #> 110  P1000110    0111 0.6263825    0111 0.8413628 2.412141e-02 0.9460018055 #> 111  P1000111    1111 0.9617826    1111 0.9923585 9.998855e-01 0.9925919199 #> 112  P1000112    1011 0.5777339    1011 0.9254427 9.989876e-01 0.0071175761 #> 113  P1000113    0000 0.9446598    0000 0.9889664 1.946025e-04 0.0007810027 #> 114  P1000114    0001 0.6665443    0001 0.7504887 3.148200e-03 0.0210281608 #> 115  P1000115    1111 0.9907027    1111 0.9974859 9.983381e-01 0.9992870214 #> 116  P1000116    0001 0.7033548    0001 0.7559912 5.276707e-04 0.0038763604 #> 117  P1000117    1011 0.9749460    1011 0.9366097 9.896354e-01 0.0531552127 #> 118  P1000118    0111 0.9246313    0111 0.9711270 1.034364e-03 0.9873671579 #> 119  P1000119    0111 0.7397078    0111 0.7160983 2.466879e-01 0.9530954999 #> 120  P1000120    0000 0.4813957    0000 0.9407560 1.373147e-02 0.0047023675 #> 121  P1000121    0000 0.8231523    0000 0.9863656 2.823893e-03 0.0007809383 #> 122  P1000122    0000 0.7177556    0000 0.9505268 1.897262e-04 0.0081843687 #> 123  P1000123    1111 0.5561821    1111 0.7533809 7.578010e-01 0.9990804427 #> 124  P1000124    1111 0.9478177    1111 0.9983402 9.998854e-01 0.9988595986 #> 125  P1000125    0000 0.8276129    0000 0.9624613 1.905251e-04 0.0007869258 #> 126  P1000126    0010 0.9201620    0010 0.7998875 7.484148e-05 0.0009444170 #> 127  P1000127    0000 0.3374194    0000 0.8532204 1.975463e-02 0.0265645837 #> 128  P1000128    1111 0.6061049    1111 0.8899254 9.791534e-01 0.9106238696 #> 129  P1000129    0000 0.5912990    0000 0.9442886 1.213012e-03 0.0255203332 #> 130  P1000130    1111 0.4985667    1111 0.9280110 9.816593e-01 0.9987474844 #> 131  P1000131    1111 0.8618244    1111 0.9694439 9.795414e-01 0.9903118602 #> 132  P1000132    0111 0.3745413    0111 0.7309041 4.848891e-02 0.9285242910 #> 133  P1000133    0111 0.8295854    0111 0.9243113 1.459600e-04 0.9387618331 #> 134  P1000134    0000 0.6654859    0000 0.8988184 4.997956e-04 0.0097864710 #> 135  P1000135    0000 0.6767300    0000 0.8750460 2.244602e-04 0.0007605206 #> 136  P1000136    0011 0.8613568    0011 0.7923109 4.690546e-03 0.0005245858 #> 137  P1000137    0000 0.9446598    0000 0.9889664 1.946025e-04 0.0007810027 #> 138  P1000138    1111 0.6394065    1111 0.9073427 9.977427e-01 0.9109838745 #> 139  P1000139    1111 0.9392987    1111 0.9968602 9.985693e-01 0.9988590677 #> 140  P1000140    0000 0.7239921    0000 0.9341995 3.066451e-03 0.0007685067 #> 141  P1000141    0000 0.7298088    0000 0.9555302 2.366700e-03 0.0007879436 #> 142  P1000142    0001 0.8954345    0001 0.9343697 1.188545e-02 0.0067070573 #> 143  P1000143    1100 0.7515131    1101 0.8409801 9.248510e-01 0.9838215660 #> 144  P1000144    0000 0.5339164    0000 0.8379403 5.097154e-04 0.0057581848 #> 145  P1000145    0000 0.5202052    0000 0.9424029 1.343257e-02 0.0007750275 #> 146  P1000146    0000 0.6487984    0000 0.8857440 2.230163e-04 0.0075569310 #> 147  P1000147    1111 0.9396613    1111 0.9896707 9.985652e-01 0.9925719541 #> 148  P1000148    1111 0.9282013    1111 0.9884698 9.998849e-01 0.9903300168 #> 149  P1000149    1111 0.5025630    1111 0.9886051 9.985190e-01 0.9991174342 #> 150  P1000150    0100 0.6510990    0000 0.6006153 1.822687e-03 0.2029620187 #> 151  P1000151    1111 0.5875859    1111 0.8770516 9.781923e-01 0.8968629023 #> 152  P1000152    1111 0.9683100    1111 0.9976063 9.998852e-01 0.9992524283 #> 153  P1000153    1011 0.7520718    1111 0.5995991 9.895068e-01 0.6061355650 #> 154  P1000154    1111 0.6698001    1111 0.9645700 9.685229e-01 0.9992775864 #> 155  P1000155    0001 0.6223080    0001 0.5301462 5.650187e-03 0.0040397296 #> 156  P1000156    0011 0.4716154    0011 0.3987922 2.536412e-02 0.0075166960 #> 157  P1000157    1111 0.9068082    1111 0.9952842 9.985615e-01 0.9992837331 #> 158  P1000158    0000 0.8086928    0000 0.9576152 1.897796e-04 0.0007880088 #> 159  P1000159    1111 0.9945934    1111 0.9989423 9.998856e-01 0.9990706252 #> 160  P1000160    1111 0.7382745    1111 0.9770613 9.998789e-01 0.9990339636 #> 161  P1000161    1111 0.5588867    1111 0.8305400 8.529175e-01 0.9995029527 #> 162  P1000162    1111 0.8742084    1111 0.9736066 9.815112e-01 0.9925589922 #> 163  P1000163    0100 0.5524161    0100 0.4314409 3.557549e-02 0.7740401860 #> 164  P1000164    0110 0.4242654    0111 0.6265374 1.416421e-03 0.8462209827 #> 165  P1000165    0101 0.9579306    0101 0.9780348 6.249255e-04 0.9911963345 #> 166  P1000166    0010 0.8165033    0010 0.8571002 9.043330e-03 0.0134417532 #> 167  P1000167    0000 0.3471208    0000 0.8576346 5.791717e-03 0.0331119525 #> 168  P1000168    0000 0.8269521    0000 0.9817105 1.945577e-04 0.0081121367 #> 169  P1000169    0001 0.4376893    0001 0.7137357 1.351374e-01 0.0004814757 #> 170  P1000170    0000 0.7520820    0000 0.9630677 2.666170e-03 0.0046865245 #> 171  P1000171    1000 0.8887600    0000 0.8249494 1.556511e-01 0.0007797704 #> 172  P1000172    1111 0.9277766    1111 0.9741175 9.815512e-01 0.9925679912 #> 173  P1000173    0000 0.6422058    0000 0.8999021 3.024839e-03 0.0074715306 #> 174  P1000174    0001 0.8474514    0001 0.9574146 2.662500e-02 0.0052464367 #> 175  P1000175    0111 0.5237299    0111 0.7387706 1.497880e-03 0.8567218465 #> 176  P1000176    0000 0.4183694    0000 0.7993072 3.302296e-03 0.0331707597 #> 177  P1000177    0101 0.7438704    0101 0.5737162 4.709868e-04 0.8776976613 #> 178  P1000178    1111 0.9340629    1111 0.9976229 9.983346e-01 0.9999285853 #> 179  P1000179    1111 0.4044636    1111 0.7667005 7.806830e-01 0.9882114927 #> 180  P1000180    1101 0.9237264    1101 0.5038911 9.870427e-01 0.9882213684 #> 181  P1000181    0000 0.8452275    0000 0.9654457 2.035898e-04 0.0046864904 #> 182  P1000182    0111 0.7732055    0111 0.9272584 1.971379e-03 0.9412414232 #> 183  P1000183    0111 0.9778627    0111 0.9661352 3.246466e-02 0.9995341738 #> 184  P1000184    0000 0.8452275    0000 0.9654457 2.035898e-04 0.0046864904 #> 185  P1000185    1000 0.6341648    1001 0.5885376 9.109320e-01 0.0040829444 #> 186  P1000186    1111 0.9087151    1111 0.9643340 9.716862e-01 0.9925554787 #> 187  P1000187    1111 0.9869690    1111 0.9980711 9.984785e-01 0.9999286434 #> 188  P1000188    0110 0.8272102    0110 0.5643191 6.843763e-04 0.5943078746 #> 189  P1000189    0101 0.8893685    0101 0.8407275 4.326247e-03 0.8564909972 #> 190  P1000190    1111 0.9853533    1111 0.9972339 9.983378e-01 0.9990700883 #> 191  P1000191    0000 0.3088114    0000 0.6812124 3.045700e-02 0.0037584954 #> 192  P1000192    0111 0.8582235    0111 0.9400262 1.443935e-04 0.9525509507 #> 193  P1000193    0011 0.4415670    0011 0.5556697 2.885290e-01 0.0005983877 #> 194  P1000194    1101 0.8235563    1111 0.7299259 9.746315e-01 0.9998957257 #> 195  P1000195    1111 0.3975133    1111 0.9023539 9.984213e-01 0.9099940540 #> 196  P1000196    0011 0.8060756    0011 0.8503734 1.695007e-03 0.0065416118 #> 197  P1000197    0100 0.6192455    0000 0.8520671 2.100176e-04 0.0912210787 #> 198  P1000198    0010 0.7296025    0000 0.6463136 1.418908e-04 0.0008575755 #> 199  P1000199    0001 0.6123087    0001 0.7390355 9.926198e-03 0.0004642245 #> 200  P1000200    0001 0.6182961    0001 0.7289854 2.933582e-03 0.0647243122 #> 201  P1000201    1111 0.9461240    1111 0.9900387 9.998854e-01 0.9903566799 #> 202  P1000202    1010 0.6770052    1011 0.7766973 9.600570e-01 0.0512907463 #> 203  P1000203    0001 0.3571427    0000 0.5947093 4.716687e-03 0.0447868752 #> 204  P1000204    0000 0.3919421    0000 0.7013253 1.888119e-03 0.0284075590 #> 205  P1000205    1011 0.6349466    1111 0.4380487 8.759600e-01 0.5123575804 #> 206  P1000206    1011 0.7894226    1011 0.5888679 9.700650e-01 0.3895093407 #> 207  P1000207    0001 0.7657022    0001 0.7922282 1.320534e-03 0.0052516944 #> 208  P1000208    0001 0.6440514    0001 0.7649792 1.017994e-02 0.0004610180 #> 209  P1000209    1110 0.8495267    1111 0.8044054 9.974256e-01 0.9116042402 #> 210  P1000210    0111 0.9563125    0111 0.9846968 2.779917e-03 0.9995251237 #> 211  P1000211    0001 0.6301059    0001 0.5259294 5.620907e-03 0.0032976300 #> 212  P1000212    0111 0.9518519    0111 0.9731712 1.289584e-02 0.9891635666 #> 213  P1000213    1001 0.7873225    1001 0.6201436 6.417732e-01 0.0004485414 #> 214  P1000214    0010 0.5354309    0011 0.5013722 1.238560e-03 0.0007531141 #> 215  P1000215    0101 0.9410067    0101 0.9455671 1.175421e-02 0.9913516466 #> 216  P1000216    0011 0.6520825    0011 0.7126675 2.318196e-02 0.1075302791 #> 217  P1000217    0111 0.9467866    0111 0.9621875 2.574718e-02 0.9938995218 #> 218  P1000218    1111 0.8586864    1111 0.9870954 9.984877e-01 0.9907406492 #> 219  P1000219    0011 0.8063998    0011 0.7833506 2.269121e-02 0.0005621206 #> 220  P1000220    0000 0.6606461    0000 0.9327402 2.600331e-03 0.0047271823 #> 221  P1000221    1111 0.9484729    1111 0.9901934 9.998854e-01 0.9903593339 #> 222  P1000222    0100 0.5073351    0100 0.3510308 1.817275e-03 0.9968454453 #> 223  P1000223    0000 0.7173790    0000 0.9775618 2.426003e-03 0.0100937286 #> 224  P1000224    0100 0.7148717    0000 0.6479874 3.371832e-03 0.2601550903 #> 225  P1000225    0110 0.3314963    0111 0.6167035 1.739497e-02 0.8002882276 #> 226  P1000226    1111 0.9480044    1111 0.9776765 9.786084e-01 0.9992514588 #> 227  P1000227    1111 0.9348567    1111 0.9893980 9.983298e-01 0.9925709753 #> 228  P1000228    1111 0.9853883    1111 0.9974198 9.983377e-01 0.9992869224 #> 229  P1000229    0001 0.8715819    0001 0.9273687 1.180637e-02 0.0052432559 #> 230  P1000230    1111 0.3873501    1111 0.6370096 6.992664e-01 0.9070635696 #> 231  P1000231    1111 0.8895560    1111 0.9875257 9.984941e-01 0.9897044475 #> 232  P1000232    0100 0.7742262    0100 0.5359309 2.505587e-03 0.9589113226 #> 233  P1000233    0010 0.9146494    0010 0.8850326 3.276478e-04 0.0053217492 #> 234  P1000234    0010 0.3393597    0000 0.6119649 2.534415e-04 0.0048121657 #> 235  P1000235    0001 0.4712906    0001 0.7982539 1.386898e-01 0.0501676740 #> 236  P1000236    1111 0.6129345    1111 0.8222567 8.648972e-01 0.9525052235 #> 237  P1000237    0011 0.9380560    0011 0.8824203 2.911947e-03 0.0972329149 #> 238  P1000238    0011 0.5689943    0111 0.5900644 3.471376e-02 0.6113714183 #> 239  P1000239    0000 0.6323509    0000 0.9132869 2.672583e-03 0.0044058841 #> 240  P1000240    0001 0.5302375    0001 0.6787155 3.909925e-02 0.0066835299 #> 241  P1000241    0001 0.9250851    0001 0.9385661 6.196377e-04 0.0067805485 #> 242  P1000242    0010 0.3489757    0000 0.6785858 1.246647e-03 0.0340730158 #> 243  P1000243    0111 0.8402894    0111 0.7737484 2.156722e-01 0.9894939854 #> 244  P1000244    0000 0.8276129    0000 0.9624613 1.905251e-04 0.0007869258 #> 245  P1000245    1111 0.9447071    1111 0.9887666 9.985697e-01 0.9903550524 #> 246  P1000246    0001 0.7218124    0001 0.8269952 1.129592e-02 0.0628479180 #> 247  P1000247    0000 0.8231523    0000 0.9863656 2.823893e-03 0.0007809383 #> 248  P1000248    0000 0.7087825    0000 0.9032429 3.043109e-03 0.0007511022 #> 249  P1000249    1111 0.9246228    1111 0.9723473 9.797673e-01 0.9925658431 #> 250  P1000250    1011 0.5152078    1011 0.6369781 6.893000e-01 0.0489446307 #> 251  P1000251    0100 0.8355148    0100 0.6221692 1.769646e-03 0.9790105031 #> 252  P1000252    1111 0.5497668    1111 0.8032626 8.652542e-01 0.9291700761 #> 253  P1000253    0000 0.7967652    0000 0.9085349 2.312047e-04 0.0007522899 #> 254  P1000254    0000 0.4550361    0000 0.9193783 1.544351e-02 0.0042668935 #> 255  P1000255    1011 0.8610741    1011 0.8042292 8.676507e-01 0.0726633815 #> 256  P1000256    0111 0.8745910    0111 0.9827785 1.374553e-04 0.9950284769 #> 257  P1000257    1000 0.5487576    0000 0.7368861 8.427509e-02 0.0045484467 #> 258  P1000258    1001 0.6954877    1001 0.5743365 6.147754e-01 0.0004710624 #> 259  P1000259    0011 0.9280517    0011 0.8845931 2.636975e-02 0.0894794593 #> 260  P1000260    1111 0.9011921    1111 0.9778694 9.785697e-01 0.9999283330 #> 261  P1000261    0001 0.5006955    0000 0.6067048 2.125850e-03 0.0036068534 #> 262  P1000262    0000 0.3573391    0000 0.8553005 5.689836e-03 0.0348151179 #> 263  P1000263    0110 0.6083840    0111 0.8373183 2.556629e-02 0.9921740917 #> 264  P1000264    0101 0.4752703    0101 0.4474485 1.388830e-01 0.5217401750 #> 265  P1000265    1000 0.3669077    0000 0.6306530 1.026253e-01 0.0445686897 #> 266  P1000266    1111 0.9527599    1111 0.9799878 9.803879e-01 0.9999284208 #> 267  P1000267    0010 0.8507816    0010 0.6134072 1.043700e-04 0.0009005982 #> 268  P1000268    0010 0.7019019    0010 0.6971961 1.187239e-03 0.0649456698 #> 269  P1000269    0111 0.9371838    0111 0.9577650 3.433844e-02 0.9951215365 #> 270  P1000270    0100 0.7710537    0000 0.7673393 1.293397e-03 0.1959142854 #> 271  P1000271    0011 0.8878955    0011 0.8523379 1.927215e-03 0.0949427022 #> 272  P1000272    0111 0.7269070    0111 0.7550078 2.192253e-01 0.9999137314 #> 273  P1000273    0100 0.5523209    0000 0.8929535 2.593567e-03 0.0748920503 #> 274  P1000274    0011 0.6946637    0011 0.5991639 2.068287e-02 0.0061445428 #> 275  P1000275    1011 0.7297066    1111 0.5994849 9.899726e-01 0.6059248391 #> 276  P1000276    0100 0.6553613    0000 0.7466438 6.707108e-03 0.2038336117 #> 277  P1000277    0010 0.4945276    0000 0.7259478 1.910596e-04 0.0068697429 #> 278  P1000278    1111 0.7214904    1111 0.9325571 9.991831e-01 0.9351341507 #> 279  P1000279    0111 0.8777847    0111 0.9274690 2.585952e-02 0.9534576706 #> 280  P1000280    0001 0.7914144    0001 0.8948646 6.300970e-04 0.0779841016 #> 281  P1000281    1111 0.9873075    1111 0.9987495 9.998856e-01 0.9990702843 #> 282  P1000282    0000 0.7362555    0000 0.9793994 2.548166e-03 0.0081115422 #> 283  P1000283    1111 0.6533609    1111 0.9140622 9.985487e-01 0.9158479387 #> 284  P1000284    0101 0.9565078    0101 0.9742048 1.203038e-02 0.9913375044 #> 285  P1000285    0000 0.5969852    0000 0.8373771 3.860733e-03 0.0044641536 #> 286  P1000286    0011 0.9064117    0011 0.8986345 3.432049e-02 0.0005485579 #> 287  P1000287    0111 0.9335231    0111 0.9767957 1.016863e-03 0.9889882304 #> 288  P1000288    0100 0.2514025    0001 0.5005536 5.467858e-02 0.2265583820 #> 289  P1000289    1111 0.9457968    1111 0.9888181 9.984981e-01 0.9903570164 #> 290  P1000290    0111 0.9671094    0111 0.9708530 2.357056e-02 0.9953598577 #> 291  P1000291    0011 0.8161052    0011 0.7910314 3.822693e-02 0.0854899572 #> 292  P1000292    1111 0.9125027    1111 0.9864449 9.998848e-01 0.9886385802 #> 293  P1000293    1111 0.9533966    1111 0.9779535 9.783144e-01 0.9999284024 #> 294  P1000294    1111 0.9885244    1111 0.9980604 9.983379e-01 0.9999286582 #> 295  P1000295    0101 0.4933536    0101 0.4045377 7.777844e-03 0.4642765574 #> 296  P1000296    0001 0.8326426    0001 0.8289110 1.079411e-02 0.0062593171 #> 297  P1000297    1111 0.5946416    1111 0.8815811 9.781988e-01 0.9015210639 #> 298  P1000298    0001 0.9509841    0001 0.9664963 6.297051e-04 0.0004337779 #> 299  P1000299    0011 0.4819161    0111 0.4629757 2.346512e-04 0.5249871124 #> 300  P1000300    1111 0.8493984    1111 0.9684475 9.814371e-01 0.9886427220 #> 301  P1000301    1111 0.9338339    1111 0.9906662 9.998849e-01 0.9925694439 #> 302  P1000302    0111 0.8722298    0111 0.9814869 1.821410e-03 0.9950311449 #> 303  P1000303    0101 0.5285803    0001 0.6112069 7.680788e-03 0.3559823605 #> 304  P1000304    0000 0.7139976    0000 0.9574924 2.606438e-03 0.0080291650 #> 305  P1000305    1111 0.6233375    1111 0.9384102 9.686893e-01 0.9990137214 #> 306  P1000306    1111 0.5225925    1111 0.9838399 9.982998e-01 0.9924734881 #> 307  P1000307    0111 0.8889459    0111 0.9371845 3.417397e-02 0.9995107361 #> 308  P1000308    1111 0.5707935    1111 0.9785235 9.984617e-01 0.9853043075 #> 309  P1000309    0000 0.7806618    0000 0.9418818 4.617046e-04 0.0043722734 #> 310  P1000310    1011 0.7426382    1011 0.9605862 9.839725e-01 0.0005452047 #> 311  P1000311    1111 0.4845079    1111 0.7436111 7.675830e-01 0.9900107459 #> 312  P1000312    0000 0.7806618    0000 0.9418818 4.617046e-04 0.0043722734 #> 313  P1000313    0000 0.7259281    0000 0.9554162 2.485729e-03 0.0007879400 #> 314  P1000314    0000 0.9446598    0000 0.9889664 1.946025e-04 0.0007810027 #> 315  P1000315    0000 0.8231523    0000 0.9863656 2.823893e-03 0.0007809383 #> 316  P1000316    0001 0.5318451    0001 0.7421742 5.848535e-02 0.0025352506 #> 317  P1000317    0111 0.7694450    0111 0.8299710 1.495469e-01 0.9891625221 #> 318  P1000318    0101 0.9443761    0101 0.8710020 6.174970e-04 0.8988012450 #> 319  P1000319    0111 0.8512125    0111 0.9746221 1.016603e-03 0.9988578123 #> 320  P1000320    0101 0.9406908    0101 0.9633159 4.417267e-03 0.9810618819 #> 321  P1000321    0001 0.9072195    0001 0.8798235 5.902406e-04 0.0004653694 #> 322  P1000322    0000 0.4915753    0000 0.8983252 5.714426e-03 0.0059610538 #> 323  P1000323    1111 0.9857159    1111 0.9975504 9.984998e-01 0.9992540361 #> 324  P1000324    0000 0.4162157    0000 0.8616447 6.397326e-03 0.0083766905 #> 325  P1000325    1101 0.7999039    1111 0.7266539 9.974392e-01 0.9856302867 #> 326  P1000326    1011 0.6476408    1111 0.4726258 8.547718e-01 0.5553127417 #> 327  P1000327    1001 0.8053063    1001 0.5516809 6.787704e-01 0.0423227983 #> 328  P1000328    1111 0.9259359    1111 0.9773826 9.795148e-01 0.9999281641 #> 329  P1000329    1000 0.4228907    0000 0.5328094 1.450564e-01 0.0006871652 #> 330  P1000330    1001 0.8297843    1001 0.8171242 9.180829e-01 0.0427213745 #> 331  P1000331    1111 0.5354908    1111 0.9905935 9.982880e-01 0.9992757951 #> 332  P1000332    1111 0.9238683    1111 0.9875935 9.984911e-01 0.9908699911 #> 333  P1000333    0100 0.6538318    0000 0.4094608 3.500603e-04 0.3307027870 #> 334  P1000334    0000 0.8086928    0000 0.9576152 1.897796e-04 0.0007880088 #> 335  P1000335    1111 0.6548238    1111 0.9002844 9.899403e-01 0.9095887634 #> 336  P1000336    1111 0.9246546    1111 0.9968550 9.984964e-01 0.9990689666 #> 337  P1000337    0111 0.9548391    0111 0.9678945 2.355034e-02 0.9951213097 #> 338  P1000338    1111 0.6118862    1111 0.7838909 7.850308e-01 0.9992586755 #> 339  P1000339    0000 0.4259047    0000 0.9170537 1.793287e-02 0.0042681132 #> 340  P1000340    1111 0.5180196    1111 0.9849869 9.991582e-01 0.9941427237 #> 341  P1000341    0011 0.5079747    0001 0.5026441 2.087542e-02 0.0759469424 #> 342  P1000342    1111 0.9552735    1111 0.9910176 9.985703e-01 0.9925896531 #> 343  P1000343    1010 0.4842563    0010 0.7887770 9.465203e-02 0.0134233331 #> 344  P1000344    0011 0.9273439    0011 0.8862670 2.623249e-02 0.0808149725 #> 345  P1000345    1101 0.4311584    1111 0.2788322 8.967398e-01 0.5523531228 #> 346  P1000346    1000 0.4188577    1001 0.4358261 8.280360e-01 0.0472622396 #> 347  P1000347    0000 0.9446598    0000 0.9889664 1.946025e-04 0.0007810027 #> 348  P1000348    1101 0.5429531    0111 0.5460320 3.170614e-01 0.9870489685 #> 349  P1000349    0001 0.8184578    0001 0.9105848 6.315086e-04 0.0644845628 #> 350  P1000350    1111 0.8991271    1111 0.9801143 9.815348e-01 0.9991201682 #> 351  P1000351    0000 0.7310853    0000 0.9794801 2.823276e-03 0.0077561512 #> 352  P1000352    1111 0.7047755    1111 0.8558402 8.650302e-01 0.9938051141 #> 353  P1000353    1011 0.9449561    1011 0.9861688 9.900166e-01 0.0005374822 #> 354  P1000354    1011 0.8882347    1011 0.9472357 9.981907e-01 0.0421055761 #> 355  P1000355    0000 0.8269521    0000 0.9817105 1.945577e-04 0.0081121367 #> 356  P1000356    1111 0.8819604    1111 0.9656104 9.685782e-01 0.9992469495 #> 357  P1000357    1111 0.6594082    1111 0.9382017 9.669020e-01 0.9922263303 #> 358  P1000358    1111 0.6729843    1111 0.9682743 9.983358e-01 0.9992147738 #> 359  P1000359    0011 0.6045246    0011 0.4863179 1.375893e-01 0.3755174730 #> 360  P1000360    0110 0.4584523    0111 0.6160927 2.085564e-01 0.9388824296 #> 361  P1000361    0000 0.6203055    0000 0.8767583 2.262090e-04 0.0098014974 #> 362  P1000362    1111 0.9866504    1111 0.9973559 9.983383e-01 0.9990702910 #> 363  P1000363    0110 0.5669499    0110 0.2576075 2.158786e-03 0.5312591147 #> 364  P1000364    1111 0.9344688    1111 0.9984208 9.998854e-01 0.9990695225 #> 365  P1000365    0011 0.6097516    0011 0.5582172 2.569384e-02 0.2730056247 #> 366  P1000366    1111 0.5683797    1111 0.9428394 9.815530e-01 0.9999233972 #> 367  P1000367    1111 0.9895321    1111 0.9982679 9.985002e-01 0.9999286661 #> 368  P1000368    1110 0.6107655    1111 0.6077566 7.160047e-01 0.9987953055 #> 369  P1000369    1111 0.5980310    1111 0.7817350 7.842977e-01 0.9990284516 #> 370  P1000370    1111 0.6472462    1111 0.9521156 9.785651e-01 0.9992156253 #> 371  P1000371    0000 0.9446598    0000 0.9889664 1.946025e-04 0.0007810027 #> 372  P1000372    1101 0.6793740    1111 0.5643461 7.544820e-01 0.9985650374 #> 373  P1000373    1111 0.6696947    1111 0.9567631 9.784198e-01 0.9999253749 #> 374  P1000374    0010 0.9309828    0010 0.9492144 3.318318e-03 0.0055037110 #> 375  P1000375    0100 0.8573814    0100 0.6802209 2.934590e-03 0.7596759272 #> 376  P1000376    0111 0.9965475    0111 0.9972983 1.988632e-03 0.9995352088 #> 377  P1000377    0011 0.5683708    0111 0.5981157 1.493817e-04 0.6061057349 #> 378  P1000378    0110 0.5263055    0010 0.2380430 1.458343e-04 0.4038446956 #> 379  P1000379    0000 0.7997533    0000 0.9797485 1.945456e-04 0.0100944287 #> 380  P1000380    1111 0.4127405    1111 0.8620496 9.984861e-01 0.9046500098 #> 381  P1000381    0111 0.9460207    0111 0.9742667 1.460976e-02 0.9999148115 #> 382  P1000382    1111 0.3479992    1111 0.6705396 7.553652e-01 0.9041277763 #> 383  P1000383    1010 0.5303125    0010 0.8120831 1.079705e-01 0.0137887591 #> 384  P1000384    1111 0.5243604    1111 0.9894800 9.984470e-01 0.9999272886 #> 385  P1000385    1111 0.6353933    1111 0.9067459 9.977387e-01 0.9109013756 #> 386  P1000386    1111 0.8480237    1111 0.9662795 9.794586e-01 0.9886330230 #> 387  P1000387    1110 0.7734565    0110 0.3297190 5.345330e-01 0.9815733301 #> 388  P1000388    1111 0.3953324    1111 0.6591946 6.802834e-01 0.9989602610 #> 389  P1000389    0111 0.6891420    0111 0.8798643 1.391559e-03 0.9989385565 #> 390  P1000390    0111 0.9625629    0111 0.9763647 1.396522e-02 0.9913253152 #> 391  P1000391    0001 0.7909993    0001 0.8808041 1.375642e-03 0.0760915049 #> 392  P1000392    1111 0.6735280    1111 0.9689584 9.984832e-01 0.9922949491 #> 393  P1000393    0000 0.7992719    0000 0.9671246 1.918736e-04 0.0053646444 #> 394  P1000394    1001 0.5098394    1001 0.5395887 9.846567e-01 0.3985091048 #> 395  P1000395    0010 0.4487402    0000 0.3354431 1.310218e-03 0.0647763878 #> 396  P1000396    0111 0.9002823    0111 0.9477087 3.507717e-02 0.9952425780 #> 397  P1000397    1011 0.7423292    1011 0.7480682 8.689883e-01 0.0839798596 #> 398  P1000398    1111 0.6683707    1111 0.9742085 9.998776e-01 0.9999253797 #> 399  P1000399    1101 0.5599750    1111 0.7650501 9.976508e-01 0.9869890442 #> 400  P1000400    1110 0.9333607    1111 0.8912429 9.979080e-01 0.9990783161 #> 401  P1000401    1111 0.9463583    1111 0.9891329 9.984978e-01 0.9907770625 #> 402  P1000402    0010 0.7171599    0010 0.4665811 5.845281e-03 0.0008657870 #> 403  P1000403    1011 0.9430476    1011 0.9809267 9.895168e-01 0.0053499202 #> 404  P1000404    0000 0.9446598    0000 0.9889664 1.946025e-04 0.0007810027 #> 405  P1000405    1111 0.9409315    1111 0.9721795 9.730402e-01 0.9992508504 #> 406  P1000406    1111 0.9465258    1111 0.9888947 9.985702e-01 0.9903572509 #> 407  P1000407    0111 0.8610595    0111 0.9215675 2.574063e-02 0.9529849255 #> 408  P1000408    0000 0.7290110    0000 0.9532928 1.125771e-03 0.0043668734 #> 409  P1000409    0000 0.9446598    0000 0.9889664 1.946025e-04 0.0007810027 #> 410  P1000410    0010 0.2918530    0000 0.7564224 2.158779e-03 0.0647756222 #> 411  P1000411    1111 0.9221295    1111 0.9765376 9.795116e-01 0.9990635987 #> 412  P1000412    0110 0.6140467    0111 0.8451361 9.214893e-04 0.9884388787 #> 413  P1000413    0011 0.9875683    0011 0.9878213 1.870968e-03 0.0005505527 #> 414  P1000414    1111 0.9035661    1111 0.9881959 9.998852e-01 0.9887099976 #> 415  P1000415    1111 0.8954496    1111 0.9850680 9.984781e-01 0.9902930972 #> 416  P1000416    0111 0.9632497    0111 0.9679934 2.583644e-02 0.9951426048 #> 417  P1000417    1111 0.9747167    1111 0.9944394 9.991863e-01 0.9952632821 #> 418  P1000418    1011 0.8608242    1011 0.9481246 9.874613e-01 0.0069275718 #> 419  P1000419    1000 0.7489506    0000 0.7082276 1.478131e-01 0.0008108092 #> 420  P1000420    0010 0.8545207    0010 0.6143614 5.327765e-04 0.0054991341 #> 421  P1000421    1101 0.5271436    1111 0.4883430 7.336391e-01 0.9987567121 #> 422  P1000422    0010 0.6151524    0010 0.7897773 6.547348e-04 0.1275645533 #> 423  P1000423    1111 0.6256394    1111 0.7778951 7.852287e-01 0.9904414192 #> 424  P1000424    1111 0.9576610    1111 0.9957494 9.985645e-01 0.9992844972 #> 425  P1000425    0001 0.4109679    0001 0.5117393 4.233632e-04 0.0658736605 #> 426  P1000426    0101 0.2396708    0001 0.4388684 1.125221e-01 0.3555464366 #> 427  P1000427    0101 0.5767601    0101 0.7269019 7.359632e-03 0.8992485515 #> 428  P1000428    0011 0.5637716    0111 0.5858684 3.759822e-02 0.6102844515 #> 429  P1000429    0000 0.4192177    0000 0.7901412 3.060526e-03 0.0043469382 #> 430  P1000430    1111 0.5700293    1111 0.9784154 9.984613e-01 0.9853014880 #> 431  P1000431    1111 0.7093979    1111 0.9685973 9.998786e-01 0.9904204080 #> 432  P1000432    0001 0.5665023    0001 0.6662790 1.268234e-03 0.0650252253 #> 433  P1000433    0100 0.4621410    0000 0.8871048 1.260518e-03 0.0528646926 #> 434  P1000434    0010 0.3583288    0000 0.7346299 1.377527e-02 0.0007913528 #> 435  P1000435    0000 0.6864261    0000 0.8976648 2.322494e-04 0.0097140900 #> 436  P1000436    0111 0.5288786    0111 0.8168157 1.950851e-02 0.9988902659 #> 437  P1000437    0011 0.6281704    0011 0.5436887 3.074424e-02 0.0060664162 #> 438  P1000438    1111 0.4138167    1111 0.6884921 7.819777e-01 0.8767596069 #> 439  P1000439    1111 0.6348122    1111 0.8898400 9.781989e-01 0.9107486179 #> 440  P1000440    1001 0.7188845    1001 0.5004233 9.799726e-01 0.0479516556 #> 441  P1000441    1111 0.9896194    1111 0.9982996 9.985719e-01 0.9999286620 #> 442  P1000442    1111 0.8981225    1111 0.9710334 9.814770e-01 0.9908466734 #> 443  P1000443    1111 0.5346800    1111 0.8493090 9.723022e-01 0.8751734763 #> 444  P1000444    0000 0.5138615    0000 0.7370258 6.682892e-04 0.0051849271 #> 445  P1000445    0111 0.8097020    0111 0.9195849 2.814691e-03 0.9384587995 #> 446  P1000446    0101 0.9494376    0101 0.9460627 1.169126e-02 0.9987228046 #> 447  P1000447    1111 0.6588626    1111 0.9639208 9.984759e-01 0.9891630701 #> 448  P1000448    1001 0.6254474    1011 0.4482205 8.874109e-01 0.0722837611 #> 449  P1000449    1010 0.5284764    0010 0.8221606 9.592081e-02 0.0137071540 #> 450  P1000450    1011 0.8268472    1011 0.8998376 9.896350e-01 0.0788001078 #> 451  P1000451    0001 0.6627184    0001 0.7636629 5.301259e-04 0.0071347728 #> 452  P1000452    1011 0.8741024    1011 0.8797045 9.892311e-01 0.0787243408 #> 453  P1000453    0000 0.4942993    0000 0.7269382 5.006083e-03 0.0006879523 #> 454  P1000454    0100 0.3068495    0000 0.7196998 1.348837e-02 0.0968505617 #> 455  P1000455    0010 0.4478491    0000 0.7735861 1.841054e-04 0.0083296747 #> 456  P1000456    1111 0.8952588    1111 0.9895982 9.998852e-01 0.9903470014 #> 457  P1000457    0000 0.5202052    0000 0.9424029 1.343257e-02 0.0007750275 #> 458  P1000458    1111 0.5940322    1111 0.7774452 7.848197e-01 0.9909716636 #> 459  P1000459    0001 0.6460120    0001 0.5505084 5.754782e-03 0.0005856783 #> 460  P1000460    0010 0.3540547    0000 0.7023074 1.560285e-04 0.0721828738 #> 461  P1000461    0000 0.6128094    0000 0.8798019 1.087293e-03 0.0007805702 #> 462  P1000462    0000 0.5025638    0000 0.8270868 2.586154e-04 0.0329474980 #> 463  P1000463    0001 0.9097564    0001 0.9266559 8.045262e-03 0.0044729656 #> 464  P1000464    0000 0.3544581    0000 0.8550552 5.974997e-03 0.0348154832 #> 465  P1000465    0000 0.4961362    0000 0.8205482 1.913235e-04 0.0007933756 #> 466  P1000466    1000 0.9271245    0000 0.4568134 5.230781e-01 0.0007459489 #> 467  P1000467    0011 0.8571511    0011 0.7987588 4.393232e-03 0.0053226217 #> 468  P1000468    0011 0.6438860    0011 0.5417523 1.598610e-03 0.0005305513 #> 469  P1000469    0000 0.7140470    0000 0.9130034 3.305420e-03 0.0007546783 #> 470  P1000470    0001 0.3268685    0001 0.4226241 3.687603e-04 0.0527040283 #> 471  P1000471    0010 0.9160019    0010 0.7950535 7.584795e-05 0.0009418805 #> 472  P1000472    1111 0.9481642    1111 0.9894688 9.983355e-01 0.9912947003 #> 473  P1000473    1111 0.8879365    1111 0.9830980 9.898971e-01 0.9938218856 #> 474  P1000474    0001 0.4753204    0001 0.7965571 1.321343e-01 0.0518693658 #> 475  P1000475    0000 0.4411242    0000 0.9114475 1.126768e-03 0.0420922836 #> 476  P1000476    0101 0.6976320    0101 0.8498632 5.699574e-04 0.9796739676 #> 477  P1000477    0010 0.7346549    0000 0.4693499 9.168629e-04 0.0086049468 #> 478  P1000478    0111 0.5524005    0111 0.6050626 3.469806e-01 0.9372903005 #> 479  P1000479    0011 0.5875053    0011 0.5829946 3.410294e-01 0.0963251116 #> 480  P1000480    1111 0.6685538    1111 0.9684467 9.998784e-01 0.9904144627 #> 481  P1000481    0101 0.9328883    0101 0.8877122 8.214069e-03 0.8980735157 #> 482  P1000482    1111 0.6298741    1111 0.7828868 7.845905e-01 0.9999255939 #> 483  P1000483    0101 0.9613832    0101 0.9522243 8.016539e-03 0.9914133524 #> 484  P1000484    1011 0.9757547    1011 0.9033919 9.992025e-01 0.0955595608 #> 485  P1000485    0000 0.8888034    0000 0.9792855 4.274857e-04 0.0007831099 #> 486  P1000486    0010 0.4849003    0000 0.7768514 1.017031e-03 0.0045813466 #> 487  P1000487    1001 0.8916364    1001 0.6498622 6.776453e-01 0.0031783025 #> 488  P1000488    1111 0.9910353    1111 0.9982143 9.983386e-01 0.9999286782 #> 489  P1000489    0111 0.9738410    0111 0.9690736 2.585256e-02 0.9953654191 #> 490  P1000490    0100 0.3903293    0000 0.8250346 9.714503e-04 0.0743298867 #> 491  P1000491    0010 0.5428091    0010 0.6354924 7.876382e-05 0.1369752257 #> 492  P1000492    0000 0.5468379    0000 0.8858315 9.772175e-04 0.0061171106 #> 493  P1000493    1111 0.9626305    1111 0.9977491 9.998850e-01 0.9999284378 #> 494  P1000494    1101 0.2929460    1111 0.6627551 7.831592e-01 0.9007557944 #> 495  P1000495    1111 0.4200030    1111 0.9702749 9.998750e-01 0.9990853291 #> 496  P1000496    1111 0.9575276    1111 0.9956773 9.984922e-01 0.9992844877 #> 497  P1000497    0000 0.6323509    0000 0.9132869 2.672583e-03 0.0044058841 #> 498  P1000498    0000 0.8344100    0000 0.9866377 2.548751e-03 0.0007809451 #> 499  P1000499    0010 0.7296025    0000 0.6463136 1.418908e-04 0.0008575755 #> 500  P1000500    1011 0.7221123    1011 0.8006951 8.813801e-01 0.0083865127 #> 501  P1000501    0000 0.4744105    0000 0.7080252 5.197018e-03 0.0006811848 #> 502  P1000502    0101 0.4691708    0001 0.4056295 4.882916e-04 0.4359280139 #> 503  P1000503    0000 0.8344100    0000 0.9866377 2.548751e-03 0.0007809451 #> 504  P1000504    0010 0.6979347    0000 0.6810177 1.472295e-04 0.0008498201 #> 505  P1000505    1111 0.9085252    1111 0.9969398 9.998849e-01 0.9991206118 #> 506  P1000506    1111 0.5430107    1111 0.8715979 9.985273e-01 0.8755960292 #> 507  P1000507    0010 0.9219450    0010 0.7387057 7.165862e-04 0.0009451845 #> 508  P1000508    0101 0.8337060    0101 0.7530892 4.188823e-03 0.7931968111 #> 509  P1000509    0100 0.4151995    0000 0.4117968 2.475583e-04 0.3168376575 #> 510  P1000510    0011 0.8843339    0011 0.8925984 1.985880e-03 0.0005749682 #> 511  P1000511    0011 0.9910146    0011 0.9860998 1.876540e-03 0.0067038688 #> 512  P1000512    1111 0.6329927    1111 0.8295941 8.710741e-01 0.9526783652 #> 513  P1000513    0010 0.4051352    0000 0.4835287 3.608710e-03 0.0049475010 #> 514  P1000514    1101 0.9574104    1101 0.9408499 9.430568e-01 0.9986547144 #> 515  P1000515    0000 0.8196681    0000 0.9368749 2.113658e-04 0.0007686614 #> 516  P1000516    0011 0.9542168    0011 0.9461202 2.969531e-03 0.0078834241 #> 517  P1000517    1111 0.9035447    1111 0.9802010 9.815333e-01 0.9992840521 #> 518  P1000518    1111 0.9511061    1111 0.9901051 9.998854e-01 0.9903579977 #> 519  P1000519    0001 0.4125446    0000 0.5595347 6.545034e-03 0.0473853690 #> 520  P1000520    1110 0.8190173    1111 0.8350165 9.854097e-01 0.9261032685 #> 521  P1000521    0001 0.5531900    0001 0.8239952 1.041307e-01 0.0004490717 #> 522  P1000522    1111 0.5957038    1111 0.7784298 7.848273e-01 0.9922971233 #> 523  P1000523    0000 0.8057773    0000 0.9644964 2.607835e-03 0.0007729561 #> 524  P1000524    0110 0.4478302    0111 0.6563174 1.323569e-01 0.8729314079 #> 525  P1000525    0000 0.6362923    0000 0.8813719 2.221508e-04 0.0075674925 #> 526  P1000526    0001 0.6976385    0001 0.8975838 5.208070e-02 0.0288704426 #> 527  P1000527    1111 0.6038775    1111 0.7613555 7.688958e-01 0.9899778505 #> 528  P1000528    0111 0.9089199    0111 0.8576756 1.406055e-01 0.9991800698 #> 529  P1000529    0001 0.8826109    0001 0.9504780 1.205946e-02 0.0068307063 #> 530  P1000530    0111 0.7566925    0111 0.6524302 3.384033e-01 0.9938604922 #> 531  P1000531    1010 0.3551954    1011 0.5710632 9.664239e-01 0.3686106425 #> 532  P1000532    1111 0.7003553    1111 0.9767810 9.998786e-01 0.9992583620 #> 533  P1000533    0100 0.5590155    0000 0.8853039 1.892348e-04 0.0762403778 #> 534  P1000534    0000 0.6372087    0000 0.8850299 2.910525e-03 0.0007616118 #> 535  P1000535    0010 0.3961852    0011 0.4351659 1.207198e-03 0.0929186279 #> 536  P1000536    0011 0.8462771    0011 0.7638561 2.567579e-04 0.0005232925 #> 537  P1000537    1000 0.3496150    1011 0.1826977 5.870421e-01 0.0416514342 #> 538  P1000538    1111 0.4456321    1111 0.7825090 8.570174e-01 0.9357472048 #> 539  P1000539    0110 0.8587049    0110 0.5075861 7.756208e-03 0.8351927380 #> 540  P1000540    1111 0.7358665    1111 0.9764594 9.984127e-01 0.9999258506 #> 541  P1000541    1010 0.4973852    0010 0.5819808 1.651483e-01 0.0059037482 #> 542  P1000542    0000 0.4832517    0000 0.8361423 4.642831e-04 0.0048591486 #> 543  P1000543    0011 0.8061409    0011 0.8337198 2.508499e-02 0.0810124685 #> 544  P1000544    0111 0.6661089    0111 0.9340332 1.892874e-02 0.9999076510 #> 545  P1000545    0110 0.5270679    0111 0.6874978 1.889576e-02 0.9998549146 #> 546  P1000546    1011 0.6267865    1011 0.9577352 9.998435e-01 0.0036708841 #> 547  P1000547    0011 0.3093267    0011 0.2931999 4.528713e-02 0.4533774823 #> 548  P1000548    0111 0.8393694    0111 0.9640051 1.255668e-02 0.9999123870 #> 549  P1000549    1111 0.9906305    1111 0.9976226 9.985001e-01 0.9992870089 #> 550  P1000550    0011 0.3080684    0011 0.3446709 2.973058e-01 0.0883771862 #> 551  P1000551    0001 0.5566609    0001 0.5466688 2.656321e-03 0.0327551540 #> 552  P1000552    0010 0.8146191    0010 0.8679323 9.262841e-03 0.0136038364 #> 553  P1000553    1101 0.7147756    1101 0.4344804 4.870895e-01 0.9822982773 #> 554  P1000554    1110 0.3014376    1111 0.8620699 9.980793e-01 0.8994175144 #> 555  P1000555    1111 0.9579235    1111 0.9813504 9.815736e-01 0.9999284577 #> 556  P1000556    0000 0.5803250    0000 0.8840097 4.784142e-04 0.0100568618 #> 557  P1000557    1111 0.6778189    1111 0.9504273 9.763498e-01 0.9992163150 #> 558  P1000558    0001 0.6007498    0001 0.6574475 2.194351e-02 0.0068328682 #> 559  P1000559    0001 0.6977404    0001 0.7591031 5.584795e-04 0.0639263350 #> 560  P1000560    0100 0.4193631    0000 0.8425886 4.378058e-04 0.0725580512 #> 561  P1000561    1111 0.5534118    1111 0.8727222 9.982888e-01 0.8763738620 #> 562  P1000562    1111 0.9404287    1111 0.9721644 9.730372e-01 0.9992838357 #> 563  P1000563    0000 0.6214135    0000 0.9670686 5.581930e-03 0.0081326298 #> 564  P1000564    1110 0.7106023    1111 0.7819940 9.681039e-01 0.8473810463 #> 565  P1000565    0011 0.9851695    0011 0.9829499 1.870728e-03 0.0054792833 #> 566  P1000566    1010 0.8645611    1011 0.6368193 9.719403e-01 0.0099854825 #> 567  P1000567    0000 0.9446598    0000 0.9889664 1.946025e-04 0.0007810027 #> 568  P1000568    0001 0.6686606    0001 0.7991198 1.080410e-02 0.0452271381 #> 569  P1000569    1111 0.6732505    1111 0.9687172 9.982346e-01 0.9922944017 #> 570  P1000570    1001 0.6007305    1001 0.5849399 9.860702e-01 0.3589476908 #> 571  P1000571    0001 0.6509019    0001 0.5255266 4.269634e-04 0.0005965592 #> 572  P1000572    0110 0.7355051    0110 0.4922077 1.541217e-03 0.9241420020 #> 573  P1000573    0101 0.5327101    0111 0.6957845 1.651417e-02 0.9864529492 #> 574  P1000574    1101 0.9513608    1101 0.9320620 9.343073e-01 0.9986523965 #> 575  P1000575    0001 0.7331242    0001 0.8592662 1.181698e-02 0.0808180087 #> 576  P1000576    0111 0.6615038    0111 0.8643868 3.915892e-03 0.9994239227 #> 577  P1000577    0101 0.4728029    0111 0.6945550 1.627942e-02 0.9746629820 #> 578  P1000578    0111 0.7680228    0111 0.8174584 1.701393e-01 0.9989078507 #> 579  P1000579    1111 0.6596235    1111 0.9852845 9.977656e-01 0.9912790462 #> 580  P1000580    1110 0.4997522    1111 0.9666418 9.779694e-01 0.9992660469 #> 581  P1000581    0101 0.4438639    0111 0.5449319 1.885916e-01 0.9987031316 #> 582  P1000582    1110 0.9061005    1111 0.9058559 9.977220e-01 0.9909482799 #> 583  P1000583    0011 0.6211658    0011 0.6454900 3.431807e-01 0.0066468660 #> 584  P1000584    0011 0.5690168    0011 0.5674840 3.635618e-01 0.0964083267 #> 585  P1000585    1111 0.3620584    1111 0.7560325 7.636967e-01 0.9991943898 #> 586  P1000586    0000 0.4869083    0000 0.9457709 1.161717e-03 0.0435068681 #> 587  P1000587    1111 0.5495894    1111 0.7795913 8.284104e-01 0.9416860947 #> 588  P1000588    1111 0.9101659    1111 0.9661707 9.686197e-01 0.9992478417 #> 589  P1000589    0000 0.8395005    0000 0.9867585 2.426710e-03 0.0007809481 #> 590  P1000590    0000 0.9446598    0000 0.9889664 1.946025e-04 0.0007810027 #> 591  P1000591    0010 0.9360161    0010 0.9577795 6.023463e-04 0.0141897235 #> 592  P1000592    1011 0.9137447    1011 0.8946780 9.894824e-01 0.0927071630 #> 593  P1000593    1111 0.9072400    1111 0.9965857 9.998847e-01 0.9992838844 #> 594  P1000594    0111 0.9535339    0111 0.9833657 1.432316e-04 0.9938600361 #> 595  P1000595    0111 0.9350632    0111 0.9652783 1.962967e-02 0.9988842974 #> 596  P1000596    0011 0.5200798    0111 0.5463005 2.620113e-03 0.5681116755 #> 597  P1000597    0000 0.4838402    0000 0.9580439 1.250897e-02 0.0077804416 #> 598  P1000598    0100 0.7221081    0000 0.4687685 3.064559e-04 0.3540941722 #> 599  P1000599    0011 0.7187669    0011 0.6062863 2.497305e-03 0.0079421117 #> 600  P1000600    0000 0.7071272    0000 0.9646168 2.784396e-03 0.0053638483 #> 601  P1000601    1111 0.9274179    1111 0.9767620 9.795159e-01 0.9992489268 #> 602  P1000602    1111 0.5570822    1111 0.8718006 9.977279e-01 0.8756579153 #> 603  P1000603    0000 0.7269846    0000 0.9134291 2.840703e-03 0.0007547105 #> 604  P1000604    0111 0.6522928    0111 0.8572401 2.560448e-03 0.9942399060 #> 605  P1000605    0000 0.8400567    0000 0.9845103 1.154380e-03 0.0043282400 #> 606  P1000606    1111 0.4148815    1111 0.7285819 7.641917e-01 0.9989695287 #> 607  P1000607    0011 0.9323306    0011 0.9357789 2.588544e-02 0.0086336233 #> 608  P1000608    0101 0.6269405    0101 0.7638725 5.545666e-04 0.9004419363 #> 609  P1000609    1111 0.6378888    1111 0.9093125 9.984737e-01 0.9111681110 #> 610  P1000610    0101 0.4970286    0101 0.3950325 5.260206e-04 0.4634412026 #> 611  P1000611    0010 0.6509641    0000 0.6274126 1.898212e-03 0.0084309029 #> 612  P1000612    0000 0.6440100    0000 0.9484322 2.753351e-03 0.0078251216 #> 613  P1000613    1000 0.5657210    0000 0.9230067 3.662328e-02 0.0099664663 #> 614  P1000614    1111 0.7391367    1111 0.9764999 9.984130e-01 0.9999258579 #> 615  P1000615    0001 0.8819269    0001 0.8738411 7.364133e-03 0.0051374301 #> 616  P1000616    0010 0.7585071    0010 0.7597567 1.392052e-02 0.0123950526 #> 617  P1000617    1101 0.9790423    1101 0.8920439 9.990213e-01 0.9865303926 #> 618  P1000618    1011 0.8513302    1011 0.7811553 8.828969e-01 0.1110430557 #> 619  P1000619    1000 0.8984732    0000 0.4735194 5.025358e-01 0.0045359327 #> 620  P1000620    0110 0.4575722    0111 0.6996002 1.799642e-04 0.9250790052 #> 621  P1000621    0010 0.8363964    0010 0.6126317 1.368450e-03 0.0009004292 #> 622  P1000622    0101 0.4216412    0001 0.5168432 1.009586e-02 0.3787133860 #> 623  P1000623    0101 0.8219612    0101 0.7288119 4.180659e-03 0.7672684006 #> 624  P1000624    0001 0.4146795    0001 0.6961053 1.232766e-01 0.0364194473 #> 625  P1000625    1011 0.9474462    1011 0.9817113 9.900271e-01 0.0053485274 #> 626  P1000626    0011 0.4691916    0011 0.3928204 1.950796e-02 0.0071696619 #> 627  P1000627    0110 0.9582185    0110 0.7139061 9.741831e-04 0.9872316406 #> 628  P1000628    1111 0.6689550    1111 0.9110098 9.998838e-01 0.9112610945 #> 629  P1000629    0100 0.7762993    0000 0.7393598 1.173341e-03 0.2388883779 #> 630  P1000630    0000 0.7379532    0000 0.9326289 1.253489e-03 0.0042599407 #> 631  P1000631    0000 0.8452275    0000 0.9654457 2.035898e-04 0.0046864904 #> 632  P1000632    0100 0.5330836    0000 0.7115731 1.864676e-02 0.2417592934 #> 633  P1000633    0000 0.7043211    0000 0.9744957 5.316581e-03 0.0007829965 #> 634  P1000634    1111 0.9057569    1111 0.9949951 9.984890e-01 0.9990658633 #> 635  P1000635    0111 0.8547552    0111 0.9051377 3.722620e-02 0.9402687331 #> 636  P1000636    0100 0.5200805    0101 0.3413053 6.556295e-03 0.8073172854 #> 637  P1000637    0001 0.3908548    0001 0.5328990 4.553984e-02 0.0030230829 #> 638  P1000638    1111 0.8837244    1111 0.9778745 9.814438e-01 0.9988514816 #> 639  P1000639    0001 0.6971268    0001 0.7906162 3.258778e-03 0.0204944833 #> 640  P1000640    0011 0.4141747    0111 0.4659759 2.585748e-04 0.5517041278 #> 641  P1000641    0011 0.9466259    0011 0.9510501 2.867793e-02 0.0066895779 #> 642  P1000642    0111 0.8714168    0111 0.9799402 1.801554e-03 0.9938087140 #> 643  P1000643    0110 0.7815104    0110 0.6084466 8.915389e-03 0.9650299416 #> 644  P1000644    0100 0.4600312    0000 0.9253556 2.553516e-03 0.0538193907 #> 645  P1000645    0110 0.6262520    0111 0.8567049 1.803195e-03 0.9936562310 #> 646  P1000646    1001 0.8315420    1001 0.9258423 9.624586e-01 0.0004329402 #> 647  P1000647    1111 0.8832605    1111 0.9764712 9.784934e-01 0.9999281450 #> 648  P1000648    0111 0.8190321    0111 0.7278932 2.662144e-01 0.9939095774 #> 649  P1000649    1011 0.8422691    1011 0.9701440 9.896731e-01 0.0084823968 #> 650  P1000650    1111 0.9564965    1111 0.9808288 9.815768e-01 0.9992850654 #> 651  P1000651    0111 0.8678569    0111 0.9844545 9.768066e-04 0.9990993766 #> 652  P1000652    0111 0.9462981    0111 0.9722230 1.470332e-02 0.9988881826 #> 653  P1000653    1001 0.7200127    1001 0.4633686 4.822721e-01 0.0027826094 #> 654  P1000654    0000 0.8196681    0000 0.9368749 2.113658e-04 0.0007686614 #> 655  P1000655    0010 0.4845851    0000 0.8302787 9.529728e-04 0.0008162925 #> 656  P1000656    1111 0.9858033    1111 0.9974677 9.985718e-01 0.9990701260 #> 657  P1000657    0001 0.7244328    0001 0.8095314 7.557564e-03 0.0516322928 #> 658  P1000658    0111 0.9589154    0111 0.9743630 1.396174e-02 0.9892091150 #> 659  P1000659    1111 0.9392668    1111 0.9921194 9.991817e-01 0.9950268423 #> 660  P1000660    1111 0.6361758    1111 0.9105395 9.998835e-01 0.9111785606 #> 661  P1000661    0110 0.5159107    0111 0.7357637 1.302260e-03 0.9833732860 #> 662  P1000662    1101 0.8427874    1111 0.7320497 9.975573e-01 0.9988838868 #> 663  P1000663    0101 0.5601676    0101 0.7313601 1.438125e-01 0.9149918156 #> 664  P1000664    1011 0.8265945    1011 0.8711270 9.897169e-01 0.1108309210 #> 665  P1000665    1111 0.9646760    1111 0.9974505 9.977877e-01 0.9999286365 #> 666  P1000666    1111 0.5425669    1111 0.8462149 9.781346e-01 0.8647395409 #> 667  P1000667    1111 0.9911717    1111 0.9983749 9.985006e-01 0.9999286799 #> 668  P1000668    1011 0.5895199    1011 0.9285725 9.720241e-01 0.0036818781 #> 669  P1000669    1111 0.8930077    1111 0.9691622 9.784761e-01 0.9925364300 #> 670  P1000670    1111 0.9463422    1111 0.9890711 9.983354e-01 0.9908962959 #> 671  P1000671    0101 0.9433460    0101 0.9344359 1.169336e-02 0.9867856507 #> 672  P1000672    0101 0.7875700    0101 0.7410237 5.697533e-02 0.9189219826 #> 673  P1000673    0111 0.6166841    0111 0.8712693 1.923218e-04 0.9994211874 #> 674  P1000674    0100 0.7043181    0000 0.4401367 3.507366e-04 0.3278044385 #> 675  P1000675    1111 0.3512176    1111 0.6910249 7.820546e-01 0.9039163230 #> 676  P1000676    0110 0.3309604    0110 0.3559332 1.001797e-01 0.9801205721 #> 677  P1000677    1111 0.5811598    1111 0.8743515 9.985413e-01 0.8757892505 #> 678  P1000678    1011 0.8770687    1011 0.8970863 9.898596e-01 0.0876033629 #> 679  P1000679    0001 0.5175870    0001 0.8248068 1.304825e-01 0.0004378875 #> 680  P1000680    0111 0.8647524    0111 0.9377381 1.836467e-03 0.9424849577 #> 681  P1000681    0010 0.6643112    0000 0.6778958 8.733910e-04 0.0047076915 #> 682  P1000682    0110 0.7782189    0110 0.7621831 5.536199e-04 0.9886687865 #> 683  P1000683    1111 0.4249228    1111 0.7733843 8.264289e-01 0.9408674903 #> 684  P1000684    1111 0.8723849    1111 0.9717728 9.795564e-01 0.9925579368 #> 685  P1000685    0000 0.7548798    0000 0.8998126 5.074484e-04 0.0007543529 #> 686  P1000686    0011 0.7768089    0011 0.7329418 2.271734e-04 0.0072568301 #> 687  P1000687    0100 0.7285175    0000 0.4071873 3.513222e-04 0.3781261844 #> 688  P1000688    0010 0.6172916    0000 0.6291667 2.185202e-03 0.0008203937 #> 689  P1000689    0000 0.4898972    0000 0.9263659 2.036142e-04 0.0449753193 #> 690  P1000690    0000 0.9446598    0000 0.9889664 1.946025e-04 0.0007810027 #> 691  P1000691    1111 0.9114636    1111 0.9959973 9.983478e-01 0.9999283734 #> 692  P1000692    0000 0.4971089    0000 0.9475909 1.161373e-03 0.0416661897 #> 693  P1000693    0101 0.8088624    0101 0.5996168 4.752409e-04 0.9029688322 #> 694  P1000694    0000 0.6994924    0000 0.9492041 2.740766e-03 0.0007892665 #> 695  P1000695    1011 0.8347190    1011 0.9374683 9.883224e-01 0.0005317080 #> 696  P1000696    0000 0.9446598    0000 0.9889664 1.946025e-04 0.0007810027 #> 697  P1000697    0100 0.4600312    0000 0.9253556 2.553516e-03 0.0538193907 #> 698  P1000698    1111 0.9309125    1111 0.9969618 9.983343e-01 0.9992861678 #> 699  P1000699    0001 0.8877941    0001 0.9396786 1.188856e-02 0.0004394263 #> 700  P1000700    1101 0.3451915    0111 0.5445030 2.436400e-01 0.9871871549 #> 701  P1000701    0111 0.9417076    0111 0.9794169 1.451895e-04 0.9938175045 #> 702  P1000702    0011 0.6220052    0011 0.5217835 1.831493e-01 0.3136575772 #> 703  P1000703    0000 0.4915753    0000 0.8983252 5.714426e-03 0.0059610538 #> 704  P1000704    0010 0.7222458    0010 0.4816038 5.500008e-03 0.0049671625 #> 705  P1000705    0011 0.9493235    0011 0.9210180 1.861419e-03 0.0631318002 #> 706  P1000706    0111 0.9632497    0111 0.9679934 2.583644e-02 0.9951426048 #> 707  P1000707    1111 0.4629593    1111 0.7135065 7.829778e-01 0.9083069429 #> 708  P1000708    0001 0.8011104    0001 0.7978840 1.043376e-02 0.0004917305 #> 709  P1000709    0001 0.8865395    0001 0.8623596 5.839806e-04 0.0051653781 #> 710  P1000710    0111 0.4026200    0111 0.7648213 2.843764e-02 0.9822011096 #> 711  P1000711    0111 0.8550835    0111 0.9661238 1.011029e-03 0.9859095873 #> 712  P1000712    1111 0.9919561    1111 0.9984520 9.985725e-01 0.9999286817 #> 713  P1000713    0011 0.7285358    0011 0.7965994 3.034091e-02 0.0089840862 #> 714  P1000714    0000 0.7362555    0000 0.9793994 2.548166e-03 0.0081115422 #> 715  P1000715    1110 0.4951235    1111 0.9786098 9.982637e-01 0.9908284598 #> 716  P1000716    1111 0.5991037    1111 0.8236860 8.652169e-01 0.9526194916 #> 717  P1000717    1011 0.5559331    1011 0.8870069 9.747575e-01 0.0510860606 #> 718  P1000718    0001 0.9050082    0001 0.9476752 1.200697e-02 0.0052096923 #> 719  P1000719    0011 0.7174804    0011 0.7856758 3.293278e-02 0.0089830989 #> 720  P1000720    1111 0.6372511    1111 0.7846972 7.868162e-01 0.9990332557 #> 721  P1000721    0111 0.9801558    0111 0.9943553 1.990106e-03 0.9995325351 #> 722  P1000722    1111 0.7456382    1111 0.8610783 8.653348e-01 0.9952757844 #> 723  P1000723    0110 0.3267777    0111 0.4575657 1.845670e-03 0.5438456195 #> 724  P1000724    0100 0.3432596    0000 0.6587678 3.058232e-04 0.0645102929 #> 725  P1000725    0111 0.8738289    0111 0.9175264 3.442833e-02 0.9533220403 #> 726  P1000726    0011 0.5227886    0111 0.6045919 1.479916e-04 0.6191231905 #> 727  P1000727    0100 0.5282404    0000 0.9084176 1.912070e-04 0.0657415856 #> 728  P1000728    1111 0.9867013    1111 0.9976513 9.985719e-01 0.9992540860 #> 729  P1000729    1100 0.6571613    0000 0.6165526 1.758610e-01 0.2347242708 #> 730  P1000730    0000 0.4064904    0000 0.8772831 2.608117e-03 0.0322851735 #> 731  P1000731    1111 0.6943869    1111 0.8599541 8.649851e-01 0.9950467363 #> 732  P1000732    1001 0.6389137    1011 0.4723419 9.863091e-01 0.0618479395 #> 733  P1000733    1111 0.6031498    1111 0.8926341 9.998833e-01 0.8932468663 #> 734  P1000734    0010 0.8612753    0010 0.7838542 7.729421e-04 0.0127198128 #> 735  P1000735    0000 0.2843262    0000 0.8776606 1.489777e-02 0.0435844386 #> 736  P1000736    0000 0.4643197    0000 0.9693487 1.653682e-02 0.0043390070 #> 737  P1000737    0010 0.5309871    0011 0.5159671 1.022019e-04 0.0097930567 #> 738  P1000738    0000 0.7997533    0000 0.9797485 1.945456e-04 0.0100944287 #> 739  P1000739    0000 0.4832517    0000 0.8361423 4.642831e-04 0.0048591486 #> 740  P1000740    1111 0.8818486    1111 0.9663488 9.713672e-01 0.9992449428 #> 741  P1000741    0000 0.3407627    0000 0.6840111 3.892226e-03 0.0348636636 #> 742  P1000742    0111 0.9058422    0111 0.9688907 2.017468e-03 0.9951663295 #> 743  P1000743    1101 0.8995108    1111 0.5484177 9.836881e-01 0.9879124284 #> 744  P1000744    0101 0.2533640    0111 0.4613777 1.774289e-02 0.8811743786 #> 745  P1000745    1111 0.9551977    1111 0.9787715 9.796202e-01 0.9992517313 #> 746  P1000746    1111 0.9618737    1111 0.9960184 9.985656e-01 0.9992518827 #> 747  P1000747    0111 0.6022053    0111 0.8139899 2.098571e-04 0.9427638343 #> 748  P1000748    1111 0.4712581    1111 0.7415849 7.586036e-01 0.9999223430 #> 749  P1000749    0000 0.6789796    0000 0.9426692 1.887895e-04 0.0102012447 #> 750  P1000750    0111 0.9567683    0111 0.9545763 3.722300e-02 0.9939396933 #> 751  P1000751    0001 0.5604411    0001 0.6978544 5.223680e-04 0.0822557914 #> 752  P1000752    1011 0.8492193    1011 0.8764739 8.823067e-01 0.0005391820 #> 753  P1000753    1101 0.9474749    1101 0.7994273 9.954302e-01 0.9835561080 #> 754  P1000754    0000 0.4009371    0000 0.7059502 9.988588e-03 0.0052437742 #> 755  P1000755    1111 0.6662108    1111 0.9426270 9.714371e-01 0.9922367070 #> 756  P1000756    0111 0.8709555    0111 0.9800164 1.975376e-03 0.9950195743 #> 757  P1000757    0110 0.4658425    0111 0.7652951 1.314137e-01 0.9867129517 #> 758  P1000758    0111 0.6315644    0111 0.8512062 1.772620e-02 0.9989125697 #> 759  P1000759    0011 0.6771032    0011 0.5324341 1.464582e-01 0.3811076005 #> 760  P1000760    0111 0.7651393    0111 0.6544158 3.387461e-01 0.9952998210 #> 761  P1000761    0000 0.5324469    0000 0.7512131 2.938176e-04 0.0045560555 #> 762  P1000762    0100 0.7740848    0100 0.5049412 5.313362e-03 0.8646967805 #> 763  P1000763    1111 0.3504642    1111 0.8385629 8.676502e-01 0.9949585456 #> 764  P1000764    0000 0.5357018    0000 0.7438935 3.047839e-04 0.0051734085 #> 765  P1000765    1111 0.7180025    1111 0.9704785 9.998787e-01 0.9923031303 #> 766  P1000766    0001 0.6653491    0001 0.8286682 3.819695e-02 0.0053846934 #> 767  P1000767    1111 0.3525018    1111 0.6571665 7.797029e-01 0.8396052461 #> 768  P1000768    0110 0.5856483    0111 0.8134228 1.807809e-03 0.9399259309 #> 769  P1000769    0000 0.9446598    0000 0.9889664 1.946025e-04 0.0007810027 #> 770  P1000770    0100 0.6688491    0000 0.7468179 6.524206e-03 0.2158301960 #> 771  P1000771    0001 0.6118516    0001 0.7054795 6.261745e-03 0.0048615333 #> 772  P1000772    1111 0.6346485    1111 0.7959340 8.002296e-01 0.9990316066 #> 773  P1000773    0011 0.9679544    0011 0.9687187 1.855821e-03 0.0086585276 #> 774  P1000774    1111 0.9353228    1111 0.9790631 9.814945e-01 0.9992827314 #> 775  P1000775    0111 0.9822446    0111 0.9792537 1.875499e-02 0.9991650853 #> 776  P1000776    1111 0.5009627    1111 0.6928559 7.009721e-01 0.9902339178 #> 777  P1000777    0000 0.6414402    0000 0.8957931 1.184527e-03 0.0097934185 #> 778  P1000778    0000 0.9446598    0000 0.9889664 1.946025e-04 0.0007810027 #> 779  P1000779    1000 0.5482769    0000 0.9299614 3.162820e-02 0.0076610493 #> 780  P1000780    1111 0.8827202    1111 0.9866775 9.985663e-01 0.9886746200 #> 781  P1000781    0000 0.6347137    0000 0.8996075 3.351203e-03 0.0074712966 #> 782  P1000782    1111 0.7404994    1111 0.9293792 9.899336e-01 0.9389987706 #> 783  P1000783    0000 0.7997533    0000 0.9797485 1.945456e-04 0.0100944287 #> 784  P1000784    0000 0.8269521    0000 0.9817105 1.945577e-04 0.0081121367 #> 785  P1000785    0000 0.4780106    0000 0.8497546 4.448025e-04 0.0080493584 #> 786  P1000786    0110 0.5376798    0111 0.3618330 2.714506e-02 0.5754153261 #> 787  P1000787    1111 0.5437830    1111 0.9922308 9.998823e-01 0.9991202495 #> 788  P1000788    0011 0.5266626    0111 0.5822953 2.232271e-02 0.6043014689 #> 789  P1000789    1001 0.7960723    0001 0.5012489 4.817245e-01 0.0307376296 #> 790  P1000790    0011 0.5862163    0111 0.4994035 2.020831e-03 0.5221505546 #> 791  P1000791    0011 0.4910958    0001 0.4829893 1.524323e-03 0.0533353283 #> 792  P1000792    0000 0.8276129    0000 0.9624613 1.905251e-04 0.0007869258 #> 793  P1000793    1111 0.4499237    1111 0.7545506 7.856517e-01 0.9992141675 #> 794  P1000794    0010 0.6558408    0000 0.4680748 1.134821e-02 0.0008661507 #> 795  P1000795    0000 0.6543815    0000 0.8907334 1.201945e-03 0.0074992015 #> 796  P1000796    0100 0.8063317    0000 0.7241480 1.304271e-03 0.2411738966 #> 797  P1000797    1111 0.5695463    1111 0.9528360 9.985058e-01 0.9999228106 #> 798  P1000798    0111 0.8555195    0111 0.9566035 2.564640e-02 0.9938081423 #> 799  P1000799    1111 0.9030635    1111 0.9801427 9.815320e-01 0.9992509737 #> 800  P1000800    1111 0.9274565    1111 0.9850072 9.985686e-01 0.9866269117 #> 801  P1000801    0111 0.6277519    0111 0.7469060 1.556073e-01 0.8975369065 #> 802  P1000802    1000 0.4022614    0000 0.4920853 1.167752e-01 0.0048145631 #> 803  P1000803    1011 0.9484962    1011 0.9859642 9.895312e-01 0.0005373601 #> 804  P1000804    1111 0.9529415    1111 0.9902330 9.998855e-01 0.9903601856 #> 805  P1000805    0001 0.4814769    0001 0.8068290 1.486157e-01 0.0004378121 #> 806  P1000806    0000 0.4278814    0000 0.7811112 5.264569e-04 0.0077530332 #> 807  P1000807    1111 0.4608982    1111 0.8474696 8.611536e-01 0.9924090619 #> 808  P1000808    1111 0.9271813    1111 0.9787153 9.814771e-01 0.9992822548 #> 809  P1000809    0110 0.5050508    0111 0.6401028 1.300395e-03 0.8759753535 #> 810  P1000810    1111 0.9488718    1111 0.9905075 9.998854e-01 0.9907792577 #> 811  P1000811    0011 0.6746139    0011 0.7185044 1.316314e-04 0.0968311114 #> 812  P1000812    0011 0.8222439    0011 0.8130295 2.329501e-02 0.0005669644 #> 813  P1000813    0000 0.8231523    0000 0.9863656 2.823893e-03 0.0007809383 #> 814  P1000814    0001 0.5632100    0001 0.6846332 5.456830e-02 0.0028955316 #> 815  P1000815    0010 0.5463689    0010 0.4343925 1.325449e-03 0.0542750659 #> 816  P1000816    0111 0.9473104    0111 0.9851404 1.022749e-03 0.9991446921 #> 817  P1000817    0000 0.8395005    0000 0.9867585 2.426710e-03 0.0007809481 #> 818  P1000818    0000 0.4947190    0000 0.7191589 6.863327e-04 0.0052245883 #> 819  P1000819    0010 0.8766488    0010 0.8291919 6.473034e-04 0.0122563651 #> 820  P1000820    0000 0.8269521    0000 0.9817105 1.945577e-04 0.0081121367 #> 821  P1000821    0111 0.6577050    0111 0.6182655 3.385601e-01 0.9418113647 #> 822  P1000822    1111 0.2937675    1111 0.6491406 6.778648e-01 0.9988751444 #> 823  P1000823    0000 0.4193581    0000 0.8952641 1.930603e-02 0.0041905503 #> 824  P1000824    0000 0.4466065    0000 0.9353217 2.549281e-03 0.0436290558 #> 825  P1000825    0011 0.5579805    0011 0.5530322 3.186720e-01 0.1073396564 #> 826  P1000826    1001 0.7869179    1001 0.5847665 9.919951e-01 0.0544737464 #> 827  P1000827    1111 0.9869352    1111 0.9971562 9.983383e-01 0.9988593832 #> 828  P1000828    0101 0.8446592    0101 0.7911168 2.117720e-02 0.9977921081 #> 829  P1000829    1000 0.6319317    1001 0.5492004 9.213616e-01 0.0036139739 #> 830  P1000830    1111 0.9145500    1111 0.9693974 9.785814e-01 0.9907456626 #> 831  P1000831    1111 0.3894031    1111 0.8634299 9.982709e-01 0.8701434934 #> 832  P1000832    0111 0.8983945    0111 0.8393215 1.588539e-01 0.9991444747 #> 833  P1000833    0001 0.9394004    0001 0.9666887 6.325227e-04 0.0068446330 #> 834  P1000834    1111 0.2836384    1111 0.8364249 9.790524e-01 0.8850392336 #> 835  P1000835    1001 0.8210735    1001 0.6298240 6.874983e-01 0.0764639274 #> 836  P1000836    0101 0.6611816    0001 0.5259469 6.240336e-04 0.4583524257 #> 837  P1000837    0111 0.7811834    0111 0.6570848 3.396815e-01 0.9951210680 #> 838  P1000838    1111 0.6470826    1111 0.9477604 9.783659e-01 0.9904940928 #> 839  P1000839    0010 0.8613429    0010 0.7793821 6.366236e-04 0.0126758887 #> 840  P1000840    0011 0.9334517    0011 0.8993508 2.621293e-02 0.0658489198 #> 841  P1000841    0111 0.9691901    0111 0.9896308 1.834111e-03 0.9951258738 #> 842  P1000842    1111 0.9082797    1111 0.9956414 9.985634e-01 0.9991204085 #> 843  P1000843    0101 0.5271917    0101 0.8115519 4.839711e-02 0.9749276580 #> 844  P1000844    1111 0.8772669    1111 0.9873850 9.983455e-01 0.9912674977 #> 845  P1000845    1111 0.4988941    1111 0.9726857 9.809776e-01 0.9991168839 #> 846  P1000846    0000 0.7032041    0000 0.9341762 2.543256e-03 0.0007799310 #> 847  P1000847    1111 0.5529233    1111 0.8697017 9.998828e-01 0.8703117417 #> 848  P1000848    0000 0.8888034    0000 0.9792855 4.274857e-04 0.0007831099 #> 849  P1000849    0010 0.5237571    0011 0.5364109 1.380874e-03 0.0109041159 #> 850  P1000850    1110 0.8691320    1111 0.5731479 9.520404e-01 0.8852615624 #> 851  P1000851    0000 0.8231523    0000 0.9863656 2.823893e-03 0.0007809383 #> 852  P1000852    0000 0.9446598    0000 0.9889664 1.946025e-04 0.0007810027 #> 853  P1000853    1111 0.9363649    1111 0.9984382 9.998854e-01 0.9990695594 #> 854  P1000854    0001 0.8986842    0001 0.9619453 1.211604e-02 0.0004312135 #> 855  P1000855    0001 0.3269368    0001 0.5747900 1.169767e-01 0.0300692957 #> 856  P1000856    0100 0.4598995    0000 0.6317359 1.489057e-02 0.2558688066 #> 857  P1000857    0000 0.7424936    0000 0.9627898 2.953950e-03 0.0046865285 #> 858  P1000858    0010 0.6392009    0000 0.5134787 6.905359e-03 0.0085025513 #> 859  P1000859    1000 0.3530318    0001 0.4729393 1.540880e-01 0.0032338618 #> 860  P1000860    0110 0.5627343    0010 0.5507247 1.095257e-02 0.3715254813 #> 861  P1000861    1100 0.7299721    1101 0.7982804 9.545587e-01 0.9039759367 #> 862  P1000862    1111 0.9125148    1111 0.9703569 9.795853e-01 0.9907464340 #> 863  P1000863    1111 0.6372511    1111 0.7846972 7.868162e-01 0.9990332557 #> 864  P1000864    1111 0.6165625    1111 0.7844937 7.850889e-01 0.9999258489 #> 865  P1000865    0001 0.8991014    0001 0.8632523 1.290210e-03 0.0051384785 #> 866  P1000866    0000 0.8320125    0000 0.9820622 1.945599e-04 0.0077567864 #> 867  P1000867    1111 0.9908551    1111 0.9976150 9.985002e-01 0.9992541371 #> 868  P1000868    1011 0.9813293    1011 0.9828966 9.901269e-01 0.0065570623 #> 869  P1000869    1000 0.6722732    0000 0.7756646 1.619771e-01 0.0045492184 #> 870  P1000870    0001 0.6436823    0001 0.7731413 1.031771e-02 0.0071828708 #> 871  P1000871    0001 0.8861858    0001 0.9364322 1.185540e-02 0.0004406237 #> 872  P1000872    0000 0.4388972    0000 0.9108337 3.049830e-03 0.0438208130 #> 873  P1000873    0010 0.6476717    0010 0.8492978 5.972487e-04 0.1258462411 #> 874  P1000874    0000 0.7548798    0000 0.8998126 5.074484e-04 0.0007543529 #> 875  P1000875    0110 0.4138651    0111 0.3637572 1.404474e-01 0.9819766362 #> 876  P1000876    0101 0.6244404    0101 0.5535787 9.712184e-02 0.9899482708 #> 877  P1000877    0101 0.5970667    0101 0.3992684 7.544303e-03 0.5379115502 #> 878  P1000878    0001 0.7353965    0001 0.7802285 5.694125e-04 0.0609239941 #> 879  P1000879    0100 0.7561701    0000 0.4842299 3.144936e-04 0.3524278345 #> 880  P1000880    0011 0.6053797    0011 0.5961614 3.442721e-01 0.0888994361 #> 881  P1000881    0001 0.4055425    0001 0.6236476 1.106187e-01 0.0005208387 #> 882  P1000882    1111 0.6838402    1111 0.9275784 9.991852e-01 0.9289831702 #> 883  P1000883    0000 0.7921430    0000 0.9057893 2.324542e-04 0.0007513097 #> 884  P1000884    0101 0.6225497    0101 0.5867597 1.116803e-01 0.9208958252 #> 885  P1000885    0110 0.5262870    0111 0.4456567 2.706150e-01 0.9212253012 #> 886  P1000886    0000 0.2983921    0000 0.6831103 3.889349e-03 0.0498641885 #> 887  P1000887    0010 0.6580120    0000 0.5168523 8.033474e-03 0.0008566100 #> 888  P1000888    0000 0.9446598    0000 0.9889664 1.946025e-04 0.0007810027 #> 889  P1000889    1111 0.9634618    1111 0.9838549 9.844600e-01 0.9995244258 #> 890  P1000890    0010 0.9138734    0010 0.8409592 7.535143e-04 0.0009506892 #> 891  P1000891    0001 0.7778367    0001 0.8926988 1.200446e-02 0.0639663002 #> 892  P1000892    0001 0.3650036    0000 0.5993858 7.831455e-04 0.0448100432 #> 893  P1000893    0011 0.6779385    0011 0.5434466 1.445305e-01 0.3562693304 #> 894  P1000894    0001 0.8927069    0001 0.8759657 5.900400e-04 0.0048480850 #> 895  P1000895    1011 0.8823725    1011 0.9432296 9.890712e-01 0.0052876301 #> 896  P1000896    0000 0.5910019    0000 0.9316057 1.252042e-03 0.0237814850 #> 897  P1000897    0111 0.9805505    0111 0.9841311 1.398201e-02 0.9991260188 #> 898  P1000898    1111 0.5206991    1111 0.9883158 9.983013e-01 0.9992727281 #> 899  P1000899    0001 0.7718359    0001 0.9021772 1.224681e-02 0.0773887853 #> 900  P1000900    1111 0.9154300    1111 0.9719367 9.730256e-01 0.9992504187 #> 901  P1000901    1111 0.8948953    1111 0.9741485 9.785560e-01 0.9999278799 #> 902  P1000902    0010 0.5316298    0011 0.5280828 1.368832e-03 0.0109587686 #> 903  P1000903    0010 0.5465499    0011 0.4795274 1.066040e-04 0.0107670766 #> 904  P1000904    1000 0.6203047    0000 0.9258410 3.336403e-02 0.0007870148 #> 905  P1000905    0001 0.5554188    0000 0.5873298 3.689346e-04 0.0006425265 #> 906  P1000906    0100 0.4938962    0101 0.5801751 9.256553e-03 0.8235794019 #> 907  P1000907    1111 0.7163872    1111 0.8567292 8.637979e-01 0.9950338774 #> 908  P1000908    0000 0.4291364    0000 0.6938723 5.124408e-03 0.0046754869 #> 909  P1000909    1111 0.5772202    1111 0.9831345 9.998827e-01 0.9886950661 #> 910  P1000910    0111 0.8659397    0111 0.9533702 2.560762e-02 0.9925239477 #> 911  P1000911    0001 0.6862245    0001 0.5631975 5.579399e-03 0.0005811403 #> 912  P1000912    0001 0.8007294    0001 0.8849721 8.520883e-03 0.0024598725 #> 913  P1000913    1111 0.9576415    1111 0.9967750 9.977872e-01 0.9992866480 #> 914  P1000914    0001 0.8933002    0001 0.9435006 9.015489e-03 0.0052544487 #> 915  P1000915    1111 0.9100127    1111 0.9964304 9.985635e-01 0.9999284018 #> 916  P1000916    0101 0.6933518    0101 0.5035110 1.195820e-02 0.5254115767 #> 917  P1000917    0001 0.4740876    0001 0.7984079 1.479511e-01 0.0052342075 #> 918  P1000918    1111 0.9481594    1111 0.9834440 9.882854e-01 0.9952630809 #> 919  P1000919    1111 0.6507150    1111 0.9649167 9.981945e-01 0.9989526089 #> 920  P1000920    0111 0.5550641    0111 0.8066494 3.946868e-02 0.9939773957 #> 921  P1000921    0011 0.5847689    0011 0.4758446 1.633239e-03 0.0926672282 #> 922  P1000922    0000 0.7126791    0000 0.9033748 2.897466e-03 0.0007511130 #> 923  P1000923    1111 0.9570446    1111 0.9957180 9.984923e-01 0.9992845367 #> 924  P1000924    1111 0.6627668    1111 0.9244899 9.892631e-01 0.9385541678 #> 925  P1000925    1010 0.2937661    0000 0.1805634 4.084316e-01 0.2799693345 #> 926  P1000926    1111 0.6323939    1111 0.8895381 9.781800e-01 0.9107052136 #> 927  P1000927    0000 0.7139976    0000 0.9574924 2.606438e-03 0.0080291650 #> 928  P1000928    0001 0.9683010    0001 0.9743254 6.371084e-04 0.0067724627 #> 929  P1000929    1111 0.9088695    1111 0.9689670 9.785776e-01 0.9903218883 #> 930  P1000930    0000 0.4643197    0000 0.9693487 1.653682e-02 0.0043390070 #> 931  P1000931    0001 0.8763065    0001 0.8641582 7.308965e-03 0.0051283957 #> 932  P1000932    1110 0.3266459    1111 0.8795697 9.998703e-01 0.9065881833 #> 933  P1000933    1111 0.9621658    1111 0.9950717 9.977782e-01 0.9990672945 #> 934  P1000934    1011 0.6181269    1011 0.9545039 9.977174e-01 0.0036740029 #> 935  P1000935    1111 0.5798469    1111 0.7656276 7.686182e-01 0.9990265450 #> 936  P1000936    0000 0.4352486    0000 0.8513622 5.808947e-03 0.0008105868 #> 937  P1000937    0001 0.8405565    0001 0.7829820 5.478083e-04 0.0050927101 #> 938  P1000938    0101 0.8805802    0101 0.8135232 4.311178e-03 0.8276245753 #> 939  P1000939    1010 0.8304993    1010 0.5324431 9.969276e-01 0.0710921664 #> 940  P1000940    1111 0.8773844    1111 0.9623404 9.716634e-01 0.9907298557 #> 941  P1000941    0000 0.8269521    0000 0.9817105 1.945577e-04 0.0081121367 #> 942  P1000942    1011 0.9849732    1011 0.9886849 9.991971e-01 0.0069435422 #> 943  P1000943    0101 0.4531382    0111 0.4359478 1.431915e-01 0.8524458233 #> 944  P1000944    0011 0.3240347    0011 0.3701055 2.839707e-01 0.3704693428 #> 945  P1000945    0010 0.4222112    0010 0.3140626 1.233717e-02 0.0539683630 #> 946  P1000946    0111 0.7890369    0111 0.7912465 1.989819e-01 0.9999160472 #> 947  P1000947    1111 0.7137854    1111 0.9581409 9.805166e-01 0.9990286806 #> 948  P1000948    0001 0.7447923    0001 0.8764932 1.197266e-02 0.0774776445 #> 949  P1000949    0111 0.6418862    0111 0.7347521 2.289969e-01 0.9939679578 #> 950  P1000950    1110 0.4887657    1111 0.4732702 9.878331e-01 0.5124747515 #> 951  P1000951    0001 0.6373745    0001 0.5249655 2.255689e-03 0.0061901065 #> 952  P1000952    0001 0.8602037    0001 0.9344878 3.764982e-03 0.0369307708 #> 953  P1000953    0010 0.4914288    0000 0.6300468 1.587023e-04 0.0454185902 #> 954  P1000954    1010 0.5433307    1011 0.3311411 6.700596e-01 0.0670699276 #> 955  P1000955    0000 0.6858902    0000 0.9283888 2.530930e-03 0.0007812624 #> 956  P1000956    0010 0.8406394    0010 0.6792652 9.690811e-05 0.0116356440 #> 957  P1000957    0001 0.3994897    0000 0.5466929 1.222353e-02 0.0006480290 #> 958  P1000958    0001 0.4342273    0001 0.7695928 1.509276e-01 0.0669806302 #> 959  P1000959    0111 0.8241534    0111 0.7465192 2.484649e-01 0.9951080612 #> 960  P1000960    1001 0.7119378    1001 0.9116280 9.916590e-01 0.0050634837 #> 961  P1000961    1111 0.9299451    1111 0.9976776 9.983347e-01 0.9999285906 #> 962  P1000962    1000 0.7940436    1000 0.3875503 5.638220e-01 0.0045085197 #> 963  P1000963    0011 0.9452521    0011 0.8947060 2.031836e-03 0.0973618605 #> 964  P1000964    1101 0.9724338    1101 0.8777903 9.935300e-01 0.9807810813 #> 965  P1000965    1111 0.5510130    1111 0.8634402 9.998824e-01 0.8648555915 #> 966  P1000966    0000 0.7202965    0000 0.9093263 2.277401e-04 0.0078428469 #> 967  P1000967    1111 0.9463233    1111 0.9892027 9.985698e-01 0.9907771458 #> 968  P1000968    0000 0.7329662    0000 0.9344794 2.767742e-03 0.0007685229 #> 969  P1000969    1001 0.6549434    1001 0.4230226 5.222076e-01 0.1772808295 #> 970  P1000970    0101 0.4294979    0001 0.6245196 5.435967e-02 0.3217481661 #> 971  P1000971    0001 0.6388472    0001 0.5825090 8.259435e-03 0.0060090407 #> 972  P1000972    1101 0.9019648    1111 0.5948043 9.841874e-01 0.9988441987 #> 973  P1000973    0000 0.7967652    0000 0.9085349 2.312047e-04 0.0007522899 #> 974  P1000974    0000 0.9446598    0000 0.9889664 1.946025e-04 0.0007810027 #> 975  P1000975    0000 0.6924700    0000 0.9555984 2.606060e-03 0.0099913862 #> 976  P1000976    0111 0.6284096    0111 0.7778927 1.727722e-01 0.9878319799 #> 977  P1000977    1111 0.8512272    1111 0.9603140 9.728539e-01 0.9891875762 #> 978  P1000978    1111 0.8687931    1111 0.9885623 9.983242e-01 0.9925577454 #> 979  P1000979    0000 0.7290110    0000 0.9532928 1.125771e-03 0.0043668734 #> 980  P1000980    0101 0.7665450    0101 0.5657811 3.303857e-03 0.8341215901 #> 981  P1000981    0101 0.5734554    0101 0.3876385 5.095260e-04 0.5279665709 #> 982  P1000982    0000 0.8344100    0000 0.9866377 2.548751e-03 0.0007809451 #> 983  P1000983    1111 0.9849306    1111 0.9976711 9.985718e-01 0.9992869701 #> 984  P1000984    0111 0.8727457    0111 0.7945944 2.023281e-01 0.9989380544 #> 985  P1000985    0110 0.4718847    0111 0.7681955 9.464132e-04 0.8716851999 #> 986  P1000986    0100 0.4302118    0000 0.8982536 2.558736e-03 0.0528930588 #> 987  P1000987    0011 0.4152143    0111 0.4589632 2.462289e-02 0.5341008349 #> 988  P1000988    1110 0.9088831    1111 0.8838986 9.977896e-01 0.9908161091 #> 989  P1000989    1001 0.4280577    1001 0.5110394 9.660245e-01 0.4654571375 #> 990  P1000990    0101 0.7360181    0101 0.6855667 6.503603e-02 0.9847686150 #> 991  P1000991    1111 0.6867325    1111 0.9660892 9.882704e-01 0.9995053893 #> 992  P1000992    0111 0.9384268    0111 0.9717078 1.469562e-02 0.9991458815 #> 993  P1000993    0110 0.5535572    0010 0.5329539 1.065507e-02 0.3653731667 #> 994  P1000994    0000 0.5015082    0000 0.8504507 9.612471e-04 0.0008117809 #> 995  P1000995    0011 0.5746954    0001 0.4622887 2.560108e-03 0.0056147392 #> 996  P1000996    0110 0.3904282    0111 0.5237898 1.482678e-03 0.8905313554 #> 997  P1000997    0110 0.8391076    0110 0.6340465 7.220971e-04 0.9973494584 #> 998  P1000998    0111 0.7481172    0111 0.9165773 1.433943e-04 0.9400054396 #> 999  P1000999    0101 0.5441067    0001 0.6159468 6.192084e-04 0.3560518785 #> 1000 P1001000    0000 0.6323509    0000 0.9132869 2.672583e-03 0.0044058841 #>        post.attr3  post.attr4 #> 1    0.9690707541 0.961378697 #> 2    0.0234633194 0.993236584 #> 3    0.9996309664 0.033017501 #> 4    0.9997563739 0.999824341 #> 5    0.9972953983 0.999929038 #> 6    0.9993915348 0.994665292 #> 7    0.9999648104 0.999214201 #> 8    0.9982371499 0.999235877 #> 9    0.9998821681 0.999492348 #> 10   0.0336732346 0.079988376 #> 11   0.9997822284 0.998980149 #> 12   0.9998280272 0.999965850 #> 13   0.1321654986 0.015443392 #> 14   0.9763296586 0.999954095 #> 15   0.2447219755 0.996433931 #> 16   0.9925058155 0.999927936 #> 17   0.0204770569 0.007269940 #> 18   0.0337935225 0.564998971 #> 19   0.0030103182 0.044725261 #> 20   0.0860738443 0.548194200 #> 21   0.8344775513 0.995981239 #> 22   0.9384042675 0.989224464 #> 23   0.8396961977 0.880421188 #> 24   0.6802359911 0.999667130 #> 25   0.9998527400 0.999957315 #> 26   0.5291073808 0.997114627 #> 27   0.9958713403 0.908334831 #> 28   0.0028040254 0.007293379 #> 29   0.0113465198 0.288962519 #> 30   0.9646749760 0.999754642 #> 31   0.0267128599 0.996463102 #> 32   0.9998734487 0.999956922 #> 33   0.5907627436 0.993567589 #> 34   0.0088774107 0.983841707 #> 35   0.3128591202 0.998181729 #> 36   0.0204371081 0.828720752 #> 37   0.9929843778 0.998742650 #> 38   0.9998585950 0.992958740 #> 39   0.9668806295 0.999017907 #> 40   0.0328779595 0.153389329 #> 41   0.9999885388 0.999958039 #> 42   0.9998203791 0.999927315 #> 43   0.2318050051 0.976903519 #> 44   0.9999890762 0.999957317 #> 45   0.0028041988 0.087309101 #> 46   0.8308926443 0.999903993 #> 47   0.0027841777 0.027285058 #> 48   0.9984797475 0.999549479 #> 49   0.9459066965 0.987462428 #> 50   0.9997897674 0.999115395 #> 51   0.0289479740 0.079849942 #> 52   0.9975046648 0.999107671 #> 53   0.5963034051 0.011783558 #> 54   0.0403755354 0.007235915 #> 55   0.7284436255 0.999131921 #> 56   0.0414576936 0.006894543 #> 57   0.0204833161 0.007263353 #> 58   0.9982294907 0.999488661 #> 59   0.0180820181 0.997215540 #> 60   0.9979892335 0.999945048 #> 61   0.9999891262 0.999475720 #> 62   0.8635399169 0.999921063 #> 63   0.0951596677 0.046171127 #> 64   0.0028429300 0.007121736 #> 65   0.8737197770 0.838374994 #> 66   0.6204586218 0.999581078 #> 67   0.9974710425 0.999106038 #> 68   0.9990197023 0.988782514 #> 69   0.7559075729 0.005382022 #> 70   0.2774010474 0.024934172 #> 71   0.0386555221 0.987905780 #> 72   0.9979010980 0.999463416 #> 73   0.9844970360 0.999788079 #> 74   0.4117324796 0.916154542 #> 75   0.9766946084 0.005216835 #> 76   0.0027765208 0.041872394 #> 77   0.9996606967 0.996694832 #> 78   0.9997550577 0.999930611 #> 79   0.9732678783 0.999120631 #> 80   0.0192443688 0.982254325 #> 81   0.0344151766 0.007210637 #> 82   0.0204813929 0.007265377 #> 83   0.2504859091 0.998475577 #> 84   0.0192085656 0.990889268 #> 85   0.0028031073 0.007280061 #> 86   0.2184000189 0.999699125 #> 87   0.2528540888 0.006567814 #> 88   0.9955511004 0.989949747 #> 89   0.9984959759 0.996156027 #> 90   0.9967170152 0.985740116 #> 91   0.0026084126 0.279230218 #> 92   0.0028041988 0.087309101 #> 93   0.0938941378 0.894100695 #> 94   0.0072234756 0.999872079 #> 95   0.9985460505 0.999944958 #> 96   0.9997938797 0.998973496 #> 97   0.9998277981 0.999368614 #> 98   0.9996159599 0.999233035 #> 99   0.9995642191 0.999140541 #> 100  0.0020106532 0.940219621 #> 101  0.0187281829 0.286234940 #> 102  0.6807884756 0.999916574 #> 103  0.9997170013 0.999994950 #> 104  0.9976435070 0.999845015 #> 105  0.9978256238 0.999996486 #> 106  0.9609425237 0.999950268 #> 107  0.1624037058 0.006918496 #> 108  0.6223574121 0.999950622 #> 109  0.9997967392 0.999985660 #> 110  0.9184153016 0.985092126 #> 111  0.9998807964 0.999996727 #> 112  0.9692130998 0.961490225 #> 113  0.0028031073 0.007280061 #> 114  0.1499802772 0.906000733 #> 115  0.9998614626 0.999996754 #> 116  0.1466607460 0.895309506 #> 117  0.9997713532 0.999739861 #> 118  0.9845361082 0.999925175 #> 119  0.9975788223 0.999103152 #> 120  0.0148807678 0.027843899 #> 121  0.0027973443 0.007324338 #> 122  0.0344843582 0.007186432 #> 123  0.9964289699 0.998843250 #> 124  0.9999891062 0.999605122 #> 125  0.0295287420 0.007221368 #> 126  0.8497641741 0.061172635 #> 127  0.0026970752 0.110153435 #> 128  0.9978393895 0.999331760 #> 129  0.0028031481 0.027465013 #> 130  0.9472258884 0.999497250 #> 131  0.9998520520 0.999416239 #> 132  0.8446766085 0.951924450 #> 133  0.9841855354 0.998869972 #> 134  0.0120967936 0.080211271 #> 135  0.0394941044 0.087097687 #> 136  0.7959380578 0.998534349 #> 137  0.0028031073 0.007280061 #> 138  0.9982615325 0.999647782 #> 139  0.9998613976 0.999563345 #> 140  0.0143986419 0.049220157 #> 141  0.0343570106 0.007247336 #> 142  0.0019847750 0.954403170 #> 143  0.0007384730 0.904140769 #> 144  0.0834045691 0.078719840 #> 145  0.0148539462 0.030885933 #> 146  0.0289451146 0.079862001 #> 147  0.9984853306 0.999996704 #> 148  0.9982083736 0.999996706 #> 149  0.9984944542 0.992372701 #> 150  0.0172212621 0.242484712 #> 151  0.9997950969 0.999414237 #> 152  0.9985085082 0.999956067 #> 153  0.9997134881 0.999923561 #> 154  0.9999881656 0.996391797 #> 155  0.0171284881 0.543933198 #> 156  0.5100343553 0.769135686 #> 157  0.9979270918 0.999488707 #> 158  0.0344151766 0.007210637 #> 159  0.9999891134 0.999996775 #> 160  0.9780851967 0.999996724 #> 161  0.9730027428 0.999994584 #> 162  0.9998748363 0.999423825 #> 163  0.0029119135 0.418882405 #> 164  0.8256386008 0.871877275 #> 165  0.0025191770 0.989634201 #> 166  0.9379594696 0.067502320 #> 167  0.1056754239 0.007046606 #> 168  0.0028089269 0.007255917 #> 169  0.0018817222 0.845550341 #> 170  0.0027838983 0.027292565 #> 171  0.0141109553 0.009865776 #> 172  0.9998267232 0.999996462 #> 173  0.0027339281 0.088200457 #> 174  0.0087496404 0.997480699 #> 175  0.8395925788 0.998861775 #> 176  0.0331724172 0.148569010 #> 177  0.3102470544 0.977941110 #> 178  0.9998818194 0.999472115 #> 179  0.9975583098 0.989929512 #> 180  0.4868961360 0.999943324 #> 181  0.0027892887 0.027147733 #> 182  0.9998006914 0.985648003 #> 183  0.9989229136 0.999983068 #> 184  0.0027892887 0.027147733 #> 185  0.0669722970 0.642480765 #> 186  0.9998497717 0.999976806 #> 187  0.9997057088 0.999957370 #> 188  0.9923674626 0.059572348 #> 189  0.0024415792 0.984852865 #> 190  0.9998614047 0.999961128 #> 191  0.0025006425 0.304461455 #> 192  0.9872245481 0.998645565 #> 193  0.9450792244 0.865513532 #> 194  0.7475057871 0.999995762 #> 195  0.9999872195 0.991718036 #> 196  0.9950837278 0.861587820 #> 197  0.0147683616 0.046992385 #> 198  0.3483075425 0.006521282 #> 199  0.2318050051 0.976903519 #> 200  0.1099803330 0.873484640 #> 201  0.9998342075 0.999955221 #> 202  0.9971351559 0.844530557 #> 203  0.0025125526 0.376159832 #> 204  0.0025900713 0.277696014 #> 205  0.9652802437 0.999856238 #> 206  0.9997315587 0.996520800 #> 207  0.0906496878 0.873005730 #> 208  0.2048376708 0.976624076 #> 209  0.9998492509 0.879899122 #> 210  0.9880829011 0.999704906 #> 211  0.0103982625 0.536250389 #> 212  0.9976125845 0.999037244 #> 213  0.0010293430 0.923317538 #> 214  0.9390062096 0.527082503 #> 215  0.0298234053 0.995181982 #> 216  0.9985324768 0.826776855 #> 217  0.9945757671 0.999139415 #> 218  0.9985185408 0.999257561 #> 219  0.8605613891 0.929596734 #> 220  0.0341867651 0.027035588 #> 221  0.9999889421 0.999956717 #> 222  0.3913622752 0.386632266 #> 223  0.0028055966 0.007286816 #> 224  0.0282846352 0.114502502 #> 225  0.8395051100 0.896975476 #> 226  0.9998275064 0.999952003 #> 227  0.9984843319 0.999956586 #> 228  0.9998361565 0.999955814 #> 229  0.0244482446 0.967240961 #> 230  0.9999768962 0.999412636 #> 231  0.9998232850 0.999460174 #> 232  0.0472724896 0.405942089 #> 233  0.9678834826 0.079239526 #> 234  0.1986091068 0.254687983 #> 235  0.0214417912 0.999677263 #> 236  0.9974020192 0.999924996 #> 237  0.9806136106 0.999946301 #> 238  0.9996333065 0.999567069 #> 239  0.0400007231 0.041627185 #> 240  0.1444307446 0.829718367 #> 241  0.0234335792 0.968601899 #> 242  0.1808700362 0.142380877 #> 243  0.9969091854 0.999985308 #> 244  0.0295287420 0.007221368 #> 245  0.9998593140 0.999960397 #> 246  0.0230830751 0.916617334 #> 247  0.0027973443 0.007324338 #> 248  0.0027261065 0.091225327 #> 249  0.9998338981 0.999996437 #> 250  0.9993432968 0.954355040 #> 251  0.0171589305 0.346993679 #> 252  0.9997497340 0.999162498 #> 253  0.0027345282 0.088016760 #> 254  0.0142751194 0.050352948 #> 255  0.9994098468 0.999600141 #> 256  0.9990179984 0.988656885 #> 257  0.1596587363 0.046839527 #> 258  0.0113393095 0.864167131 #> 259  0.9988768180 0.999134512 #> 260  0.9998542445 0.999445744 #> 261  0.0176545671 0.381323113 #> 262  0.0882730120 0.027123265 #> 263  0.9997990179 0.866977549 #> 264  0.0020103073 0.994817421 #> 265  0.1349477705 0.183279967 #> 266  0.9997078180 0.999954002 #> 267  0.6677181252 0.069777722 #> 268  0.7775466485 0.032797594 #> 269  0.9997821293 0.996952173 #> 270  0.0029220282 0.043597434 #> 271  0.9801928455 0.964950295 #> 272  0.9628266454 0.999825168 #> 273  0.0028381181 0.028801416 #> 274  0.6266982811 0.986821094 #> 275  0.9999808860 0.998962958 #> 276  0.0156667671 0.043985899 #> 277  0.2061239389 0.075825960 #> 278  0.9980654349 0.999949485 #> 279  0.9993614142 0.999064757 #> 280  0.0241543274 0.995035228 #> 281  0.9998367705 0.999956091 #> 282  0.0028037574 0.007295427 #> 283  0.9999874294 0.999466977 #> 284  0.0024887737 0.997162186 #> 285  0.0026739910 0.154667016 #> 286  0.9458874172 0.984692912 #> 287  0.9894102138 0.998989271 #> 288  0.0022569631 0.705869692 #> 289  0.9999889008 0.999954952 #> 290  0.9997819798 0.999144203 #> 291  0.9365117246 0.962900738 #> 292  0.9978956684 0.999957119 #> 293  0.9997080684 0.999996475 #> 294  0.9998363462 0.999955879 #> 295  0.0024023780 0.781160832 #> 296  0.0020786638 0.845616328 #> 297  0.9998089745 0.999295621 #> 298  0.0236111518 0.991020425 #> 299  0.8095910476 0.998663078 #> 300  0.9984043962 0.999512889 #> 301  0.9982154071 0.999956874 #> 302  0.9997789173 0.988291204 #> 303  0.0256687675 0.981065263 #> 304  0.0027847411 0.029691387 #> 305  0.9696124659 0.999690609 #> 306  0.9998340426 0.992982440 #> 307  0.9712415087 0.999793575 #> 308  0.9999887562 0.994602903 #> 309  0.0122208049 0.041777866 #> 310  0.9969844863 0.978812758 #> 311  0.9760872298 0.999993205 #> 312  0.0122208049 0.041777866 #> 313  0.0343538302 0.007249342 #> 314  0.0028031073 0.007280061 #> 315  0.0027973443 0.007324338 #> 316  0.1991120811 0.998078947 #> 317  0.9978346628 0.989703006 #> 318  0.0295395726 0.999849858 #> 319  0.9877400648 0.988669212 #> 320  0.0025071493 0.988702025 #> 321  0.0227450486 0.902148343 #> 322  0.0852885337 0.007172872 #> 323  0.9998362179 0.999957312 #> 324  0.1195169716 0.007099482 #> 325  0.7381609978 0.999306186 #> 326  0.9954074377 0.998987387 #> 327  0.1395954307 0.998127348 #> 328  0.9978255213 0.999952170 #> 329  0.1291176012 0.334532981 #> 330  0.0668896668 0.978978991 #> 331  0.9998607405 0.993086964 #> 332  0.9982033597 0.999956910 #> 333  0.0392101248 0.377179319 #> 334  0.0344151766 0.007210637 #> 335  0.9998595305 0.999964897 #> 336  0.9998614082 0.999418943 #> 337  0.9973133221 0.998779679 #> 338  0.9997424299 0.998878909 #> 339  0.0142476561 0.050596005 #> 340  0.9984843687 0.993059829 #> 341  0.4634360760 0.998127664 #> 342  0.9998803712 0.999960595 #> 343  0.9462352697 0.078053437 #> 344  0.9914198977 0.999128393 #> 345  0.5490089972 0.999852365 #> 346  0.1501641932 0.575768143 #> 347  0.0028031073 0.007280061 #> 348  0.7061269667 0.999816575 #> 349  0.0240922539 0.997668897 #> 350  0.9999885722 0.999394535 #> 351  0.0028028717 0.007301222 #> 352  0.9960250755 0.999937660 #> 353  0.9997683471 0.996736747 #> 354  0.9971532982 0.993502555 #> 355  0.0028089269 0.007255917 #> 356  0.9977622442 0.999724275 #> 357  0.9760126812 0.999685045 #> 358  0.9706495888 0.999945045 #> 359  0.9145639444 0.997705730 #> 360  0.9973341688 0.843604234 #> 361  0.0289000367 0.087022467 #> 362  0.9999890679 0.999955797 #> 363  0.6973953523 0.417719137 #> 364  0.9999891093 0.999474695 #> 365  0.8196383437 0.961095555 #> 366  0.9614075053 0.999418397 #> 367  0.9998819134 0.999955912 #> 368  0.9559601018 0.815553605 #> 369  0.9972177779 0.998873081 #> 370  0.9740280099 0.999414800 #> 371  0.0028031073 0.007280061 #> 372  0.7343907060 0.999991896 #> 373  0.9775243678 0.999188336 #> 374  0.9626176039 0.005200740 #> 375  0.0460203411 0.047938657 #> 376  0.9998217860 0.999928032 #> 377  0.9795420956 0.998172626 #> 378  0.6914447831 0.325998747 #> 379  0.0028105005 0.007249388 #> 380  0.9474803590 0.999945739 #> 381  0.9891313144 0.999141270 #> 382  0.9725126664 0.998671989 #> 383  0.9885941632 0.078476215 #> 384  0.9979192410 0.993091981 #> 385  0.9975932720 0.999659241 #> 386  0.9981041113 0.999568084 #> 387  0.9997500135 0.423783033 #> 388  0.9668224526 0.999961382 #> 389  0.8823647001 0.998936995 #> 390  0.9998176145 0.999044166 #> 391  0.0089702374 0.964957669 #> 392  0.9783087935 0.999264839 #> 393  0.0205184909 0.007226337 #> 394  0.1251259617 0.990183963 #> 395  0.5361525124 0.294486989 #> 396  0.9883003800 0.997208387 #> 397  0.9279436957 0.999117489 #> 398  0.9750944718 0.999282278 #> 399  0.7803880486 0.991410080 #> 400  0.9998691641 0.893420689 #> 401  0.9998799610 0.999956489 #> 402  0.5001961311 0.069919673 #> 403  0.9997682853 0.996716981 #> 404  0.0028031073 0.007280061 #> 405  0.9998737225 0.999977227 #> 406  0.9999889030 0.999960401 #> 407  0.9931299168 0.998929895 #> 408  0.0344236120 0.007214673 #> 409  0.0028031073 0.007280061 #> 410  0.1963294563 0.006701235 #> 411  0.9978221019 0.999952073 #> 412  0.9883955248 0.864214409 #> 413  0.9955015830 0.994682989 #> 414  0.9999889070 0.999604264 #> 415  0.9962173194 0.999956320 #> 416  0.9994974350 0.999027754 #> 417  0.9999890181 0.999996737 #> 418  0.9699617531 0.995745866 #> 419  0.1536040677 0.009358135 #> 420  0.6304299860 0.022108224 #> 421  0.6559866081 0.981592448 #> 422  0.9862691549 0.075621764 #> 423  0.9998112744 0.999993599 #> 424  0.9979278150 0.999955796 #> 425  0.2473338488 0.752291366 #> 426  0.1948399144 0.929324357 #> 427  0.0604334685 0.844189211 #> 428  0.9953695332 0.999580332 #> 429  0.1342794785 0.077953772 #> 430  0.9998783061 0.994602457 #> 431  0.9777643336 0.999954492 #> 432  0.1256723948 0.810437259 #> 433  0.0146131690 0.047918880 #> 434  0.1816013001 0.085626238 #> 435  0.0027394724 0.090422393 #> 436  0.8376962497 0.987258240 #> 437  0.5916613524 0.963735580 #> 438  0.9997118177 0.999888790 #> 439  0.9981694212 0.999949002 #> 440  0.4682547622 0.998743533 #> 441  0.9998364492 0.999961243 #> 442  0.9984113955 0.999953703 #> 443  0.9975309922 0.999613719 #> 444  0.0114506548 0.249957491 #> 445  0.9840064602 0.996429891 #> 446  0.0387632201 0.997505270 #> 447  0.9763179276 0.999450181 #> 448  0.5620545145 0.999923848 #> 449  0.9290228797 0.006372782 #> 450  0.9971027653 0.989677528 #> 451  0.2062567934 0.971914446 #> 452  0.9656459049 0.999302277 #> 453  0.0025727959 0.268753950 #> 454  0.1893145774 0.006782774 #> 455  0.1803086387 0.054048496 #> 456  0.9998802723 0.999464246 #> 457  0.0148539462 0.030885933 #> 458  0.9997787182 0.998906713 #> 459  0.0245207656 0.567149468 #> 460  0.2538823226 0.006526632 #> 461  0.0736330782 0.050918410 #> 462  0.0027054242 0.149076179 #> 463  0.0020013934 0.940347999 #> 464  0.0882799445 0.027139653 #> 465  0.1368030112 0.052844025 #> 466  0.0140805365 0.087483179 #> 467  0.8190075789 0.981260413 #> 468  0.5925043971 0.926237877 #> 469  0.0027340709 0.081155866 #> 470  0.1917515099 0.519766374 #> 471  0.8494733838 0.066846358 #> 472  0.9998594602 0.999956942 #> 473  0.9998778105 0.999390013 #> 474  0.0018063737 0.973520580 #> 475  0.0408678185 0.007077869 #> 476  0.0401196619 0.903005430 #> 477  0.5024027637 0.064374298 #> 478  0.9750148643 0.997665409 #> 479  0.9922896260 0.993144881 #> 480  0.9783156226 0.999240956 #> 481  0.0024429817 0.998949633 #> 482  0.9967543531 0.999924731 #> 483  0.0299505070 0.998375019 #> 484  0.9997791954 0.999869938 #> 485  0.0123365676 0.007263038 #> 486  0.1847705011 0.039701931 #> 487  0.0748987850 0.999060076 #> 488  0.9999890848 0.999957353 #> 489  0.9994979755 0.999928553 #> 490  0.1115989004 0.006829089 #> 491  0.7605266148 0.005287554 #> 492  0.1021104911 0.007058926 #> 493  0.9979892335 0.999945048 #> 494  0.9404925001 0.999891028 #> 495  0.9779809166 0.992996697 #> 496  0.9979274172 0.999955782 #> 497  0.0400007231 0.041627185 #> 498  0.0027979473 0.007319705 #> 499  0.3483075425 0.006521282 #> 500  0.9200384308 0.999899937 #> 501  0.0025563832 0.287779071 #> 502  0.2953896020 0.989023264 #> 503  0.0027979473 0.007319705 #> 504  0.3133146305 0.006598132 #> 505  0.9985075814 0.999419696 #> 506  0.9972717665 0.999344421 #> 507  0.7436865472 0.005661551 #> 508  0.0285694242 0.982573681 #> 509  0.2605461889 0.257725760 #> 510  0.9598181811 0.930648268 #> 511  0.9955217384 0.999104140 #> 512  0.9997988263 0.999933192 #> 513  0.2568425848 0.325062574 #> 514  0.0006630506 0.999424882 #> 515  0.0144301118 0.048940905 #> 516  0.9710854961 0.984473874 #> 517  0.9998551731 0.999451518 #> 518  0.9998598148 0.999996711 #> 519  0.0024686753 0.423118123 #> 520  0.9981175007 0.909985023 #> 521  0.0196153949 0.944078016 #> 522  0.9997389340 0.998859585 #> 523  0.0027789484 0.029787970 #> 524  0.9997163263 0.875123857 #> 525  0.0337383277 0.079751559 #> 526  0.0229131367 0.998542734 #> 527  0.9998213917 0.999993356 #> 528  0.9997898675 0.999145314 #> 529  0.0234544918 0.992315403 #> 530  0.9942413255 0.999825552 #> 531  0.9997633620 0.941676311 #> 532  0.9780857530 0.999484388 #> 533  0.0351209175 0.006963719 #> 534  0.0336021194 0.080386109 #> 535  0.8902370553 0.515228298 #> 536  0.7684613799 0.993822448 #> 537  0.5227078723 0.438378217 #> 538  0.9628785841 0.999899251 #> 539  0.9996643994 0.382021123 #> 540  0.9780381504 0.999955193 #> 541  0.9929328278 0.341785446 #> 542  0.1361384525 0.026088232 #> 543  0.9983582267 0.929450325 #> 544  0.9868202665 0.964345748 #> 545  0.8495561499 0.828543400 #> 546  0.9975071654 0.963632793 #> 547  0.6039937067 0.961693691 #> 548  0.9872875837 0.988404621 #> 549  0.9998362325 0.999996756 #> 550  0.5648545287 0.999294334 #> 551  0.0023491770 0.563545269 #> 552  0.9663148032 0.080207897 #> 553  0.2078338919 0.999775201 #> 554  0.9675986950 0.989526766 #> 555  0.9998765700 0.999958365 #> 556  0.0612273089 0.050254009 #> 557  0.9740193694 0.999952283 #> 558  0.0886909282 0.753221228 #> 559  0.0264221473 0.834697377 #> 560  0.0932339148 0.006863645 #> 561  0.9974684500 0.999584526 #> 562  0.9998250815 0.999977228 #> 563  0.0123825120 0.007324917 #> 564  0.9998165301 0.953153815 #> 565  0.9955064030 0.994661459 #> 566  0.9999586526 0.649242084 #> 567  0.0028031073 0.007280061 #> 568  0.1589075271 0.997892003 #> 569  0.9782954357 0.999264056 #> 570  0.0811873579 0.999816278 #> 571  0.0340728374 0.541582948 #> 572  0.8247465059 0.354903018 #> 573  0.7146801243 0.999911653 #> 574  0.0006802793 0.999325925 #> 575  0.0020301792 0.949654739 #> 576  0.8673592562 0.999715869 #> 577  0.7229754069 0.989595970 #> 578  0.9974777987 0.989745009 #> 579  0.9998795077 0.996257560 #> 580  0.9979800228 0.990294264 #> 581  0.6857005390 0.997052707 #> 582  0.9998504096 0.915457795 #> 583  0.9921972942 0.999843453 #> 584  0.9955384043 0.994143336 #> 585  0.9973392001 0.986231144 #> 586  0.0028348735 0.007155264 #> 587  0.9997370575 0.999552365 #> 588  0.9980894975 0.999976968 #> 589  0.0027982148 0.007317650 #> 590  0.0028031073 0.007280061 #> 591  0.9772902725 0.005116260 #> 592  0.9996802498 0.996480297 #> 593  0.9979343648 0.999474174 #> 594  0.9895371662 0.999926458 #> 595  0.9847570071 0.999982695 #> 596  0.9982129584 0.958303592 #> 597  0.0149915350 0.007436560 #> 598  0.0346635960 0.276030404 #> 599  0.6231275001 0.979209060 #> 600  0.0204770569 0.007269940 #> 601  0.9978229380 0.999996481 #> 602  0.9980253731 0.999624218 #> 603  0.0027350783 0.081087263 #> 604  0.8627739759 0.999919963 #> 605  0.0028038168 0.007284509 #> 606  0.9626552327 0.999909081 #> 607  0.9878090621 0.981463721 #> 608  0.0320468195 0.856821666 #> 609  0.9999873324 0.999365839 #> 610  0.0255935457 0.772996149 #> 611  0.3467898113 0.026604222 #> 612  0.0344123759 0.007230695 #> 613  0.0027114491 0.033445635 #> 614  0.9780388055 0.999996709 #> 615  0.0020477663 0.887266809 #> 616  0.7934721337 0.023828693 #> 617  0.0946491990 0.999958710 #> 618  0.9949272960 0.998898090 #> 619  0.0118494345 0.085182772 #> 620  0.8589750302 0.839181664 #> 621  0.6672779695 0.069907382 #> 622  0.2240914636 0.996180809 #> 623  0.0284316494 0.985462659 #> 624  0.1426696939 0.974731946 #> 625  0.9997686516 0.997019065 #> 626  0.5074159866 0.752809866 #> 627  0.9982501996 0.273134870 #> 628  0.9998635213 0.999947321 #> 629  0.0286089893 0.006466327 #> 630  0.0144316676 0.048967457 #> 631  0.0027892887 0.027147733 #> 632  0.0029166513 0.045558522 #> 633  0.0123560501 0.007344920 #> 634  0.9979258806 0.999488291 #> 635  0.9997981872 0.999980872 #> 636  0.2621955694 0.628491677 #> 637  0.2374641385 0.771666141 #> 638  0.9978311344 0.999529924 #> 639  0.1420182694 0.936017365 #> 640  0.7618780814 0.999824342 #> 641  0.9962382099 0.989586035 #> 642  0.9990100283 0.988640007 #> 643  0.8696860354 0.281183936 #> 644  0.0125282146 0.007123209 #> 645  0.9970432204 0.864910224 #> 646  0.0004994087 0.957682972 #> 647  0.9984245414 0.999444887 #> 648  0.9977192890 0.999940593 #> 649  0.9997670265 0.988429921 #> 650  0.9999885824 0.999958308 #> 651  0.9990213836 0.987241620 #> 652  0.9872763014 0.999927949 #> 653  0.0013004700 0.895503771 #> 654  0.0144301118 0.048940905 #> 655  0.1621209822 0.006942894 #> 656  0.9998614914 0.999961168 #> 657  0.0302076359 0.886960270 #> 658  0.9998169401 0.999126391 #> 659  0.9979154205 0.999955487 #> 660  0.9999873809 0.999307266 #> 661  0.8704384522 0.862413295 #> 662  0.7338899365 0.999947065 #> 663  0.0274565337 0.962494821 #> 664  0.9996827284 0.990144921 #> 665  0.9999890670 0.999742903 #> 666  0.9999856655 0.999962795 #> 667  0.9999890895 0.999955915 #> 668  0.9997487178 0.954828571 #> 669  0.9977906547 0.999957039 #> 670  0.9998593606 0.999956934 #> 671  0.0384753546 0.997088786 #> 672  0.1394702210 0.999582785 #> 673  0.8859179800 0.984600221 #> 674  0.0027339674 0.357979067 #> 675  0.9679364681 0.998697840 #> 676  0.5775212499 0.332352443 #> 677  0.9998176910 0.999950262 #> 678  0.9995548806 0.993559908 #> 679  0.0210675681 0.974985034 #> 680  0.9974090894 0.999025581 #> 681  0.3133692404 0.006598585 #> 682  0.7910361547 0.030197743 #> 683  0.9966453913 0.994636766 #> 684  0.9999883773 0.999419303 #> 685  0.0120378926 0.087827650 #> 686  0.8059493637 0.920709034 #> 687  0.0027672382 0.360239371 #> 688  0.3075468964 0.080706048 #> 689  0.0028203951 0.027645262 #> 690  0.0028031073 0.007280061 #> 691  0.9982387813 0.999471524 #> 692  0.0028334144 0.007161336 #> 693  0.3167190549 0.998257146 #> 694  0.0403671607 0.007240418 #> 695  0.9515790064 0.996905844 #> 696  0.0028031073 0.007280061 #> 697  0.0125282146 0.007123209 #> 698  0.9998614077 0.999471334 #> 699  0.0232453479 0.974742371 #> 700  0.7019148953 0.996923847 #> 701  0.9855635964 0.999926238 #> 702  0.9404846742 0.998573672 #> 703  0.0852885337 0.007172872 #> 704  0.5033607643 0.036076825 #> 705  0.9955470462 0.989485613 #> 706  0.9994974350 0.999027754 #> 707  0.9999798346 0.999992324 #> 708  0.0303884511 0.831799491 #> 709  0.0218429488 0.885925350 #> 710  0.8218057767 0.959458427 #> 711  0.9892959181 0.991156939 #> 712  0.9999890917 0.999961248 #> 713  0.9967023426 0.834361258 #> 714  0.0028037574 0.007295427 #> 715  0.9979530529 0.991275451 #> 716  0.9999839226 0.999077333 #> 717  0.9999672933 0.953651303 #> 718  0.0019735321 0.966470176 #> 719  0.9915672453 0.829537875 #> 720  0.9981118919 0.999993744 #> 721  0.9977436245 0.999052295 #> 722  0.9998108702 0.999929526 #> 723  0.9450674610 0.841720227 #> 724  0.0379238612 0.271182354 #> 725  0.9965094103 0.999981277 #> 726  0.9796455871 0.986513507 #> 727  0.0226161197 0.007026063 #> 728  0.9998615373 0.999961184 #> 729  0.0245171038 0.009092398 #> 730  0.0884056930 0.007033542 #> 731  0.9998155353 0.998837224 #> 732  0.5275870769 0.990030320 #> 733  0.9998356096 0.999556024 #> 734  0.8650369910 0.075765470 #> 735  0.0401875288 0.030239287 #> 736  0.0027700691 0.007543015 #> 737  0.9740529013 0.530124680 #> 738  0.0028105005 0.007249388 #> 739  0.1361384525 0.026088232 #> 740  0.9956469410 0.999977075 #> 741  0.0197251641 0.277662555 #> 742  0.9765444982 0.998768934 #> 743  0.5655134173 0.999939070 #> 744  0.6061897512 0.811461669 #> 745  0.9998758046 0.999996489 #> 746  0.9982303448 0.999955803 #> 747  0.8545934691 0.998805422 #> 748  0.9764015209 0.998937480 #> 749  0.0405498278 0.007166628 #> 750  0.9976697939 0.999775063 #> 751  0.2388616173 0.995337805 #> 752  0.9962435930 0.995098923 #> 753  0.1819263002 0.999405495 #> 754  0.0113802679 0.277491252 #> 755  0.9762632021 0.999716531 #> 756  0.9980428435 0.988663395 #> 757  0.9970881281 0.904740529 #> 758  0.8634732507 0.998833107 #> 759  0.9993210878 0.999843728 #> 760  0.9958468781 0.999832215 #> 761  0.0162583033 0.234694734 #> 762  0.0030528892 0.406120385 #> 763  0.9768113179 0.988992704 #> 764  0.0025997633 0.250399568 #> 765  0.9778349896 0.999996672 #> 766  0.1141617723 0.981008160 #> 767  0.9963688707 0.999205047 #> 768  0.9967600766 0.866372060 #> 769  0.0028031073 0.007280061 #> 770  0.0157824806 0.030046890 #> 771  0.1999361322 0.901002805 #> 772  0.9959430130 0.999927332 #> 773  0.9954739016 0.983473789 #> 774  0.9981502035 0.999996510 #> 775  0.9989691523 0.999774470 #> 776  0.9962259956 0.999506732 #> 777  0.0147379835 0.080251195 #> 778  0.0028031073 0.007280061 #> 779  0.0027206375 0.032924051 #> 780  0.9999888652 0.999414070 #> 781  0.0027332203 0.088251733 #> 782  0.9998142913 0.999996174 #> 783  0.0028105005 0.007249388 #> 784  0.0028089269 0.007255917 #> 785  0.1369553199 0.006966989 #> 786  0.9391103392 0.630779269 #> 787  0.9998816182 0.993332160 #> 788  0.9943757507 0.979258747 #> 789  0.0012344171 0.998446304 #> 790  0.9652920559 0.975679699 #> 791  0.4460752575 0.915829334 #> 792  0.0295287420 0.007221368 #> 793  0.9643242948 0.999993605 #> 794  0.5008247913 0.065772060 #> 795  0.0146952009 0.087615302 #> 796  0.0029569436 0.043983818 #> 797  0.9543965214 0.999955995 #> 798  0.9994922112 0.988453906 #> 799  0.9998287132 0.999451461 #> 800  0.9998232315 0.999960066 #> 801  0.9993605684 0.987714152 #> 802  0.1095993344 0.398655954 #> 803  0.9997681037 0.997024758 #> 804  0.9999889425 0.999996711 #> 805  0.0207303883 0.974571764 #> 806  0.1339519644 0.087184537 #> 807  0.9969402617 0.991734148 #> 808  0.9978337882 0.999958214 #> 809  0.8542445806 0.836406968 #> 810  0.9998804080 0.999956754 #> 811  0.9783351648 0.816688175 #> 812  0.8951486393 0.928870185 #> 813  0.0027973443 0.007324338 #> 814  0.0203446609 0.754203188 #> 815  0.6532275458 0.323516029 #> 816  0.9881485880 0.998774616 #> 817  0.0027982148 0.007317650 #> 818  0.0113832878 0.268139927 #> 819  0.9136920067 0.077324255 #> 820  0.0028089269 0.007255917 #> 821  0.9937182808 0.999811486 #> 822  0.9579741339 0.993699952 #> 823  0.0027021277 0.083393688 #> 824  0.0124930028 0.007156845 #> 825  0.9221900556 0.999743275 #> 826  0.3910257036 0.999427999 #> 827  0.9999890638 0.999966776 #> 828  0.1800713677 0.989163581 #> 829  0.1077901672 0.660643979 #> 830  0.9998248332 0.999996405 #> 831  0.9997980251 0.993919087 #> 832  0.9996161099 0.999233411 #> 833  0.0237171971 0.997624527 #> 834  0.9697720768 0.991093091 #> 835  0.0112234325 0.992860304 #> 836  0.0266433309 0.996744563 #> 837  0.9999696086 0.999987304 #> 838  0.9771601408 0.999207491 #> 839  0.8600543567 0.075592450 #> 840  0.9899308464 0.999125110 #> 841  0.9972262996 0.999042321 #> 842  0.9985023226 0.999435744 #> 843  0.0025362628 0.876564801 #> 844  0.9982113874 0.999484223 #> 845  0.9999884822 0.991819874 #> 846  0.0341278907 0.029505930 #> 847  0.9998299013 0.999538533 #> 848  0.0123365676 0.007263038 #> 849  0.9993423551 0.542072580 #> 850  0.9974179573 0.660978557 #> 851  0.0027973443 0.007324338 #> 852  0.0028031073 0.007280061 #> 853  0.9999891094 0.999492175 #> 854  0.0234660779 0.997840036 #> 855  0.0922273023 0.762959178 #> 856  0.1347874711 0.043536977 #> 857  0.0027832684 0.027309490 #> 858  0.4530546822 0.063557728 #> 859  0.0116588808 0.604717147 #> 860  0.9902998812 0.170166083 #> 861  0.0006616643 0.899549703 #> 862  0.9998252746 0.999957136 #> 863  0.9981118919 0.999993744 #> 864  0.9997428124 0.998981846 #> 865  0.0091253669 0.876621386 #> 866  0.0028086448 0.007257087 #> 867  0.9998615144 0.999996756 #> 868  0.9997692175 0.999451095 #> 869  0.0855565241 0.009644669 #> 870  0.2063986144 0.993750549 #> 871  0.0232131668 0.971374863 #> 872  0.0028007435 0.042454995 #> 873  0.9789243807 0.004853996 #> 874  0.0120378926 0.087827650 #> 875  0.7116900659 0.669915889 #> 876  0.3520100387 0.997304856 #> 877  0.2305401341 0.999770858 #> 878  0.0021344097 0.835898583 #> 879  0.0028240083 0.278021109 #> 880  0.9991422954 0.999846876 #> 881  0.0192138729 0.742147174 #> 882  0.9998669827 0.999399136 #> 883  0.0027321872 0.090772809 #> 884  0.2569442882 0.999971637 #> 885  0.9927176529 0.729664332 #> 886  0.0379064409 0.252762388 #> 887  0.4527081629 0.063905528 #> 888  0.0028031073 0.007280061 #> 889  0.9998773942 0.999977821 #> 890  0.9160315259 0.077795498 #> 891  0.0020049396 0.967877073 #> 892  0.0111384675 0.366426489 #> 893  0.9854843515 0.999236941 #> 894  0.0227687683 0.901852678 #> 895  0.9579554750 0.999740919 #> 896  0.0027892369 0.042127924 #> 897  0.9998201539 0.999145657 #> 898  0.9975476689 0.993075943 #> 899  0.0019907462 0.992447555 #> 900  0.9998736918 0.999727462 #> 901  0.9956787990 0.999957737 #> 902  0.9993393998 0.533656545 #> 903  0.9483281989 0.502981828 #> 904  0.0335287806 0.007769894 #> 905  0.0178881786 0.403778032 #> 906  0.0382028556 0.735365586 #> 907  0.9969664828 0.999937629 #> 908  0.0187281829 0.286234940 #> 909  0.9998330813 0.994638740 #> 910  0.9945316591 0.991353192 #> 911  0.0023174098 0.569096889 #> 912  0.0973389563 0.991331318 #> 913  0.9999890541 0.999707198 #> 914  0.0233853405 0.980497619 #> 915  0.9985044796 0.999419675 #> 916  0.0268740196 0.999939235 #> 917  0.0256751291 0.973401061 #> 918  0.9998776677 0.999953455 #> 919  0.9675675720 0.999956218 #> 920  0.8318346094 0.999920818 #> 921  0.5412269832 0.975990221 #> 922  0.0027264216 0.091201878 #> 923  0.9979794387 0.999944631 #> 924  0.9959925343 0.999216733 #> 925  0.5712768633 0.363796882 #> 926  0.9978357539 0.999943903 #> 927  0.0027847411 0.029691387 #> 928  0.0019773561 0.983565583 #> 929  0.9998517630 0.999952640 #> 930  0.0027700691 0.007543015 #> 931  0.0020561823 0.877435198 #> 932  0.9753578934 0.989728209 #> 933  0.9982260823 0.999978447 #> 934  0.9974891472 0.962136227 #> 935  0.9973691697 0.998939778 #> 936  0.1369205407 0.007075395 #> 937  0.0218435009 0.806758697 #> 938  0.0024243548 0.986002381 #> 939  0.9671826740 0.410738190 #> 940  0.9998712901 0.999721284 #> 941  0.0028089269 0.007255917 #> 942  0.9966331873 0.999758959 #> 943  0.6001686365 0.998651249 #> 944  0.7462517542 0.993995884 #> 945  0.4843505104 0.332715886 #> 946  0.9797619594 0.999985306 #> 947  0.9770326832 0.999996431 #> 948  0.0238485753 0.985931508 #> 949  0.9721709201 0.989362985 #> 950  0.9997637008 0.947290255 #> 951  0.0126664597 0.534740682 #> 952  0.0238546213 0.997652838 #> 953  0.3135050530 0.038357954 #> 954  0.6545222239 0.629173297 #> 955  0.0401116372 0.029452095 #> 956  0.7369532208 0.071564703 #> 957  0.0753220972 0.414868597 #> 958  0.0218839435 0.996513566 #> 959  0.9981663754 0.999280852 #> 960  0.0066468319 0.928156870 #> 961  0.9999890804 0.999419724 #> 962  0.1084353177 0.172121420 #> 963  0.9963950289 0.997108756 #> 964  0.0995024790 0.999994329 #> 965  0.9981485644 0.999966007 #> 966  0.0027464885 0.080453635 #> 967  0.9998799840 0.999955005 #> 968  0.0144019344 0.049190941 #> 969  0.0110231050 0.998558722 #> 970  0.0246622746 0.995938399 #> 971  0.0331085913 0.611198803 #> 972  0.6067645715 0.999995596 #> 973  0.0027345282 0.088016760 #> 974  0.0028031073 0.007280061 #> 975  0.0027863076 0.029665269 #> 976  0.9606911085 0.988205245 #> 977  0.9979604803 0.999720617 #> 978  0.9982698909 0.999326943 #> 979  0.0344236120 0.007214673 #> 980  0.3089535018 0.997980637 #> 981  0.2284686001 0.963828934 #> 982  0.0027979473 0.007319705 #> 983  0.9998650268 0.999944618 #> 984  0.9973852951 0.999985436 #> 985  0.9811539744 0.892190015 #> 986  0.0219915221 0.028932495 #> 987  0.9954696928 0.907130049 #> 988  0.9964321775 0.896317199 #> 989  0.0005482695 0.990195907 #> 990  0.2392573998 0.995894137 #> 991  0.9785834909 0.999312620 #> 992  0.9872754516 0.999138702 #> 993  0.9576895430 0.170545614 #> 994  0.1417643856 0.006987745 #> 995  0.4838644936 0.919860571 #> 996  0.6825000193 0.824307232 #> 997  0.8768010241 0.284160166 #> 998  0.9864709720 0.985439657 #> 999  0.0258169699 0.981593500 #> 1000 0.0400007231 0.041627185"},{"path":"/dev/reference/tdcm.summary.html","id":null,"dir":"Reference","previous_headings":"","what":"TDCM results compiler and summarizer. — tdcm.summary","title":"TDCM results compiler and summarizer. — tdcm.summary","text":"Function summarize results TDCM analyses.","code":""},{"path":"/dev/reference/tdcm.summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"TDCM results compiler and summarizer. — tdcm.summary","text":"","code":"tdcm.summary(   model,   transition.option = 1,   classthreshold = 0.5,   attribute.names = c() )"},{"path":"/dev/reference/tdcm.summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"TDCM results compiler and summarizer. — tdcm.summary","text":"model gdina object returned tdcm function. transition.option option reporting results. = 1 compares first time point last. = 2 compares first time point every time point. = 3 compares successive time points. Default = 1. classthreshold probability threshold establishing proficiency examinee posterior probabilities. Default .50, maximizes overall classification accuracy. can set lower value minimize false negatives (.e., misclassifying proficient examinees non-proficient) set higher value minimize false positives (.e., misclassifying non-proficient examinees proficient). attribute.names optional vector attribute names include results output.","code":""},{"path":"/dev/reference/tdcm.summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"TDCM results compiler and summarizer. — tdcm.summary","text":"list following items: $item.parameters: item parameter estimates specified DCM. $growth: proficiency proportions time point attribute $growth.effects: growth effect size estimates attribute specified transitions including growth proficiency proportion, odds ratio = odds proficiency later time point divided odds proficiency earlier time point, Cohen's h (arcsine-transformed difference proportions; Cohen, 1988) $transition.probabilities: conditional attribute proficiency transition probability matrices $posterior.probabilities: examinee marginal attribute posterior probabilities proficiency $transition.posteriors: examinee marginal attribute transition posterior probabilities $.likely.transitions: examinee likely transitions attribute transition $classifications: examinee classifications determined specified threshold applied posterior probabilities $reliability: estimated transition reliability metrics attribute specified transitions. “pt bis” = longitudinal point biserial metric; “info gain” = longitudinal information gain metric; “polychor” = longitudinal tetrachoric metric; “ave max tr” = average maximum transition posterior metric; “P(t>k)” = proportion examinee marginal attribute transition posteriors greater k; “wt pt bis” = weighted longitudinal point biserial; “wt info gain” = weighted longitudinal information gain. $att.corr: estimated attribute correlation matrix $model.fit: Several model fit indices tests output including item root mean square error approximation (RMSEA; von Davier, 2005), mean RMSEA, bivariate item fit statistics (Chen et al., 2013), absolute fit statistics mean absolute deviation observed expected item correlations (MADcor; DiBello, Roussos, & Stout, 2007), standardized root mean square root squared residuals (SRMSR; Maydeu-Olivares, 2013)","code":""},{"path":"/dev/reference/tdcm.summary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"TDCM results compiler and summarizer. — tdcm.summary","text":"Provides summary TDCM results including item parameters, attribute posterior probabilities, transition posterior probabilities, classifications, growth, growth effects, transition probabilities, attribute correlations, several transition reliability metrics, model fit. Includes longitudinal DCM reliability metrics developed Schellman Madison (2024).","code":""},{"path":"/dev/reference/tdcm.summary.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"TDCM results compiler and summarizer. — tdcm.summary","text":"Chen, J., de la Torre, J. ,& Zhang, Z. (2013). Relative absolute fit evaluation cognitive diagnosis modeling. Journal Educational Measurement, 50, 123-140. Cohen, J. (1988). Statistical Power Analysis Behavioral Sciences (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum Associates, Publishers. DiBello, L. V., Roussos, L. ., & Stout, W. F. (2007). Review cognitively diagnostic assessment summary psychometric models. C. R. Rao S. Sinharay (Eds.), Handbook Statistics, Vol. 26 (pp.979–1030). Amsterdam: Elsevier. Johnson, M. S., & Sinharay, S. (2020). reliability posterior probability skill attainment diagnostic classification models. Journal Educational Measurement, 47(1), 5 – 31. Madison, M. J. (2019). Reliably assessing growth longitudinal diagnostic classification models. Educational Measurement: Issues Practice, 38(2), 68-78. Maydeu-Olivares, . (2013). Goodness--fit assessment item response theory models (discussion). Measurement: Interdisciplinary Research Perspectives, 11, 71-137. Schellman, M., & Madison, M. J. (2024). Estimating reliability skill transition longitudinal DCMs. Journal Educational Behavioral Statistics. Templin, J., & Bradshaw, L. (2013). Measuring reliability diagnostic classification model examinee estimates. Journal Classification, 30, 251-275. von Davier M. (2008). general diagnostic model applied language testing data. British journal mathematical statistical psychology, 61(2), 287–307.","code":""},{"path":"/dev/reference/tdcm.summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"TDCM results compiler and summarizer. — tdcm.summary","text":"","code":"# \\donttest{ ## Example 1: T = 2, A = 4 data(data.tdcm01, package = \"TDCM\") dat1 <- data.tdcm01$data qmat1 <- data.tdcm01$q.matrix  # estimate TDCM with invariance assumed and full LCDM m1 <- TDCM::tdcm(dat1, qmat1, num.time.points = 2, invariance = TRUE, rule = \"LCDM\") #> [1] Preparing data for tdcm()... #> [1] Estimating the multigroup TDCM in mg.tdcm()... #> [1] Depending on model complexity, estimation time may vary... #> [1] TDCM estimation complete. #> [1] Use tdcm.summary() to display results.  # summarize results with tdcm.summary function results1 <- TDCM::tdcm.summary(m1, transition.option = 1) #> [1] Summarizing results... #> [1] Routine finished. Check results. results1$item.parameters #>         λ0     λ1,1  λ1,2  λ1,3  λ1,4  λ2,12 λ2,13 λ2,14 λ2,23 λ2,24  λ2,34 #> Item 1  -1.905 2.599   --    --    --    --    --    --    --    --     --  #> Item 2  -2.072 2.536   --    --    --    --    --    --    --    --     --  #> Item 3  -1.934 2.517   --    --    --    --    --    --    --    --     --  #> Item 4  -1.892 1.091 1.499   --    --  1.057   --    --    --    --     --  #> Item 5  -2.17  1.456   --  1.794   --    --  1.018   --    --    --     --  #> Item 6  -1.843   --  2.199   --    --    --    --    --    --    --     --  #> Item 7  -1.825   --  2.259   --    --    --    --    --    --    --     --  #> Item 8  -1.967   --  2.497   --    --    --    --    --    --    --     --  #> Item 9  -2.009   --  1.079 1.511   --    --    --    --  1.818   --     --  #> Item 10 -2       --  1.849   --  1.324   --    --    --    --  1.065    --  #> Item 11 -1.845   --    --  2.329   --    --    --    --    --    --     --  #> Item 12 -2.033   --    --  2.539   --    --    --    --    --    --     --  #> Item 13 -2.071   --    --  2.55    --    --    --    --    --    --     --  #> Item 14 -2.093   --    --  1.739 2.031   --    --    --    --    --   0.496 #> Item 15 -1.785 0.307   --  1.295   --    --  2.374   --    --    --     --  #> Item 16 -2.218   --    --    --  2.837   --    --    --    --    --     --  #> Item 17 -2.084   --    --    --  2.69    --    --    --    --    --     --  #> Item 18 -2.101   --    --    --  2.521   --    --    --    --    --     --  #> Item 19 -2.1   2.653   --    --  1.432   --    --  0.098   --    --     --  #> Item 20 -2.061   --  2.545   --  1.53    --    --    --    --  -0.005   --  results1$growth #>             T1[1] T2[1] #> Attribute 1 0.190 0.370 #> Attribute 2 0.317 0.491 #> Attribute 3 0.392 0.579 #> Attribute 4 0.242 0.693 results1$growth.effects #>             T1[1] T2[1] Growth Odds Ratio Cohen`s h #> Attribute 1 0.190 0.370  0.180       2.50      0.41 #> Attribute 2 0.317 0.491  0.174       2.08      0.36 #> Attribute 3 0.392 0.579  0.187       2.13      0.38 #> Attribute 4 0.242 0.693  0.451       7.07      0.94 results1$transition.probabilities #> , , Attribute 1: Time 1 to Time 2 #>  #>        T2 [0] T2 [1] #> T1 [0]  0.680  0.320 #> T1 [1]  0.417  0.583 #>  #> , , Attribute 2: Time 1 to Time 2 #>  #>        T2 [0] T2 [1] #> T1 [0]  0.581  0.419 #> T1 [1]  0.353  0.647 #>  #> , , Attribute 3: Time 1 to Time 2 #>  #>        T2 [0] T2 [1] #> T1 [0]  0.549  0.451 #> T1 [1]  0.221  0.779 #>  #> , , Attribute 4: Time 1 to Time 2 #>  #>        T2 [0] T2 [1] #> T1 [0]  0.371  0.629 #> T1 [1]  0.104  0.896 #>  results1$reliability #>             pt bis info gain polychor ave max tr P(t>.6) P(t>.7) P(t>.8) #> Attribute 1  0.821     0.516    0.936      0.931   0.966   0.927   0.861 #> Attribute 2  0.792     0.552    0.916      0.908   0.939   0.893   0.839 #> Attribute 3  0.770     0.540    0.922      0.895   0.943   0.870   0.796 #> Attribute 4  0.771     0.494    0.914      0.913   0.952   0.894   0.829 #>             P(t>.9) wt pt bis wt info gain #> Attribute 1   0.790     0.834        0.601 #> Attribute 2   0.731     0.809        0.591 #> Attribute 3   0.674     0.786        0.584 #> Attribute 4   0.748     0.798        0.602 head(results1$most.likely.transitions) #>   Attribute 1: T1 to T2 Attribute 2: T1 to T2 Attribute 3: T1 to T2 #> 1     01                    10                    01                #> 2     10                    00                    10                #> 3     00                    11                    01                #> 4     00                    01                    01                #> 5     00                    01                    01                #> 6     00                    10                    01                #>   Attribute 4: T1 to T2 #> 1     11                #> 2     11                #> 3     10                #> 4     01                #> 5     11                #> 6     01                results1$model.fit$Item.RMSEA #>     Item 1     Item 2     Item 3     Item 4     Item 5     Item 6     Item 7  #> 0.09391612 0.12079524 0.10670311 0.10952611 0.11962801 0.13655715 0.13845978  #>     Item 8     Item 9    Item 10    Item 11    Item 12    Item 13    Item 14  #> 0.10811876 0.11353405 0.11115225 0.12981641 0.11323978 0.10265758 0.11435661  #>    Item 15    Item 16    Item 17    Item 18    Item 19    Item 20    Item 21  #> 0.12122112 0.12147005 0.10578848 0.11120378 0.09767873 0.13304620 0.10788168  #>    Item 22    Item 23    Item 24    Item 25    Item 26    Item 27    Item 28  #> 0.10949474 0.11713454 0.12149082 0.11334556 0.12767058 0.12317678 0.10590232  #>    Item 29    Item 30    Item 31    Item 32    Item 33    Item 34    Item 35  #> 0.11158355 0.11326936 0.11504822 0.11948474 0.11920146 0.09564141 0.12998822  #>    Item 36    Item 37    Item 38    Item 39    Item 40  #> 0.11363849 0.12522381 0.11581421 0.10939110 0.11244670  # }"},{"path":"/dev/news/index.html","id":"tdcm-development-version","dir":"Changelog","previous_headings":"","what":"TDCM (development version)","title":"TDCM (development version)","text":"Improved several references included package documentation. Added CRAN badge README.Rmd README.md. Updated required versions various package dependencies. Updated Developer Guide vignette provide information various ways people can contribute project added GitHub issue templates streamline submission bug reports feature requests. addition primarily authored undergraduate students Dr. Cotterell’s research group Summer 2024.","code":""},{"path":"/dev/news/index.html","id":"tdcm-010","dir":"Changelog","previous_headings":"","what":"tdcm 0.1.0","title":"tdcm 0.1.0","text":"CRAN release: 2024-02-05 Initial CRAN submission.","code":""},{"path":"/dev/news/index.html","id":"tdcm-0009000","dir":"Changelog","previous_headings":"","what":"tdcm 0.0.0.9000","title":"tdcm 0.0.0.9000","text":"TDCM R package project born!","code":""}]
