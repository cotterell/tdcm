[{"path":[]},{"path":"/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement mepcott@uga.edu. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired [Mozilla’s code conduct enforcement ladder][https://github.com/mozilla/inclusion]. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to tdcm","title":"Contributing to tdcm","text":"document outlines propose change tdcm.","code":""},{"path":"/CONTRIBUTING.html","id":"bug-reports-and-feature-requests","dir":"","previous_headings":"","what":"Bug Reports and Feature Requests","title":"Contributing to tdcm","text":"encountered problem tdcm package idea new feature, please submit using project’s issue tracker.","code":""},{"path":"/CONTRIBUTING.html","id":"pull-requests","dir":"","previous_headings":"","what":"Pull Requests","title":"Contributing to tdcm","text":"recommend create Git branch pull request (PR). Look Github Actions build status making changes. README contain badges continuous integration services used package. New code follow consistent style. can use styler package apply default style, please don’t restyle code nothing PR. use roxygen2, Markdown syntax, documentation. use testthat. Contributions test cases included easier accept. user-facing changes, add bullet top NEWS.md current development version header describing changes made followed GitHub username, links relevant issue(s)/PR(s).","code":""},{"path":"/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"Contributing to tdcm","text":"Small typos grammatical errors documentation may edited directly using GitHub web interface, long changes made source file. YES: edit roxygen comment .R file R/. : edit .Rd file man/.","code":""},{"path":"/CONTRIBUTING.html","id":"prerequisites","dir":"","previous_headings":"","what":"Prerequisites","title":"Contributing to tdcm","text":"make substantial pull request, always file issue make sure someone team agrees problem. found bug, create associated issue illustrate bug minimal reprex.","code":""},{"path":"/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to tdcm","text":"Please note pkgdown project released Contributor Code Conduct. contributing project agree abide terms.","code":""},{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 TDCM authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/articles/TDCM.html","id":"overview-of-the-tdcm-package","dir":"Articles","previous_headings":"","what":"Overview of the TDCM Package","title":"Introduction to the TDCM Package","text":"TDCM R package implements estimation longitudinal DCMs using transition diagnostic classification model (TDCM) framework described Madison & Bradshaw (2018). TDCM longitudinal extension log-linear cognitive diagnosis model (LCDM) developed Henson, Templin & Willse (2009). LCDM general DCM, many DCMs can embedded within TDCM. TDCM package includes functions estimate single- multigroup TDCM, summarize results interest including item parameter estimates, growth proportions, transition probabilities, transition reliability, attribute correlations, model fit, growth plots. TDCM package extension CDM package (Robitzsch et al., 2022), therefore inherits much CDM package’s functionality. vignette provides overview package’s core functionality walking two examples. code can copied R console run. detailed video demonstrations package functionality, visit .","code":""},{"path":"/articles/TDCM.html","id":"core-functionalities","dir":"Articles","previous_headings":"","what":"Core Functionalities","title":"Introduction to the TDCM Package","text":"estimate single- multigroup TDCM, use tdcm() mg.tdcm() functions, respectively. extract item, person, structural parameters TDCM estimates, use tdcm.summary() mg.tdcm.summary() functions single- multigroup analyses, respectively. summary functions produce list results including item parameter estimates, growth proportions, transition probability matrices, transition reliability, attribute correlations, model fit. compare models assess relative , use tdcm.compare() function. plot results TDCM analysis, use tdcm.plot() function score responses using fixed item parameters previously calibrated model, use tdcm.score() function","code":""},{"path":"/articles/TDCM.html","id":"extended-functionalities","dir":"Articles","previous_headings":"","what":"Extended Functionalities","title":"Introduction to the TDCM Package","text":"Different DCMs (e.g., DINA, ACDM) can implemented within tdcm() function using dcmrule argument. Multiple Q-matrices time point permitted tdcm() function number.q argument. Anchor (common) items time points can specified anchor argument. two time points, transitions can defined differently (e.g., first--last, first--, successive) transition.option argument. Responses can scored using fixed item parameters previously calibrated model using tdcm.score() function.","code":""},{"path":"/articles/TDCM.html","id":"example-1-single-group-tdcm","dir":"Articles","previous_headings":"","what":"Example #1: Single Group TDCM","title":"Introduction to the TDCM Package","text":"Suppose sample 1000 fourth grade students. assessed unit covering four measurement data (MD) standards (attributes; 4.MD.1 - 4.MD.4). students took 20-item assessment five weeks apart. goal examine students transition proficiency assessed attributes. Step 1: Load package Dataset #1 included package: Step 2: estimate TDCM, let’s make decisions. Q-matrix complex items measuring two attributes, initially estimate full LCDM two-way interactions (default). Since students took assessment, can assume measurement invariance test assumption later. Step 3: summarize results, use tdcm.summary() function. running summary function, can examine item parameters, growth attribute proficiency, transition probability matrices, individual transitions, transitional reliability estimates. demonstrate interpretation, let’s discuss results. Item 1 measuring 4.MD.1 intercept estimate -1.923 main effect estimate 2.616. respect growth, see students exhibited amount growth 4.MD.1 - 4.MD.3 (17% growth proficiency), showed larger gains 4.MD.4 (44%). Examining 4.MD.1 transition probability matrix, see students started non-proficiency, 32% transitioned proficiency. Examining individual transition posterior probabilities, see Examinee #1 mostly likely transition 0 → 1 (.985 probability). Finally, transition reliability appears adequate, average maximum transition posteriors ranging .88 .92 four attributes. Step 4: assess measurement invariance, let’s estimate model without invariance assumed, compare first model. see AIC, BIC, likelihood ratio test prefer model invariance assumed. Therefore, item parameter invariance reasonable assumption can interpret results. Step 5: estimate DCMs, change dcmrule argument. specify one DCM across items, include one specification. specify different DCM item, use vector length equal number items. , specify DINA measurement model main effects model (ACDM). , see full LCDM fits better DINA model main effects model. Step 6: assess absolute fit, extract model fit statistics results summary. Step 7: visual presentation results, run tdcm.plot() function:","code":"#load the TDCM library library(TDCM)  #read data and Q-matrix dat1 <- data.tdcm01$data qmat1 <- data.tdcm01$qmatrix head(dat1) ##   t1tem1 t1tem2 t1tem3 t1tem4 t1tem5 t1tem6 t1tem7 t1tem8 t1tem9 t1tem10 ## 1      0      0      1      0      0      0      1      0      0       1 ## 2      0      1      1      0      1      0      0      0      0       1 ## 3      0      0      0      1      1      1      0      1      0       1 ## 4      1      0      0      0      0      0      0      0      0       0 ## 5      1      0      0      0      0      0      0      0      0       0 ## 6      0      0      0      0      0      0      1      0      1       0 ##   t1tem11 t1tem12 t1tem13 t1tem14 t1tem15 t1tem16 t1tem17 t1tem18 t1tem19 ## 1       0       0       0       1       0       1       0       1       0 ## 2       1       1       1       1       1       1       0       1       0 ## 3       1       0       0       1       0       0       1       1       0 ## 4       0       0       0       0       0       0       0       0       0 ## 5       0       1       0       1       0       1       0       1       0 ## 6       1       0       0       0       0       0       0       0       0 ##   t1tem20 t2item1 t2item2 t2item3 t2item4 t2item5 t2item6 t2item7 t2item8 ## 1       1       0       1       1       1       1       0       0       0 ## 2       0       0       0       0       0       0       0       0       0 ## 3       1       0       0       1       0       1       0       1       1 ## 4       0       0       0       0       0       0       1       0       1 ## 5       0       0       1       0       0       1       1       1       1 ## 6       1       0       0       0       0       0       0       0       0 ##   t2item9 t2item10 t2item11 t2item12 t2item13 t2item14 t2item15 t2item16 ## 1       0        0        0        1        0        1        1        0 ## 2       0        1        0        0        0        1        0        1 ## 3       1        1        1        1        1        0        1        0 ## 4       1        0        1        1        1        1        1        1 ## 5       1        1        1        0        1        1        0        1 ## 6       1        0        1        1        1        1        1        1 ##   t2item17 t2item18 t2item19 t2item20 ## 1        1        0        1        0 ## 2        1        0        1        0 ## 3        0        0        0        0 ## 4        1        1        1        1 ## 5        1        1        0        1 ## 6        1        1        0        0 #calibrate TDCM with measurement invariance assumed, full LCDM m1 <- tdcm(data = dat1, qmatrix = qmat1, time.points = 2, invariance = TRUE, dcmrule = \"GDINA\") #summarize results results1 <- tdcm.summary(m1, time.points = 2, attribute.names = c(\"4.MD.1\", \"4.MD.2\", \"4.MD.3\", \"4.MD.4\")) results1$item.parameters ##         λ0     λ1,1  λ1,2  λ1,3  λ1,4  λ2,12 λ2,13 λ2,14 λ2,23 λ2,24 ## Item 1  -1.923 2.616   --    --    --    --    --    --    --    --  ## Item 2  -2.071 2.506   --    --    --    --    --    --    --    --  ## Item 3  -1.936 2.506   --    --    --    --    --    --    --    --  ## Item 4  -1.891 1.051 1.471   --    --  1.115   --    --    --    --  ## Item 5  -2.157 1.705   --  1.732   --    --  0.835   --    --    --  ## Item 6  -1.841   --  2.175   --    --    --    --    --    --    --  ## Item 7  -1.841   --  2.272   --    --    --    --    --    --    --  ## Item 8  -1.965   --  2.475   --    --    --    --    --    --    --  ## Item 9  -2.029   --  1.242 1.531   --    --    --    --  1.628   --  ## Item 10 -2.004   --  1.921   --  1.239   --    --    --    --  0.999 ## Item 11 -1.851   --    --  2.349   --    --    --    --    --    --  ## Item 12 -2.045   --    --  2.566   --    --    --    --    --    --  ## Item 13 -2.083   --    --  2.576   --    --    --    --    --    --  ## Item 14 -2.125   --    --  1.739 2.104   --    --    --    --    --  ## Item 15 -1.805 0.777   --  1.31    --    --  1.896   --    --    --  ## Item 16 -2.156   --    --    --  2.736   --    --    --    --    --  ## Item 17 -2.089   --    --    --  2.679   --    --    --    --    --  ## Item 18 -2.087   --    --    --  2.476   --    --    --    --    --  ## Item 19 -2.11  2.219   --    --  1.46    --    --  0.558   --    --  ## Item 20 -2.047   --  2.408   --  1.49    --    --    --    --  0.154 ##         λ2,34 ## Item 1    --  ## Item 2    --  ## Item 3    --  ## Item 4    --  ## Item 5    --  ## Item 6    --  ## Item 7    --  ## Item 8    --  ## Item 9    --  ## Item 10   --  ## Item 11   --  ## Item 12   --  ## Item 13   --  ## Item 14 0.493 ## Item 15   --  ## Item 16   --  ## Item 17   --  ## Item 18   --  ## Item 19   --  ## Item 20   -- results1$growth ##        T1[1] T2[1] ## 4.MD.1 0.201 0.372 ## 4.MD.2 0.327 0.492 ## 4.MD.3 0.397 0.573 ## 4.MD.4 0.252 0.696 results1$transition.probabilities ## , , 4.MD.1: Time 1 to Time 2 ##  ##        T2 [0] T2 [1] ## T1 [0]  0.678  0.322 ## T1 [1]  0.432  0.568 ##  ## , , 4.MD.2: Time 1 to Time 2 ##  ##        T2 [0] T2 [1] ## T1 [0]  0.578  0.422 ## T1 [1]  0.363  0.637 ##  ## , , 4.MD.3: Time 1 to Time 2 ##  ##        T2 [0] T2 [1] ## T1 [0]   0.55   0.45 ## T1 [1]   0.24   0.76 ##  ## , , 4.MD.4: Time 1 to Time 2 ##  ##        T2 [0] T2 [1] ## T1 [0]  0.365  0.635 ## T1 [1]  0.123  0.877 head(results1$transition.posteriors) ## , , 4.MD.1: T1 to T2 ##  ##      00    01    10    11 ## 1 0.004 0.985 0.000 0.011 ## 2 0.229 0.005 0.748 0.018 ## 3 0.854 0.123 0.020 0.003 ## 4 0.960 0.032 0.007 0.000 ## 5 0.969 0.025 0.006 0.000 ## 6 0.996 0.003 0.000 0.000 ##  ## , , 4.MD.2: T1 to T2 ##  ##      00    01    10    11 ## 1 0.310 0.003 0.682 0.005 ## 2 0.966 0.022 0.011 0.000 ## 3 0.001 0.020 0.042 0.937 ## 4 0.082 0.916 0.000 0.002 ## 5 0.000 0.999 0.000 0.001 ## 6 0.397 0.003 0.596 0.004 ##  ## , , 4.MD.3: T1 to T2 ##  ##      00    01    10    11 ## 1 0.033 0.930 0.001 0.036 ## 2 0.000 0.000 0.955 0.045 ## 3 0.000 0.506 0.000 0.494 ## 4 0.000 0.993 0.000 0.006 ## 5 0.001 0.607 0.001 0.391 ## 6 0.001 0.626 0.000 0.373 ##  ## , , 4.MD.4: T1 to T2 ##  ##      00    01    10    11 ## 1 0.002 0.043 0.043 0.912 ## 2 0.000 0.191 0.002 0.806 ## 3 0.013 0.001 0.925 0.061 ## 4 0.000 0.998 0.000 0.002 ## 5 0.000 0.257 0.000 0.743 ## 6 0.004 0.995 0.000 0.002 results1$reliability ##        pt bis info gain polychor ave max tr P(t>.6) P(t>.7) P(t>.8) ## 4.MD.1  0.788     0.511    0.925      0.922   0.964   0.929   0.856 ## 4.MD.2  0.769     0.546    0.905      0.896   0.923   0.868   0.821 ## 4.MD.3  0.728     0.527    0.905      0.878   0.918   0.856   0.750 ## 4.MD.4  0.715     0.485    0.891      0.899   0.936   0.883   0.801 ##        P(t>.9) wt pt bis wt info gain ## 4.MD.1   0.747     0.822        0.591 ## 4.MD.2   0.694     0.792        0.581 ## 4.MD.3   0.625     0.757        0.568 ## 4.MD.4   0.709     0.772        0.585 #run TDCM with measurement invariance not assumed m2 <- tdcm(data = dat1, qmatrix = qmat1, time.points = 2, invariance = FALSE, dcmrule = \"GDINA\")  #compare Model 1 (longitudinal invariance assumed) to Model 2 (invariance not assumed) tdcm.compare(m1, m2) ##   Model   loglike Deviance Npars      AIC      BIC Chisq df      p ## 1    m1 -21429.51 42859.02    93 43045.02 43501.44 58.14 56 0.3965 ## 2    m2 -21400.44 42800.88   149 43098.88 43830.14    NA NA     NA #calibrate TDCM with measurement invariance assumed, DINA measurement model m3 <- tdcm(data = dat1, qmatrix = qmat1, time.points = 2, invariance = TRUE, dcmrule = \"DINA\")  #calibrate TDCM with measurement invariance assumed, ACDM measurement model m4 <- tdcm(data = dat1, qmatrix = qmat1, time.points = 2, invariance = TRUE, dcmrule = \"ACDM\")  #compare Model 1 (full LCDM) to Model 3 (DINA) tdcm.compare(m1, m3) ##   Model   loglike Deviance Npars      AIC      BIC  Chisq df  p ## 1    m1 -21429.51 42859.02    93 43045.02 43501.44 500.48 16  0 ## 2    m3 -21679.75 43359.49    77 43513.49 43891.39     NA NA NA #compare Model 1 (full LCDM) to Model 4 (ACDM) tdcm.compare(m1, m4) ##   Model   loglike Deviance Npars      AIC      BIC Chisq df  p ## 1    m1 -21429.51 42859.02    93 43045.02 43501.44 53.72  8  0 ## 2    m4 -21456.37 42912.74    85 43082.74  43499.9    NA NA NA results1$model.fit$Global.Fit.Stats ##                        est ## MADcor          0.02221611 ## SRMSR           0.02793421 ## 100*MADRESIDCOV 0.48573824 ## MADQ3           0.03307904 ## MADaQ3          0.03196812 results1$model.fit$Global.Fit.Tests ##        type      value         p ## 1   max(X2) 9.45244172 1.0000000 ## 2 abs(fcor) 0.09801383 0.7680444 results1$model.fit$Global.Fit.Stats2 ##      maxX2 p_maxX2     MADcor      SRMSR 100*MADRESIDCOV      MADQ3 ## 1 9.452442       1 0.02221611 0.02793421       0.4857382 0.03307904 ##       MADaQ3 ## 1 0.03196812 results1$model.fit$Item.RMSEA ##    Item 1    Item 2    Item 3    Item 4    Item 5    Item 6    Item 7  ## 0.1072683 0.1273641 0.1082175 0.1191112 0.1255691 0.1401920 0.1357562  ##    Item 8    Item 9   Item 10   Item 11   Item 12   Item 13   Item 14  ## 0.1130181 0.1208428 0.1135816 0.1318266 0.1110083 0.1104637 0.1190979  ##   Item 15   Item 16   Item 17   Item 18   Item 19   Item 20   Item 21  ## 0.1274363 0.1244858 0.1133979 0.1235323 0.1142053 0.1400732 0.1122910  ##   Item 22   Item 23   Item 24   Item 25   Item 26   Item 27   Item 28  ## 0.1072758 0.1246946 0.1223008 0.1262111 0.1286012 0.1267738 0.1105200  ##   Item 29   Item 30   Item 31   Item 32   Item 33   Item 34   Item 35  ## 0.1164483 0.1158832 0.1303099 0.1289143 0.1225251 0.1096947 0.1357179  ##   Item 36   Item 37   Item 38   Item 39   Item 40  ## 0.1320643 0.1304714 0.1168578 0.1116256 0.1156059 results1$model.fit$Mean.Item.RMSEA ## [1] 0.1212809 #plot results (check plot viewer for line plot and bar chart) tdcm.plot(results1, attribute.names = c(\"4.MD.1\", \"4.MD.2\", \"4.MD.3\", \"4.MD.4\"))"},{"path":"/articles/TDCM.html","id":"example-2-multigroup-tdcm-example","dir":"Articles","previous_headings":"","what":"Example #2: Multigroup TDCM Example","title":"Introduction to the TDCM Package","text":"Suppose now sample 1700 fourth grade students. example, researchers wanted evaluate effects instructional intervention. randomly assigned students either control group (Group 1, N1 = 800) treatment group (Group 2, N2 = 900). goal see innovative instructional method resulted students transitioning proficiency. Similar Example #1, students assessed unit covering four measurement data (MD) standards (attributes; 4.MD.1 - 4.MD.4). students took 20-item assessment five weeks apart. Step 1: Load package Dataset #4 included package: Step 2: estimate multigroup TDCM, use mg.tdcm() function. initial model, assume item invariance group invariance. next step, test assumptions. Step 3: assess measurement invariance, let’s estimate three additional models: - model assuming item invariance (TRUE) assuming group invariance (FALSE) - model assuming item invariance (FALSE) assuming group invariance (TRUE) - model assuming either; item invariance (FALSE) group invariance (FALSE) model comparisons prefer model group time invariance. Therefore, can proceed interpreting Model 1. Step 4: summarize results, use mg.tdcm.summary() function. running summary function, can examine item parameters, growth attribute proficiency group, transition probability matrices group, individual transitions, transitional reliability estimates. demonstrate interpretation, let’s discuss results. Item 1 measuring 4.MD.1 intercept estimate -1.87 main effect estimate 2.375. respect growth, first see randomization appeared work, groups similar proficiency proportions first assessment. see 4.MD.4 attribute, treatment group showed increased growth attribute proficiency. Step 5: visual presentation results, run tdcm.plot() function:","code":"#load the TDCM library library(TDCM)  #read data, Q-matrix, and group labels dat4 <- data.tdcm04$data qmat4 <- data.tdcm04$qmatrix groups <- data.tdcm04$groups head(dat4) ##   t1item1 t1item2 t1item3 t1item4 t1item5 t1item6 t1item7 t1item8 t1item9 ## 1       0       0       0       0       0       0       0       0       0 ## 2       0       0       0       0       0       0       0       0       0 ## 3       0       1       0       0       0       0       0       1       0 ## 4       0       0       0       1       0       0       0       0       0 ## 5       1       0       0       1       1       0       1       1       1 ## 6       1       1       1       0       1       0       1       1       0 ##   t1item10 t1item11 t1item12 t1item13 t1item14 t1item15 t1item16 t1item17 ## 1        0        0        0        0        0        0        0        0 ## 2        1        0        0        0        0        0        0        0 ## 3        0        0        0        1        0        0        0        0 ## 4        0        1        0        0        0        0        1        1 ## 5        0        0        0        0        0        0        0        0 ## 6        1        0        1        1        1        1        1        0 ##   t1item18 t1item19 t1item20 t2item1 t2item2 t2item3 t2item4 t2item5 ## 1        0        0        0       0       0       1       1       0 ## 2        0        0        0       0       1       1       0       0 ## 3        0        0        0       0       0       1       0       0 ## 4        0        0        0       0       1       1       1       1 ## 5        1        0        0       0       0       1       1       0 ## 6        1        1        1       0       0       0       0       0 ##   t2item6 t2item7 t2item8 t2item9 t2item10 t2item11 t2item12 t2item13 ## 1       0       0       0       0        0        1        1        0 ## 2       1       0       0       0        0        0        0        0 ## 3       0       0       0       0        0        1        1        1 ## 4       0       1       1       0        1        0        1        0 ## 5       0       1       0       0        1        0        0        0 ## 6       1       1       1       1        1        1        0        1 ##   t2item14 t2item15 t2item16 t2item17 t2item18 t2item19 t2item20 ## 1        1        1        0        1        1        0        0 ## 2        0        0        0        0        0        0        0 ## 3        0        0        0        0        0        0        0 ## 4        1        1        0        1        1        1        1 ## 5        1        0        1        1        1        0        1 ## 6        1        0        0        0        0        0        1 #calibrate mgTDCM with item and group invariance assumed, full LCDM mg1 <- mg.tdcm(data = dat4, qmatrix = qmat4, time.points = 2, dcmrule = \"GDINA\", groups = groups, group.invariance = TRUE, item.invariance = TRUE) ## [1] Preparing data... ## [1] Estimating mgTDCM... ## [1] Note: Depending on model specifications, estimation for the multigroup TDCM can take a few minutes.  ## [1] Estimating mgTDCM, progress = 47%... ## [1] Routine finished. Use the mg.tdcm.summary function to display results. #calibrate mgTDCM with item invariance assumed, full LCDM mg2 <- mg.tdcm(data = dat4, qmatrix = qmat4, time.points = 2, dcmrule = \"GDINA\", groups = groups, group.invariance = FALSE, item.invariance = TRUE) ## [1] Preparing data... ## [1] Estimating mgTDCM... ## [1] Note: Depending on model specifications, estimation for the multigroup TDCM can take a few minutes.  ## [1] Estimating mgTDCM, progress = 37%... ## [1] Routine finished. Use the mg.tdcm.summary function to display results. #calibrate mgTDCM with group invariance assumed, full LCDM mg3 <- mg.tdcm(data = dat4, qmatrix = qmat4, time.points = 2, dcmrule = \"GDINA\", groups = groups, group.invariance = TRUE, item.invariance = FALSE) ## [1] Preparing data... ## [1] Estimating mgTDCM... ## [1] Note: Depending on model specifications, estimation for the multigroup TDCM can take a few minutes.  ## [1] Estimating mgTDCM, progress = 30%... ## [1] Routine finished. Use the mg.tdcm.summary function to display results. #calibrate mgTDCM with no invariance assumed, full LCDM mg4 <- mg.tdcm(data = dat4, qmatrix = qmat4, time.points = 2, dcmrule = \"GDINA\", groups = groups, group.invariance = FALSE, item.invariance = FALSE) ## [1] Preparing data... ## [1] Estimating mgTDCM... ## [1] Note: Depending on model specifications, estimation for the multigroup TDCM can take a few minutes.  ## [1] Estimating mgTDCM, progress = 38%... ## [1] Routine finished. Use the mg.tdcm.summary function to display results. #compare Model 1 (group/item invariance) to Model 2 (no group invariance) tdcm.compare(mg1, mg2) ##   Model   loglike Deviance Npars      AIC      BIC Chisq df      p ## 1   mg1 -37371.96 74743.92   130 75003.92 75710.91 27.92 56 0.9994 ## 2   mg2    -37358    74716   186    75088 76099.54    NA NA     NA #compare Model 1 (group/item invariance) to Model 3 (no item invariance) tdcm.compare(mg1, mg3) ##   Model   loglike Deviance Npars      AIC      BIC Chisq df      p ## 1   mg1 -37371.96 74743.92   130 75003.92 75710.91 63.22 56 0.2366 ## 2   mg3 -37340.35  74680.7   186  75052.7 76064.24    NA NA     NA #compare Model 1 (group/item invariance) to Model 4 (no invariance) tdcm.compare(m1, m4) ##   Model   loglike Deviance Npars      AIC      BIC Chisq df  p ## 1    m1 -21429.51 42859.02    93 43045.02 43501.44 53.72  8  0 ## 2    m4 -21456.37 42912.74    85 43082.74  43499.9    NA NA NA #summarize results resultsmg1 <- mg.tdcm.summary(mg1, time.points = 2, attribute.names = c(\"4.MD.1\", \"4.MD.2\", \"4.MD.3\", \"4.MD.4\"), group.names = c(\"Control\", \"Treatment\")) ## [1] Summarizing results... ## [1] Summarizing results, progress = 42%... ## [1] Routine finished. Check results. resultsmg1$item.parameters ##         λ0     λ1,1  λ1,2  λ1,3  λ1,4  λ2,12 λ2,13 λ2,14 λ2,23 λ2,24 ## Item 1  -1.87  2.375   --    --    --    --    --    --    --    --  ## Item 2  -2.039 2.553   --    --    --    --    --    --    --    --  ## Item 3  -2.153 2.6     --    --    --    --    --    --    --    --  ## Item 4  -2.103 1.722 1.528   --    --  0.822   --    --    --    --  ## Item 5  -2.1   1.519   --  1.428   --    --  1.241   --    --    --  ## Item 6  -1.943   --  2.456   --    --    --    --    --    --    --  ## Item 7  -1.904   --  2.463   --    --    --    --    --    --    --  ## Item 8  -2       --  2.434   --    --    --    --    --    --    --  ## Item 9  -2.084   --  1.744 1.764   --    --    --    --  0.624   --  ## Item 10 -2.088   --  1.406   --  1.636   --    --    --    --  0.922 ## Item 11 -1.958   --    --  2.474   --    --    --    --    --    --  ## Item 12 -2.151   --    --  2.642   --    --    --    --    --    --  ## Item 13 -1.877   --    --  2.367   --    --    --    --    --    --  ## Item 14 -1.911   --    --  1.297 1.198   --    --    --    --    --  ## Item 15 -2.156 1.788   --  1.772   --    --  0.617   --    --    --  ## Item 16 -2.129   --    --    --  2.584   --    --    --    --    --  ## Item 17 -2.367   --    --    --  3.004   --    --    --    --    --  ## Item 18 -2.016   --    --    --  2.429   --    --    --    --    --  ## Item 19 -2.03  1.561   --    --  1.395   --    --  0.839   --    --  ## Item 20 -2.197   --  1.614   --  1.744   --    --    --    --  0.803 ##         λ2,34 ## Item 1    --  ## Item 2    --  ## Item 3    --  ## Item 4    --  ## Item 5    --  ## Item 6    --  ## Item 7    --  ## Item 8    --  ## Item 9    --  ## Item 10   --  ## Item 11   --  ## Item 12   --  ## Item 13   --  ## Item 14 1.214 ## Item 15   --  ## Item 16   --  ## Item 17   --  ## Item 18   --  ## Item 19   --  ## Item 20   -- resultsmg1$growth ## , , Control ##  ##        T1[1] T2[1] ## 4.MD.1 0.307 0.434 ## 4.MD.2 0.406 0.501 ## 4.MD.3 0.221 0.618 ## 4.MD.4 0.427 0.735 ##  ## , , Treatment ##  ##        T1[1] T2[1] ## 4.MD.1 0.305 0.621 ## 4.MD.2 0.392 0.731 ## 4.MD.3 0.209 0.687 ## 4.MD.4 0.454 0.709 resultsmg1$transition.probabilities ## , , 4.MD.1: Time 1 to Time 2, Control ##  ##        T2 [0] T2 [1] ## T1 [0]  0.633  0.367 ## T1 [1]  0.416  0.584 ##  ## , , 4.MD.2: Time 1 to Time 2, Control ##  ##        T2 [0] T2 [1] ## T1 [0]  0.571  0.429 ## T1 [1]  0.395  0.605 ##  ## , , 4.MD.3: Time 1 to Time 2, Control ##  ##        T2 [0] T2 [1] ## T1 [0]  0.432  0.568 ## T1 [1]  0.203  0.797 ##  ## , , 4.MD.4: Time 1 to Time 2, Control ##  ##        T2 [0] T2 [1] ## T1 [0]  0.333  0.667 ## T1 [1]  0.173  0.827 ##  ## , , 4.MD.1: Time 1 to Time 2, Treatment ##  ##        T2 [0] T2 [1] ## T1 [0]  0.437  0.563 ## T1 [1]  0.250  0.750 ##  ## , , 4.MD.2: Time 1 to Time 2, Treatment ##  ##        T2 [0] T2 [1] ## T1 [0]  0.369  0.631 ## T1 [1]  0.115  0.885 ##  ## , , 4.MD.3: Time 1 to Time 2, Treatment ##  ##        T2 [0] T2 [1] ## T1 [0]  0.370  0.630 ## T1 [1]  0.097  0.903 ##  ## , , 4.MD.4: Time 1 to Time 2, Treatment ##  ##        T2 [0] T2 [1] ## T1 [0]  0.352  0.648 ## T1 [1]  0.219  0.781 head(resultsmg1$transition.posteriors) ## , , 4.MD.1: T1 to T2 ##  ##      00    01    10    11 ## 1 0.654 0.344 0.001 0.001 ## 2 0.962 0.037 0.001 0.000 ## 3 0.973 0.012 0.015 0.000 ## 4 0.000 0.987 0.000 0.013 ## 5 0.433 0.109 0.369 0.089 ## 6 0.001 0.000 0.998 0.001 ##  ## , , 4.MD.2: T1 to T2 ##  ##      00    01    10    11 ## 1 0.988 0.009 0.003 0.000 ## 2 0.970 0.014 0.016 0.000 ## 3 0.976 0.003 0.021 0.000 ## 4 0.004 0.984 0.000 0.012 ## 5 0.009 0.027 0.186 0.778 ## 6 0.000 0.026 0.000 0.974 ##  ## , , 4.MD.3: T1 to T2 ##  ##      00    01    10    11 ## 1 0.035 0.964 0.000 0.000 ## 2 0.997 0.003 0.000 0.000 ## 3 0.182 0.818 0.000 0.001 ## 4 0.034 0.962 0.000 0.004 ## 5 0.928 0.040 0.031 0.001 ## 6 0.000 0.011 0.009 0.980 ##  ## , , 4.MD.4: T1 to T2 ##  ##      00    01    10    11 ## 1 0.082 0.914 0.001 0.003 ## 2 0.974 0.009 0.017 0.000 ## 3 0.990 0.005 0.006 0.000 ## 4 0.000 0.330 0.000 0.669 ## 5 0.000 0.994 0.000 0.006 ## 6 0.000 0.000 0.120 0.879 resultsmg1$reliability ##        pt bis info gain polychor ave max tr P(t>.6) P(t>.7) P(t>.8) ## 4.MD.1  0.777     0.541    0.897      0.894   0.914   0.877   0.825 ## 4.MD.2  0.757     0.527    0.885      0.877   0.905   0.847   0.768 ## 4.MD.3  0.765     0.498    0.911      0.914   0.952   0.903   0.842 ## 4.MD.4  0.769     0.516    0.882      0.887   0.931   0.858   0.771 ##        P(t>.9) wt pt bis wt info gain ## 4.MD.1   0.677     0.806        0.562 ## 4.MD.2   0.625     0.766        0.545 ## 4.MD.3   0.746     0.826        0.584 ## 4.MD.4   0.658     0.775        0.556 #plot results (check plot viewer for line plots and bar charts) tdcm.plot(resultsmg1, attribute.names = c(\"4.MD.1\", \"4.MD.2\", \"4.MD.3\", \"4.MD.4\"),            group.names = c(\"Control\", \"Treatment\")) ## [1] **Check plots window for line and bar plots for growth proportions."},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"package proudly brought : Matthew J. Madison. Author, copyright holder. Sergio Haab. Author. Minjeong Jeon. Author, copyright holder. Michael E. Cotterell. Author, maintainer, copyright holder. University Georgia. Copyright holder.            content opinions expressed material necessarily         reflect views endorsed University Georgia         University System Georgia. Institute Education Sciences. Funder.            work supported U.S. Department Education Institute         Education Sciences IES Award Number R305D220020. National Science Foundation. Funder.            work supported National Science Foundation NSF         Award Number 1921373.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Madison M, Haab S, Jeon M, Cotterell M (2024). TDCM: Transition Diagnostic Classification Model Framework. R package version 0.1.0, https://github.com/cotterell/tdcm.","code":"@Manual{,   title = {TDCM: The Transition Diagnostic Classification Model Framework},   author = {Matthew J. Madison and Sergio Haab and Minjeong Jeon and Michael E. Cotterell},   year = {2024},   note = {R package version 0.1.0},   url = {https://github.com/cotterell/tdcm}, }"},{"path":"/index.html","id":"tdcm","dir":"","previous_headings":"","what":"The Transition Diagnostic Classification Model Framework","title":"The Transition Diagnostic Classification Model Framework","text":"‘TDCM’ R package lets users estimate transition diagnostic classification model (TDCM) described Madison & Bradshaw (2018), longitudinal extension log-linear cognitive diagnosis model (LCDM) Henson, Templin & Willse (2009). LCDM subsumes many diagnostic classification models (DCMs), many DCMs can estimated longitudinally via TDCM framework. ‘TDCM’ package includes functions estimate single-group multigroup TDCM, summarize results interest including item parameters, growth proportions, transition probabilities, transitional reliability, attribute correlations, model fit, growth plots.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"The Transition Diagnostic Classification Model Framework","text":"can install ‘TDCM’ package like :","code":"# Install TDCM from CRAN install.packages(\"TDCM\") # Or install the latest development version of TDCM from GitHub: if (!require(\"devtools\")) install.packages(\"devtools\") devtools::install_github(\"cotterell/tdcm\")"},{"path":"/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting Started","title":"The Transition Diagnostic Classification Model Framework","text":"See vignette(\"TDCM\", package = \"TDCM\") overview ‘TDCM’ package.","code":""},{"path":"/reference/data.tdcm.html","id":null,"dir":"Reference","previous_headings":"","what":"Several data sets for the 'tdcm' package. — data.tdcm","title":"Several data sets for the 'tdcm' package. — data.tdcm","text":"Several data sets 'tdcm' package.","code":""},{"path":"/reference/data.tdcm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Several data sets for the 'tdcm' package. — data.tdcm","text":"","code":"data.tdcm01  data.tdcm02  data.tdcm03  data.tdcm04  data.tdcm05"},{"path":"/reference/data.tdcm.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Several data sets for the 'tdcm' package. — data.tdcm","text":"data.tdcm01 simulated sample data two time points, four attributes, twenty items, one group size 1000, single Q-matrix. format list two: data: data frame binary item responses qmatrix: data frame specifying Q-matrix data.tdcm02 simulated data three time points, two attributes, ten items, one group size 2500, single Q-matrix. format list two: data: data frame binary item responses qmatrix: data frame specifying Q-matrix data.tdcm03 simulated data three time points, two attributes, one group size 1500, three different ten-item Q-matrices time point. Anchor items specified items 1/1/21 items 14/24. format list five: data: data frame binary item responses q1: data frame specifying Q-matrix first time point q2: data frame specifying Q-matrix second time point q3: data frame specifying Q-matrix third time point qmatrix123: data frame specifying combined Q-matrix time points data.tdcm04 simulated data two time points, four attributes, twenty items, two group size 800 900, respectively, single Q-matrix. format list three: data: data frame binary item responses qmatrix: data frame specifying Q-matrix groups: vector specifying examinee group memberships data.tdcm05 simulated data two one time point, four attributes, twenty items. use 1-PLCDM. format list two: data: data frame binary item responses qmatrix: data frame specifying Q-matrix","code":""},{"path":"/reference/data.tdcm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Several data sets for the 'tdcm' package. — data.tdcm","text":"","code":"## Example 1: T = 2, A = 4 data(data.tdcm01, package = \"TDCM\") dat1 <- data.tdcm01$data qmat1 <- data.tdcm01$qmatrix  # estimate TDCM with invariance assumed and full LCDM m1 <- TDCM::tdcm(dat1, qmat1, time.points = 2, invariance = TRUE, dcmrule = \"GDINA\")  # summarize results with tdcm.summary function results <- TDCM::tdcm.summary(m1, time.points = 2) results$item.parameters #>         λ0     λ1,1  λ1,2  λ1,3  λ1,4  λ2,12 λ2,13 λ2,14 λ2,23 λ2,24 #> Item 1  -1.923 2.616   --    --    --    --    --    --    --    --  #> Item 2  -2.071 2.506   --    --    --    --    --    --    --    --  #> Item 3  -1.936 2.506   --    --    --    --    --    --    --    --  #> Item 4  -1.891 1.051 1.471   --    --  1.115   --    --    --    --  #> Item 5  -2.157 1.705   --  1.732   --    --  0.835   --    --    --  #> Item 6  -1.841   --  2.175   --    --    --    --    --    --    --  #> Item 7  -1.841   --  2.272   --    --    --    --    --    --    --  #> Item 8  -1.965   --  2.475   --    --    --    --    --    --    --  #> Item 9  -2.029   --  1.242 1.531   --    --    --    --  1.628   --  #> Item 10 -2.004   --  1.921   --  1.239   --    --    --    --  0.999 #> Item 11 -1.851   --    --  2.349   --    --    --    --    --    --  #> Item 12 -2.045   --    --  2.566   --    --    --    --    --    --  #> Item 13 -2.083   --    --  2.576   --    --    --    --    --    --  #> Item 14 -2.125   --    --  1.739 2.104   --    --    --    --    --  #> Item 15 -1.805 0.777   --  1.31    --    --  1.896   --    --    --  #> Item 16 -2.156   --    --    --  2.736   --    --    --    --    --  #> Item 17 -2.089   --    --    --  2.679   --    --    --    --    --  #> Item 18 -2.087   --    --    --  2.476   --    --    --    --    --  #> Item 19 -2.11  2.219   --    --  1.46    --    --  0.558   --    --  #> Item 20 -2.047   --  2.408   --  1.49    --    --    --    --  0.154 #>         λ2,34 #> Item 1    --  #> Item 2    --  #> Item 3    --  #> Item 4    --  #> Item 5    --  #> Item 6    --  #> Item 7    --  #> Item 8    --  #> Item 9    --  #> Item 10   --  #> Item 11   --  #> Item 12   --  #> Item 13   --  #> Item 14 0.493 #> Item 15   --  #> Item 16   --  #> Item 17   --  #> Item 18   --  #> Item 19   --  #> Item 20   --  results$growth #>             T1[1] T2[1] #> Attribute 1 0.201 0.372 #> Attribute 2 0.327 0.492 #> Attribute 3 0.397 0.573 #> Attribute 4 0.252 0.696 results$transition.probabilities #> , , Attribute 1: Time 1 to Time 2 #>  #>        T2 [0] T2 [1] #> T1 [0]  0.678  0.322 #> T1 [1]  0.432  0.568 #>  #> , , Attribute 2: Time 1 to Time 2 #>  #>        T2 [0] T2 [1] #> T1 [0]  0.578  0.422 #> T1 [1]  0.363  0.637 #>  #> , , Attribute 3: Time 1 to Time 2 #>  #>        T2 [0] T2 [1] #> T1 [0]   0.55   0.45 #> T1 [1]   0.24   0.76 #>  #> , , Attribute 4: Time 1 to Time 2 #>  #>        T2 [0] T2 [1] #> T1 [0]  0.365  0.635 #> T1 [1]  0.123  0.877 #>   # estimate TDCM with invariance assumed and only main effects m2 <- TDCM::tdcm(dat1, qmat1, time.points = 2, invariance = TRUE, dcmrule = \"GDINA1\")  # estimate TDCM with invariance not assumed m3 <- TDCM::tdcm(dat1, qmat1, time.points = 2, invariance = FALSE, dcmrule = \"GDINA\")  # compare models to assess measurement invariance. TDCM::tdcm.compare(m1, m3) #>   Model   loglike Deviance Npars      AIC      BIC Chisq df      p #> 1    m1 -21429.51 42859.02    93 43045.02 43501.44 58.14 56 0.3965 #> 2    m3 -21400.44 42800.88   149 43098.88 43830.14    NA NA     NA  ## Example 2: T = 3, A = 2 data(data.tdcm02, package = \"TDCM\") dat2 <- data.tdcm02$data qmat2 <- data.tdcm02$qmatrix  # estimate TDCM with invariance assumed and full LCDM m1 <- TDCM::tdcm(dat2, qmat2, time.points = 3)  # estimate TDCM with invariance not assumed m2 <- TDCM::tdcm(dat2, qmat2, time.points = 3, invariance = FALSE)  # compare models to assess measurement invariance TDCM::tdcm.compare(m1, m2) #>   Model   loglike Deviance Npars      AIC      BIC Chisq df      p #> 1    m1 -46110.97 92221.95    50 92321.95 92613.15  73.8 56 0.0556 #> 2    m2 -46074.07 92148.13   106 92360.13 92977.48    NA NA     NA"},{"path":"/reference/item.influence.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimating item influence measures. — item.influence","title":"Estimating item influence measures. — item.influence","text":"Function estimate estimate item influence measures. Code adapted (Jurich & Madison, 2023). function available longitudinal DCMs.","code":""},{"path":"/reference/item.influence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimating item influence measures. — item.influence","text":"","code":"item.influence(model, data, fullcorrelation = FALSE, progress = TRUE)"},{"path":"/reference/item.influence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimating item influence measures. — item.influence","text":"model previously calibrated model; object class gdina. data required \\(N \\times \\) matrix. Binary item responses columns. fullcorrelation optional logical argument indicating full reduced response-classification correlation matrix. progress optional logical indicating whether function print progress estimation.","code":""},{"path":"/reference/item.influence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimating item influence measures. — item.influence","text":"list containing several item influence measures.","code":""},{"path":"/reference/item.influence.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimating item influence measures. — item.influence","text":"DCMs, item influence quantifies much item impacts classifications. Given estimated DCM item response data, function estimates five item influence measures, including item pull, item override, proportion attribute information, response-classification correlation (corr1), response-posterior correlation (corr2).","code":""},{"path":"/reference/item.influence.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimating item influence measures. — item.influence","text":"Currently, function currently runs DCMs estimated single time point. run properly TDCM objects.","code":""},{"path":"/reference/item.influence.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimating item influence measures. — item.influence","text":"Jurich, D. & Madison, M. J. (2023). Measuring item influence diagnostic classification models. Educational Assessment.","code":""},{"path":"/reference/item.influence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimating item influence measures. — item.influence","text":"","code":"## Item influence illustration #load data (simulated based on Jurich and Bradshaw (2014)) qmatrix <- CDM::data.sda6$q.matrix responses <- CDM::data.sda6$data  #Estimate the full LCDM model1 <- CDM::gdina(responses, qmatrix, linkfct = \"logit\", method = \"ML\") #> ----------------------------------------------------------------- #> CDM 8.2-6 (2022-08-25 15:43:23)  #> GDINA Model  #>  Link function: logit  #>   ** 2024-02-01 00:09:14.445008  #> ----------------------------------------------------------------- #> ........................................................... #> Iteration 1     2024-02-01 00:09:14.463446  #> Deviance = 41250.26 #> Maximum parameter change: 0.255116  #> ........................................................... #> Iteration 2     2024-02-01 00:09:14.503748  #> Deviance = 37307.05 | Deviance change = 3943.205 #> Maximum parameter change: 0.237804  #> ........................................................... #> Iteration 3     2024-02-01 00:09:14.527036  #> Deviance = 36844.82 | Deviance change = 462.2331 #> Maximum parameter change: 0.058056  #> ........................................................... #> Iteration 4     2024-02-01 00:09:14.555745  #> Deviance = 36784.82 | Deviance change = 60.00074 #> Maximum parameter change: 0.037476  #> ........................................................... #> Iteration 5     2024-02-01 00:09:14.581701  #> Deviance = 36765.74 | Deviance change = 19.07726 #> Maximum parameter change: 0.134754  #> ........................................................... #> Iteration 6     2024-02-01 00:09:14.611646  #> Deviance = 36639.5 | Deviance change = 126.237 #> Maximum parameter change: 0.052503  #> ........................................................... #> Iteration 7     2024-02-01 00:09:14.630995  #> Deviance = 36619.88 | Deviance change = 19.628 #> Maximum parameter change: 0.058732  #> ........................................................... #> Iteration 8     2024-02-01 00:09:14.657052  #> Deviance = 36562.93 | Deviance change = 56.9458 #> Maximum parameter change: 0.028076  #> ........................................................... #> Iteration 9     2024-02-01 00:09:14.675588  #> Deviance = 36557.01 | Deviance change = 5.918638 #> Maximum parameter change: 0.069777  #> ........................................................... #> Iteration 10     2024-02-01 00:09:14.702422  #> Deviance = 36533.7 | Deviance change = 23.31049 #> Maximum parameter change: 0.006856  #> ........................................................... #> Iteration 11     2024-02-01 00:09:14.717512  #> Deviance = 36535.91 | Deviance change = -2.21303 #> **** Deviances decreases! Check for nonconvergence.   **** #> Maximum parameter change: 0.034248  #> ........................................................... #> Iteration 12     2024-02-01 00:09:14.749153  #> Deviance = 36529.54 | Deviance change = 6.379348 #> Maximum parameter change: 0.005495  #> ........................................................... #> Iteration 13     2024-02-01 00:09:14.763527  #> Deviance = 36528.75 | Deviance change = 0.7851916 #> Maximum parameter change: 0.003748  #> ........................................................... #> Iteration 14     2024-02-01 00:09:14.783071  #> Deviance = 36528.29 | Deviance change = 0.4589058 #> Maximum parameter change: 0.00302  #> ........................................................... #> Iteration 15     2024-02-01 00:09:14.797489  #> Deviance = 36527.71 | Deviance change = 0.5760876 #> Maximum parameter change: 0.009911  #> ........................................................... #> Iteration 16     2024-02-01 00:09:14.823913  #> Deviance = 36527.23 | Deviance change = 0.4854475 #> Maximum parameter change: 0.00118  #> ........................................................... #> Iteration 17     2024-02-01 00:09:14.838259  #> Deviance = 36526.96 | Deviance change = 0.2715357 #> Maximum parameter change: 0.010884  #> ........................................................... #> Iteration 18     2024-02-01 00:09:14.865014  #> Deviance = 36526.76 | Deviance change = 0.2015728 #> Maximum parameter change: 0.001425  #> ........................................................... #> Iteration 19     2024-02-01 00:09:14.87914  #> Deviance = 36526.66 | Deviance change = 0.1012999 #> Maximum parameter change: 0.00123  #> ........................................................... #> Iteration 20     2024-02-01 00:09:14.893876  #> Deviance = 36526.58 | Deviance change = 0.0787773 #> Maximum parameter change: 0.001022  #> ........................................................... #> Iteration 21     2024-02-01 00:09:14.907803  #> Deviance = 36526.51 | Deviance change = 0.0670459 #> Maximum parameter change: 0.000859  #> ........................................................... #> Iteration 22     2024-02-01 00:09:14.928846  #> Deviance = 36526.45 | Deviance change = 0.0594842 #> Maximum parameter change: 0.00073  #> ........................................................... #> Iteration 23     2024-02-01 00:09:14.942664  #> Deviance = 36526.4 | Deviance change = 0.0540514 #> Maximum parameter change: 0.000624  #> ........................................................... #> Iteration 24     2024-02-01 00:09:14.956513  #> Deviance = 36526.35 | Deviance change = 0.0498587 #> Maximum parameter change: 0.000537  #> ........................................................... #> Iteration 25     2024-02-01 00:09:14.970611  #> Deviance = 36526.3 | Deviance change = 0.0464631 #> Maximum parameter change: 0.000465  #> ........................................................... #> Iteration 26     2024-02-01 00:09:14.984718  #> Deviance = 36526.26 | Deviance change = 0.0436157 #> Maximum parameter change: 0.000405  #> ........................................................... #> Iteration 27     2024-02-01 00:09:14.998871  #> Deviance = 36526.21 | Deviance change = 0.0411638 #> Maximum parameter change: 0.000355  #> ........................................................... #> Iteration 28     2024-02-01 00:09:15.013252  #> Deviance = 36526.18 | Deviance change = 0.0390077 #> Maximum parameter change: 0.000312  #> ........................................................... #> Iteration 29     2024-02-01 00:09:15.027665  #> Deviance = 36526.14 | Deviance change = 0.0370793 #> Maximum parameter change: 0.000277  #> ........................................................... #> Iteration 30     2024-02-01 00:09:15.042025  #> Deviance = 36526.1 | Deviance change = 0.0353313 #> Maximum parameter change: 0.000246  #> ........................................................... #> Iteration 31     2024-02-01 00:09:15.056272  #> Deviance = 36526.07 | Deviance change = 0.0337297 #> Maximum parameter change: 0.00022  #> ........................................................... #> Iteration 32     2024-02-01 00:09:15.07682  #> Deviance = 36526.04 | Deviance change = 0.0322497 #> Maximum parameter change: 0.000212  #> ........................................................... #> Iteration 33     2024-02-01 00:09:15.091149  #> Deviance = 36526.01 | Deviance change = 0.0308728 #> Maximum parameter change: 0.000207  #> ........................................................... #> Iteration 34     2024-02-01 00:09:15.105295  #> Deviance = 36525.98 | Deviance change = 0.0295852 #> Maximum parameter change: 0.000202  #> ........................................................... #> Iteration 35     2024-02-01 00:09:15.119243  #> Deviance = 36525.95 | Deviance change = 0.028376 #> Maximum parameter change: 0.000197  #> ........................................................... #> Iteration 36     2024-02-01 00:09:15.133113  #> Deviance = 36525.92 | Deviance change = 0.0272367 #> Maximum parameter change: 0.000192  #> ........................................................... #> Iteration 37     2024-02-01 00:09:15.147075  #> Deviance = 36525.9 | Deviance change = 0.0261606 #> Maximum parameter change: 0.000187  #> ........................................................... #> Iteration 38     2024-02-01 00:09:15.161077  #> Deviance = 36525.87 | Deviance change = 0.025142 #> Maximum parameter change: 0.000183  #> ........................................................... #> Iteration 39     2024-02-01 00:09:15.175001  #> Deviance = 36525.85 | Deviance change = 0.0241762 #> Maximum parameter change: 0.000178  #> ........................................................... #> Iteration 40     2024-02-01 00:09:15.188749  #> Deviance = 36525.82 | Deviance change = 0.0232592 #> Maximum parameter change: 0.000174  #> ........................................................... #> Iteration 41     2024-02-01 00:09:15.202446  #> Deviance = 36525.8 | Deviance change = 0.0223876 #> Maximum parameter change: 0.00017  #> ........................................................... #> Iteration 42     2024-02-01 00:09:15.21603  #> Deviance = 36525.78 | Deviance change = 0.0215582 #> Maximum parameter change: 0.000166  #> ........................................................... #> Iteration 43     2024-02-01 00:09:15.235815  #> Deviance = 36525.76 | Deviance change = 0.0207684 #> Maximum parameter change: 0.000162  #> ........................................................... #> Iteration 44     2024-02-01 00:09:15.2492  #> Deviance = 36525.74 | Deviance change = 0.0200156 #> Maximum parameter change: 0.000158  #> ........................................................... #> Iteration 45     2024-02-01 00:09:15.262502  #> Deviance = 36525.72 | Deviance change = 0.0192977 #> Maximum parameter change: 0.000154  #> ........................................................... #> Iteration 46     2024-02-01 00:09:15.275733  #> Deviance = 36525.7 | Deviance change = 0.0186127 #> Maximum parameter change: 0.00015  #> ........................................................... #> Iteration 47     2024-02-01 00:09:15.28895  #> Deviance = 36525.68 | Deviance change = 0.0179586 #> Maximum parameter change: 0.000147  #> ........................................................... #> Iteration 48     2024-02-01 00:09:15.30267  #> Deviance = 36525.66 | Deviance change = 0.0173337 #> Maximum parameter change: 0.000143  #> ........................................................... #> Iteration 49     2024-02-01 00:09:15.316083  #> Deviance = 36525.65 | Deviance change = 0.0167363 #> Maximum parameter change: 0.00014  #> ........................................................... #> Iteration 50     2024-02-01 00:09:15.329731  #> Deviance = 36525.63 | Deviance change = 0.0161651 #> Maximum parameter change: 0.000137  #> ........................................................... #> Iteration 51     2024-02-01 00:09:15.342756  #> Deviance = 36525.62 | Deviance change = 0.0156186 #> Maximum parameter change: 0.000134  #> ........................................................... #> Iteration 52     2024-02-01 00:09:15.355651  #> Deviance = 36525.6 | Deviance change = 0.0150956 #> Maximum parameter change: 0.000131  #> ........................................................... #> Iteration 53     2024-02-01 00:09:15.368228  #> Deviance = 36525.59 | Deviance change = 0.0145947 #> Maximum parameter change: 0.000128  #> ........................................................... #> Iteration 54     2024-02-01 00:09:15.38678  #> Deviance = 36525.57 | Deviance change = 0.0141148 #> Maximum parameter change: 0.000125  #> ........................................................... #> Iteration 55     2024-02-01 00:09:15.399332  #> Deviance = 36525.56 | Deviance change = 0.0136549 #> Maximum parameter change: 0.000122  #> ........................................................... #> Iteration 56     2024-02-01 00:09:15.411476  #> Deviance = 36525.55 | Deviance change = 0.013214 #> Maximum parameter change: 0.000119  #> ........................................................... #> Iteration 57     2024-02-01 00:09:15.423647  #> Deviance = 36525.53 | Deviance change = 0.0127911 #> Maximum parameter change: 0.000117  #> ........................................................... #> Iteration 58     2024-02-01 00:09:15.435843  #> Deviance = 36525.52 | Deviance change = 0.0123853 #> Maximum parameter change: 0.000114  #> ........................................................... #> Iteration 59     2024-02-01 00:09:15.448048  #> Deviance = 36525.51 | Deviance change = 0.0119958 #> Maximum parameter change: 0.000112  #> ........................................................... #> Iteration 60     2024-02-01 00:09:15.460407  #> Deviance = 36525.5 | Deviance change = 0.0116218 #> Maximum parameter change: 0.000109  #> ........................................................... #> Iteration 61     2024-02-01 00:09:15.472785  #> Deviance = 36525.49 | Deviance change = 0.0112625 #> Maximum parameter change: 0.000107  #> ........................................................... #> Iteration 62     2024-02-01 00:09:15.485215  #> Deviance = 36525.47 | Deviance change = 0.0109173 #> Maximum parameter change: 0.000105  #> ........................................................... #> Iteration 63     2024-02-01 00:09:15.498149  #> Deviance = 36525.46 | Deviance change = 0.0105854 #> Maximum parameter change: 0.000102  #> ........................................................... #> Iteration 64     2024-02-01 00:09:15.510533  #> Deviance = 36525.45 | Deviance change = 0.0102663 #> Maximum parameter change: 1e-04  #> ........................................................... #> Iteration 65     2024-02-01 00:09:15.522818  #> Deviance = 36525.44 | Deviance change = 0.0099593 #> Maximum parameter change: 9.8e-05  #> ----------------------------------------------------------------- #> Time difference of 1.159065 secs  #Estimate item influence measures influence <- TDCM::item.influence(model1, responses) #> [1] Calclating item influence measures. Progress = 0%. #> [1] Calclating item influence measures. Progress = 24%. #> [1] Calclating item influence measures. Progress = 47%. #> [1] Calclating item influence measures. Progress = 71%. #> [1] Calclating item influence measures. Progress = 94%. #> [1] Routine finished. Check results.  #Summarize influence statistics influence$Pull #item pull #>    Item Attribute pull0 pull1 #> 1     1         1  0.65  0.65 #> 2     2         1  0.68  0.74 #> 3     3         1  0.60  0.69 #> 4     4         1  0.86  0.68 #> 5     5         2  0.50  0.70 #> 6     6         2  0.47  0.81 #> 7     7         2  0.52  0.76 #> 8     8         2  0.59  0.76 #> 9     9         3  0.60  0.63 #> 10   10         3  0.58  0.71 #> 11   11         3  0.50  0.71 #> 12   12         3  0.55  0.68 #> 13   13         3  1.00  0.82 #> 14   14         3  0.86  0.75 #> 15   15         4  0.58  0.77 #> 16   16         4  0.63  0.86 #> 17   17         4  0.75  0.75 influence$Override #item override #>    Item Attribute override #> 1     1         1     0.07 #> 2     2         1     0.10 #> 3     3         1     0.04 #> 4     4         1     0.11 #> 5     5         2     0.03 #> 6     6         2     0.07 #> 7     7         2     0.07 #> 8     8         2     0.09 #> 9     9         3     0.02 #> 10   10         3     0.04 #> 11   11         3     0.02 #> 12   12         3     0.03 #> 13   13         3     0.16 #> 14   14         3     0.09 #> 15   15         4     0.10 #> 16   16         4     0.22 #> 17   17         4     0.09 influence$Information #proportion of attribute information #>    Item Attribute propinfo #> 1     1         1     0.16 #> 2     2         1     0.24 #> 3     3         1     0.13 #> 4     4         1     0.48 #> 5     5         2     0.12 #> 6     6         2     0.25 #> 7     7         2     0.27 #> 8     8         2     0.37 #> 9     9         3     0.03 #> 10   10         3     0.08 #> 11   11         3     0.04 #> 12   12         3     0.04 #> 13   13         3     0.59 #> 14   14         3     0.22 #> 15   15         4     0.22 #> 16   16         4     0.40 #> 17   17         4     0.38 influence$Correlation1 #correlation of responses and classifications #>    Item Attribute Correl1 #> 1     1         1    0.30 #> 2     2         1    0.41 #> 3     3         1    0.27 #> 4     4         1    0.52 #> 5     5         2    0.19 #> 6     6         2    0.29 #> 7     7         2    0.29 #> 8     8         2    0.34 #> 9     9         3    0.19 #> 10   10         3    0.30 #> 11   11         3    0.21 #> 12   12         3    0.23 #> 13   13         3    0.76 #> 14   14         3    0.56 #> 15   15         4    0.36 #> 16   16         4    0.50 #> 17   17         4    0.47 influence$Correlation2 #correlation of responses and posterior probabilities #>    Item Attribute Correl2 #> 1     1         1    0.36 #> 2     2         1    0.44 #> 3     3         1    0.33 #> 4     4         1    0.60 #> 5     5         2    0.22 #> 6     6         2    0.31 #> 7     7         2    0.33 #> 8     8         2    0.39 #> 9     9         3    0.21 #> 10   10         3    0.36 #> 11   11         3    0.25 #> 12   12         3    0.27 #> 13   13         3    0.82 #> 14   14         3    0.58 #> 15   15         4    0.44 #> 16   16         4    0.58 #> 17   17         4    0.58"},{"path":"/reference/mg.summary.param1.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility function in TDCM — mg.summary.param1","title":"Utility function in TDCM — mg.summary.param1","text":"Utility function TDCM","code":""},{"path":"/reference/mg.summary.param1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility function in TDCM — mg.summary.param1","text":"","code":"mg.summary.param1(model, time.points, num.atts, num.items)"},{"path":"/reference/mg.summary.param1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility function in TDCM — mg.summary.param1","text":"model gdina object mg.tdcm function time.points number time points num.atts number attributes num.items number items","code":""},{"path":"/reference/mg.summary.param2.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility function in TDCM — mg.summary.param2","title":"Utility function in TDCM — mg.summary.param2","text":"Utility function TDCM","code":""},{"path":"/reference/mg.summary.param2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility function in TDCM — mg.summary.param2","text":"","code":"mg.summary.param2(model, time.points, num.atts, num.items)"},{"path":"/reference/mg.summary.param2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility function in TDCM — mg.summary.param2","text":"model gdina object mg.tdcm function time.points number time points num.atts number attributes num.items number items","code":""},{"path":"/reference/mg.summary.param3.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility function in TDCM — mg.summary.param3","title":"Utility function in TDCM — mg.summary.param3","text":"Utility function TDCM","code":""},{"path":"/reference/mg.summary.param3.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility function in TDCM — mg.summary.param3","text":"","code":"mg.summary.param3(model, time.points, num.atts, num.items)"},{"path":"/reference/mg.summary.param3.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility function in TDCM — mg.summary.param3","text":"model gdina object mg.tdcm function time.points number time points num.atts number attributes num.items number items","code":""},{"path":"/reference/mg.summary.param4.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility function in TDCM — mg.summary.param4","title":"Utility function in TDCM — mg.summary.param4","text":"Utility function TDCM","code":""},{"path":"/reference/mg.summary.param4.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility function in TDCM — mg.summary.param4","text":"","code":"mg.summary.param4(model, time.points, num.atts, num.items)"},{"path":"/reference/mg.summary.param4.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility function in TDCM — mg.summary.param4","text":"model gdina object mg.tdcm function time.points number time points num.atts number attributes num.items number items","code":""},{"path":"/reference/mg.summary1.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility function in TDCM — mg.summary1","title":"Utility function in TDCM — mg.summary1","text":"Utility function TDCM","code":""},{"path":"/reference/mg.summary1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility function in TDCM — mg.summary1","text":"","code":"mg.summary1(   model,   num.atts,   num.groups,   time.points,   attribute.names,   group.names )"},{"path":"/reference/mg.summary1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility function in TDCM — mg.summary1","text":"model gdina object mg.tdcm function num.atts number attributes num.groups number groups time.points number time points attribute.names optional vector specify attribute names group.names optional vector specify group names","code":""},{"path":"/reference/mg.summary2.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility function in TDCM — mg.summary2","title":"Utility function in TDCM — mg.summary2","text":"Utility function TDCM","code":""},{"path":"/reference/mg.summary2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility function in TDCM — mg.summary2","text":"","code":"mg.summary2(   model,   num.atts,   num.groups,   time.points,   attribute.names,   group.names )"},{"path":"/reference/mg.summary2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility function in TDCM — mg.summary2","text":"model gdina object mg.tdcm function num.atts number attributes num.groups number groups time.points number time points attribute.names optional vector specify attribute names group.names optional vector specify group names","code":""},{"path":"/reference/mg.summary3.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility function in TDCM — mg.summary3","title":"Utility function in TDCM — mg.summary3","text":"Utility function TDCM","code":""},{"path":"/reference/mg.summary3.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility function in TDCM — mg.summary3","text":"","code":"mg.summary3(   model,   num.atts,   num.groups,   time.points,   attribute.names,   group.names )"},{"path":"/reference/mg.summary3.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility function in TDCM — mg.summary3","text":"model gdina object mg.tdcm function num.atts number attributes num.groups number groups time.points number time points attribute.names optional vector specify attribute names group.names optional vector specify group names","code":""},{"path":"/reference/mg.tdcm.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimating the multigroup transition diagnostic classification model (TDCM) — mg.tdcm","title":"Estimating the multigroup transition diagnostic classification model (TDCM) — mg.tdcm","text":"function estimates multigroup TDCM (Madison & Bradshaw, 2018).","code":""},{"path":"/reference/mg.tdcm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimating the multigroup transition diagnostic classification model (TDCM) — mg.tdcm","text":"","code":"mg.tdcm(   data,   qmatrix,   time.points,   dcmrule = \"GDINA\",   groups,   group.invariance = TRUE,   item.invariance = TRUE,   progress = TRUE )"},{"path":"/reference/mg.tdcm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimating the multigroup transition diagnostic classification model (TDCM) — mg.tdcm","text":"data required \\(N \\times T \\times \\) matrix. time point, binary item responses columns. qmatrix required \\(\\times \\) matrix indicating items measure attributes. time.points number time points (.e., measurement/testing occasions), integer \\(\\ge 2\\). dcmrule specific DCM employed. Currently accepts “GDINA”, “ACDM”, “DINA”, “GDINA1”, “GDINA2”, . Default “GDINA”, implemented logit link estimate LCDM. “ACDM” rule estimate LCDM main effects. “DINA” rule estimate DINA model. “GDINA1” estimate LCDM main effects, equivalent “ACDM”. “GDINA2” estimate LCDM two-way interaction effects. dcmrule entered single string, DCM assumed item. entered vector, DCM can specified item. groups required vector group identifiers multiple group estimation. group.invariance logical indicator whether item parameter invariance assumed equal groups. Default = T. specified false, item parameters assumed equal groups. item.invariance logical indicator whether item parameter invariance constrained equal time point. Default = T. specified false, item parameters assumed equal time. progress optional logical indicating whether function print progress estimation.","code":""},{"path":"/reference/mg.tdcm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimating the multigroup transition diagnostic classification model (TDCM) — mg.tdcm","text":"object class gdina entries indicated CDM package. TDCM-specific results (e.g., growth, transitions), results summarized using mg.tdcm.summary function.","code":""},{"path":"/reference/mg.tdcm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimating the multigroup transition diagnostic classification model (TDCM) — mg.tdcm","text":"Currently, function accepts single Q-matrix.","code":""},{"path":"/reference/mg.tdcm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimating the multigroup transition diagnostic classification model (TDCM) — mg.tdcm","text":"Madison, M. J., & Bradshaw, L. (2018). Evaluating intervention effects diagnostic classification model framework. Journal Educational Measurement, 55(1), 32-51.","code":""},{"path":"/reference/mg.tdcm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimating the multigroup transition diagnostic classification model (TDCM) — mg.tdcm","text":"","code":"## Example 4: G = 2, T = 2, A = 4 data(data.tdcm04, package = \"TDCM\") dat4 <- data.tdcm04$data qmat4 <- data.tdcm04$qmatrix group4 <- data.tdcm04$groups  # estimate mgTDCM with invariance assumed and full LCDM mg1 <- TDCM::mg.tdcm(dat4, qmat4,   time.points = 2, dcmrule = \"GDINA\",   group = group4, group.invariance = TRUE, item.invariance = TRUE) #> [1] Preparing data... #> [1] Estimating mgTDCM... #> [1] Note: Depending on model specifications, estimation for the multigroup TDCM can take a few minutes.  #> [1] Estimating mgTDCM, progress = 48%... #> [1] Routine finished. Use the mg.tdcm.summary function to display results.  # summarize results results1 <- TDCM::mg.tdcm.summary(mg1, time.points = 2) #> [1] Summarizing results... #> [1] Summarizing results, progress = 43%... #> [1] Routine finished. Check results.  # plot results TDCM::tdcm.plot(results1)         #> [1] **Check plots window for line and bar plots for growth proportions.  # estimate mgTDCM without group invariance mg2 <- TDCM::mg.tdcm(dat4, qmat4,   time.points = 2, dcmrule = \"GDINA\",   group = group4, group.invariance = FALSE, item.invariance = TRUE) #> [1] Preparing data... #> [1] Estimating mgTDCM... #> [1] Note: Depending on model specifications, estimation for the multigroup TDCM can take a few minutes.  #> [1] Estimating mgTDCM, progress = 41%... #> [1] Routine finished. Use the mg.tdcm.summary function to display results.  # compare models to assess group invariance TDCM::tdcm.compare(mg1, mg2) #>   Model   loglike Deviance Npars      AIC      BIC Chisq df      p #> 1   mg1 -37371.96 74743.92   130 75003.92 75710.91 27.92 56 0.9994 #> 2   mg2    -37358    74716   186    75088 76099.54    NA NA     NA"},{"path":"/reference/mg.tdcm.summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Multigroup TDCM results compiler and summarizer. — mg.tdcm.summary","title":"Multigroup TDCM results compiler and summarizer. — mg.tdcm.summary","text":"function compile results calibration multigroup TDCM (Madison & Bradshaw, 2018).","code":""},{"path":"/reference/mg.tdcm.summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multigroup TDCM results compiler and summarizer. — mg.tdcm.summary","text":"","code":"mg.tdcm.summary(   model,   time.points,   transition.option = 1,   classthreshold = 0.5,   attribute.names = c(),   group.names = c() )"},{"path":"/reference/mg.tdcm.summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multigroup TDCM results compiler and summarizer. — mg.tdcm.summary","text":"model gdina object returned mg.tdcm function. time.points number time points (.e., measurement/testing occasions), integer \\(\\ge 2\\). transition.option option reporting results. = 1 compares first time point last. = 2 compares first time point every time point. = 3 compares successive time points. Default = 1. classthreshold probability threshold establishing proficiency examinee posterior probabilities. Default .50, maximizes overall classification accuracy. can set lower value minimize false negatives (.e., misclassifying proficient examinees non-proficient) set higher value minimize false positives (.e., misclassifying non-proficient examinees proficient). attribute.names optional vector attribute names include plots. group.names optional vector group names include plots.","code":""},{"path":"/reference/mg.tdcm.summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multigroup TDCM results compiler and summarizer. — mg.tdcm.summary","text":"list following items: $item.parameters: LCDM item parameter estimates specified DCM. $growth: proficiency proportions time point attribute $transition.probabilities: conditional attribute proficiency transition probability matrices $posterior.probabilities: examinee marginal attribute posterior probabilities proficiency $transition.posteriors: examinee marginal attribute transition posterior probabilities $.likely.transitions: examinee likely transitions attribute transition $classifications: examinee classifications determined specified threshold applied posterior probabilities $reliability: estimated transition reliability metrics attribute specified transitions. “pt bis” = longitudinal point biserial metric; “info gain” = longitudinal information gain metric; “polychor” = longitudinal tetrachoric metric; “ave max tr” = average maximum transition posterior metric; “P(t>k)” = proportion examinee marginal attribute transition posteriors greater k; “wt pt bis” = weighted longitudinal point biserial; “wt info gain” = weighted longitudinal information gain. $att.corr: estimated attribute correlation matrix $model.fit: Several model fit indices tests output including item root mean square error approximation (RMSEA; von Davier, 2005), mean RMSEA, bivariate item fit statistics (Chen et al., 2013), absolute fit statistics mean absolute deviation observed expected item correlations (MADcor; DiBello, Roussons, & Stout, 2007), standardized root mean square root squared residuals (SRMSR; Maydeu-Olivares, 2013)","code":""},{"path":"/reference/mg.tdcm.summary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multigroup TDCM results compiler and summarizer. — mg.tdcm.summary","text":"Provides summary multigroup TDCM results including item parameters, attribute posterior probabilities, transition posterior probabilities, classifications, group-wise growth, group-wise transition probabilities, attribute correlations, several transition reliability metrics, model fit. Includes longitudinal versions reliability metrics developed Templin Bradshaw (2013) Johnson Sinharay (2020).","code":""},{"path":"/reference/mg.tdcm.summary.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multigroup TDCM results compiler and summarizer. — mg.tdcm.summary","text":"Chen, J., de la Torre, J. ,& Zhang, Z. (2013). Relative absolute fit evaluation cognitive diagnosis modeling. Journal Educational Measurement, 50, 123-140. DiBello, L. V., Roussos, L. ., & Stout, W. F. (2007). Review cognitively diagnostic assessment summary psychometric models. C. R. Rao S. Sinharay (Eds.), Handbook Statistics, Vol. 26 (pp.979–1030). Amsterdam: Elsevier. Johnson, M. S., & Sinharay, S. (2020). reliability posterior probability skill attainment diagnostic classification models. Journal Educational Measurement, 47(1), 5 – 31. Madison, M. J. (2019). Reliably assessing growth longitudinal diagnostic classification models. Educational Measurement: Issues Practice, 38(2), 68-78. Madison, M. J., & Bradshaw, L. (2018). Evaluating intervention effects diagnostic classification model framework. Journal Educational Measurement, 55(1), 32-51. Maydeu-Olivares, . (2013). Goodness--fit assessment item response theory models (discussion). Measurement: Interdisciplinary Research Perspectives, 11, 71-137. Schellman, M., & Madison, M. J. (2021, July). Estimating reliability skill transition longitudinal DCMs. Paper presented 2021 International Meeting Psychometric Society. Templin, J., & Bradshaw, L. (2013). Measuring reliability diagnostic classification model examinee estimates. Journal Classification, 30, 251-275. von Davier M. (2008). general diagnostic model applied language testing data. British journal mathematical statistical psychology, 61(2), 287–307.","code":""},{"path":"/reference/mg.tdcm.summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multigroup TDCM results compiler and summarizer. — mg.tdcm.summary","text":"","code":"## Example 4: G = 2, T = 2, A = 4 data(data.tdcm04, package = \"TDCM\") dat4 <- data.tdcm04$data qmat4 <- data.tdcm04$qmatrix group4 <- data.tdcm04$groups  # estimate mgTDCM with invariance assumed and full LCDM mg1 <- TDCM::mg.tdcm(dat4, qmat4,   time.points = 2, dcmrule = \"GDINA\",   group = group4, group.invariance = TRUE, item.invariance = TRUE) #> [1] Preparing data... #> [1] Estimating mgTDCM... #> [1] Note: Depending on model specifications, estimation for the multigroup TDCM can take a few minutes.  #> [1] Estimating mgTDCM, progress = 31%... #> [1] Routine finished. Use the mg.tdcm.summary function to display results.  # summarize results results1 <- TDCM::mg.tdcm.summary(mg1, time.points = 2) #> [1] Summarizing results... #> [1] Summarizing results, progress = 50%... #> [1] Routine finished. Check results.  # plot results TDCM::tdcm.plot(results1)         #> [1] **Check plots window for line and bar plots for growth proportions.  # estimate mgTDCM without group invariance mg2 <- TDCM::mg.tdcm(dat4, qmat4,   time.points = 2, dcmrule = \"GDINA\",   group = group4, group.invariance = FALSE, item.invariance = TRUE) #> [1] Preparing data... #> [1] Estimating mgTDCM... #> [1] Note: Depending on model specifications, estimation for the multigroup TDCM can take a few minutes.  #> [1] Estimating mgTDCM, progress = 31%... #> [1] Routine finished. Use the mg.tdcm.summary function to display results.   # compare models to assess group invariance TDCM::tdcm.compare(mg1, mg2) #>   Model   loglike Deviance Npars      AIC      BIC Chisq df      p #> 1   mg1 -37371.96 74743.92   130 75003.92 75710.91 27.92 56 0.9994 #> 2   mg2    -37358    74716   186    75088 76099.54    NA NA     NA"},{"path":"/reference/oneplcdm.html","id":null,"dir":"Reference","previous_headings":"","what":"One-parameter log-linear cognitive diagnosis model. — oneplcdm","title":"One-parameter log-linear cognitive diagnosis model. — oneplcdm","text":"Function estimate 1-PLCDM (Madison et al., 2023; Maas et al., 2023).","code":""},{"path":"/reference/oneplcdm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"One-parameter log-linear cognitive diagnosis model. — oneplcdm","text":"","code":"oneplcdm(data, qmatrix, progress = TRUE)"},{"path":"/reference/oneplcdm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"One-parameter log-linear cognitive diagnosis model. — oneplcdm","text":"data required \\(N \\times \\) matrix. Binary item responses columns. qmatrix required \\(\\times \\) matrix indicating items measure attributes. progress optional logical indicating whether function print progress estimation.","code":""},{"path":"/reference/oneplcdm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"One-parameter log-linear cognitive diagnosis model. — oneplcdm","text":"object class gdina entries indicated CDM package.","code":""},{"path":"/reference/oneplcdm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"One-parameter log-linear cognitive diagnosis model. — oneplcdm","text":"Estimates single-attribute multi-attribute 1-PLCDM described Madison et al. (2023). Example shows attribute subscores sufficient statistics classifications.","code":""},{"path":"/reference/oneplcdm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"One-parameter log-linear cognitive diagnosis model. — oneplcdm","text":"Currently, model embedded within TDCM via dcmrule argument.","code":""},{"path":"/reference/oneplcdm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"One-parameter log-linear cognitive diagnosis model. — oneplcdm","text":"George, . C., Robitzsch, ., Kiefer, T., Gross, J., & Ünlü , . (2016). R package CDM cognitive diagnosis models. Journal Statistical Software, 74(2), 1-24. Henson, R., Templin, J., & Willse, J. (2009). Defining family cognitive diagnosis models using log linear models latent variables. Psychometrika, 74, 191-21. Madison, M.J., Chung, S., Kim, J., & Bradshaw, L. (2023). Approaches estimating longitudinal diagnostic classification models. Behaviormetrika. Madison, M.J., Wind, S., Maas, L., Yamaguchi, K. & Haab, S. (2023). one-parameter diagnostic classification model familiar measurement properties. Arxiv. Maas, L., Madison, M. J., & Brinkhuis, M. J. (2024). Properties performance one-parameter log-linear cognitive diagnosis model. Frontiers.","code":""},{"path":"/reference/oneplcdm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"One-parameter log-linear cognitive diagnosis model. — oneplcdm","text":"","code":"## Example 1: A = 4 data(data.tdcm05) dat5 <- data.tdcm05$data qmat5 <- data.tdcm05$qmatrix  # calibrate LCDM m1 <- CDM::gdina(dat5, qmat5, linkfct = \"logit\", method = \"ML\") #> ----------------------------------------------------------------- #> CDM 8.2-6 (2022-08-25 15:43:23)  #> GDINA Model  #>  Link function: logit  #>   ** 2024-02-01 00:10:16.312824  #> ----------------------------------------------------------------- #> ........................................................... #> Iteration 1     2024-02-01 00:10:16.332884  #> Deviance = 19770.5 #> Maximum parameter change: 0.084303  #> ........................................................... #> Iteration 2     2024-02-01 00:10:16.369944  #> Deviance = 17905.28 | Deviance change = 1865.213 #> Maximum parameter change: 0.05588  #> ........................................................... #> Iteration 3     2024-02-01 00:10:16.39574  #> Deviance = 17666.32 | Deviance change = 238.9634 #> Maximum parameter change: 0.074029  #> ........................................................... #> Iteration 4     2024-02-01 00:10:16.4315  #> Deviance = 17522.41 | Deviance change = 143.912 #> Maximum parameter change: 0.02881  #> ........................................................... #> Iteration 5     2024-02-01 00:10:16.450789  #> Deviance = 17509.64 | Deviance change = 12.76482 #> Maximum parameter change: 0.021972  #> ........................................................... #> Iteration 6     2024-02-01 00:10:16.47194  #> Deviance = 17503.68 | Deviance change = 5.9658 #> Maximum parameter change: 0.004612  #> ........................................................... #> Iteration 7     2024-02-01 00:10:16.491374  #> Deviance = 17500.71 | Deviance change = 2.966632 #> Maximum parameter change: 0.014631  #> ........................................................... #> Iteration 8     2024-02-01 00:10:16.517998  #> Deviance = 17491.82 | Deviance change = 8.893127 #> Maximum parameter change: 0.003278  #> ........................................................... #> Iteration 9     2024-02-01 00:10:16.537005  #> Deviance = 17494.42 | Deviance change = -2.603457 #> **** Deviances decreases! Check for nonconvergence.   **** #> Maximum parameter change: 0.021912  #> ........................................................... #> Iteration 10     2024-02-01 00:10:16.5671  #> Deviance = 17484.83 | Deviance change = 9.589414 #> Maximum parameter change: 0.003986  #> ........................................................... #> Iteration 11     2024-02-01 00:10:16.585073  #> Deviance = 17484.8 | Deviance change = 0.0370989 #> Maximum parameter change: 0.010959  #> ........................................................... #> Iteration 12     2024-02-01 00:10:16.606592  #> Deviance = 17482.69 | Deviance change = 2.110455 #> Maximum parameter change: 0.00172  #> ........................................................... #> Iteration 13     2024-02-01 00:10:16.622057  #> Deviance = 17482.63 | Deviance change = 0.0551816 #> Maximum parameter change: 0.003247  #> ........................................................... #> Iteration 14     2024-02-01 00:10:16.641716  #> Deviance = 17482.5 | Deviance change = 0.1285058 #> Maximum parameter change: 0.000442  #> ........................................................... #> Iteration 15     2024-02-01 00:10:16.657645  #> Deviance = 17482.5 | Deviance change = 0.0050662 #> Maximum parameter change: 0.000736  #> ........................................................... #> Iteration 16     2024-02-01 00:10:16.676692  #> Deviance = 17482.5 | Deviance change = -0.0019762 #> **** Deviances decreases! Check for nonconvergence.   **** #> Maximum parameter change: 0.00023  #> ........................................................... #> Iteration 17     2024-02-01 00:10:16.697834  #> Deviance = 17482.5 | Deviance change = -0.0017578 #> **** Deviances decreases! Check for nonconvergence.   **** #> Maximum parameter change: 0.000182  #> ........................................................... #> Iteration 18     2024-02-01 00:10:16.714552  #> Deviance = 17482.5 | Deviance change = -0.0020594 #> **** Deviances decreases! Check for nonconvergence.   **** #> Maximum parameter change: 0.000145  #> ........................................................... #> Iteration 19     2024-02-01 00:10:16.728146  #> Deviance = 17482.5 | Deviance change = -0.0020351 #> **** Deviances decreases! Check for nonconvergence.   **** #> Maximum parameter change: 0.000118  #> ........................................................... #> Iteration 20     2024-02-01 00:10:16.741508  #> Deviance = 17482.51 | Deviance change = -0.001883 #> **** Deviances decreases! Check for nonconvergence.   **** #> Maximum parameter change: 9.9e-05  #> ----------------------------------------------------------------- #> Time difference of 0.491065 secs  # calibrate 1-PLCDM m2 <- TDCM::oneplcdm(dat5, qmat5) #> [1] Estimating 1-PLCDM... #> [1] Estimation is complete. Use the CDM summary function to display results. summary(m2) #> ----------------------------------------------------------------- #> CDM 8.2-6 (2022-08-25 15:43:23)  #>  #> Call: #> CDM::gdina(data = data, q.matrix = qmatrix, linkfct = \"logit\",  #>     method = \"ML\", delta.designmatrix = delta.designmatrix, HOGDINA = 0,  #>     progress = FALSE) #>  #> Date of Analysis: 2024-02-01 00:10:19.122611  #> Time difference of 1.623365 secs #> Computation Time: 1.623365  #>  #> Higher Order Generalized DINA Model  #>  #> Number of iterations = 47 #> Iteration with minimal deviance = 4  #>  #> Estimation method: ML #> Optimizer: CDM #> Monotonicity constraints: FALSE #> Number of items at boundary monotonicity constraint: NA #>  #> Parameter regularization: FALSE #>  #> Deviance = 18247.97  | Log likelihood = -9123.99  #>  #> Number of persons = 750  #> Number of groups = 1  #> Number of items = 20  #> Number of estimated parameters = 28  #> Number of estimated item parameters = 24  #> Number of estimated skill class parameters = 4 ( 16 latent skill classes) #>  #> AIC = 18304  | penalty = 56    | AIC = -2*LL + 2*p   #> BIC = 18433  | penalty = 185.36    | BIC = -2*LL + log(n)*p    #> CAIC = 18461  | penalty = 213.36    | CAIC = -2*LL + [log(n)+1]*p  (consistent AIC)    #>  #> ----------------------------------------------------------------- #> Used Q-matrix  #>  #>        Att1 Att2 Att3 Att4 #> Item1     1    0    0    0 #> Item2     1    0    0    0 #> Item3     1    0    0    0 #> Item4     1    0    0    0 #> Item5     1    0    0    0 #> Item6     0    1    0    0 #> Item7     0    1    0    0 #> Item8     0    1    0    0 #> Item9     0    1    0    0 #> Item10    0    1    0    0 #> Item11    0    0    1    0 #> Item12    0    0    1    0 #> Item13    0    0    1    0 #> Item14    0    0    1    0 #> Item15    0    0    1    0 #> Item16    0    0    0    1 #> Item17    0    0    0    1 #> Item18    0    0    0    1 #> Item19    0    0    0    1 #> Item20    0    0    0    1 #>  #> ----------------------------------------------------------------- #>  #> Item Parameter Estimates  #>  #>     link   item itemno partype  rule     est     se partype.attr #> 1  logit  Item1      1       0 GDINA -1.5972 0.1281              #> 2  logit  Item1      1       1 GDINA  1.7928 0.1710         Att1 #> 3  logit  Item2      2       0 GDINA -1.8484 0.1398              #> 4  logit  Item2      2       1 GDINA  1.7928 0.1796         Att1 #> 5  logit  Item3      3       0 GDINA -1.2660 0.1157              #> 6  logit  Item3      3       1 GDINA  1.7928 0.1643         Att1 #> 7  logit  Item4      4       0 GDINA -1.4336 0.1216              #> 8  logit  Item4      4       1 GDINA  1.7928 0.1670         Att1 #> 9  logit  Item5      5       0 GDINA -1.5713 0.1270              #> 10 logit  Item5      5       1 GDINA  1.7928 0.1703         Att1 #> 11 logit  Item6      6       0 GDINA -1.4673 0.1418              #> 12 logit  Item6      6       1 GDINA  2.4114 0.1784         Att2 #> 13 logit  Item7      7       0 GDINA -1.5011 0.1434              #> 14 logit  Item7      7       1 GDINA  2.4114 0.1791         Att2 #> 15 logit  Item8      8       0 GDINA -0.9655 0.1238              #> 16 logit  Item8      8       1 GDINA  2.4114 0.1750         Att2 #> 17 logit  Item9      9       0 GDINA -1.0838 0.1274              #> 18 logit  Item9      9       1 GDINA  2.4114 0.1746         Att2 #> 19 logit Item10     10       0 GDINA -1.2169 0.1318              #> 20 logit Item10     10       1 GDINA  2.4114 0.1750         Att2 #> 21 logit Item11     11       0 GDINA -1.2240 0.1131              #> 22 logit Item11     11       1 GDINA  2.9666 0.1967         Att3 #> 23 logit Item12     12       0 GDINA -1.6220 0.1277              #> 24 logit Item12     12       1 GDINA  2.9666 0.1906         Att3 #> 25 logit Item13     13       0 GDINA -1.4200 0.1197              #> 26 logit Item13     13       1 GDINA  2.9666 0.1924         Att3 #> 27 logit Item14     14       0 GDINA -1.1768 0.1117              #> 28 logit Item14     14       1 GDINA  2.9666 0.1981         Att3 #> 29 logit Item15     15       0 GDINA -1.4495 0.1208              #> 30 logit Item15     15       1 GDINA  2.9666 0.1919         Att3 #> 31 logit Item16     16       0 GDINA -1.2130 0.1774              #> 32 logit Item16     16       1 GDINA  2.7803 0.2092         Att4 #> 33 logit Item17     17       0 GDINA -1.6921 0.2057              #> 34 logit Item17     17       1 GDINA  2.7803 0.2272         Att4 #> 35 logit Item18     18       0 GDINA -1.3103 0.1823              #> 36 logit Item18     18       1 GDINA  2.7803 0.2116         Att4 #> 37 logit Item19     19       0 GDINA -1.5943 0.1990              #> 38 logit Item19     19       1 GDINA  2.7803 0.2223         Att4 #> 39 logit Item20     20       0 GDINA -1.3030 0.1819              #> 40 logit Item20     20       1 GDINA  2.7803 0.2114         Att4 #>  #> Note: Standard errors are not (yet) correctly implemented! #>  #> RMSD (RMSEA) Item Fit Statistics #>  Item1  Item2  Item3  Item4  Item5  Item6  Item7  Item8  Item9 Item10  #>  0.161  0.144  0.184  0.160  0.192  0.196  0.121  0.143  0.137  0.160  #> Item11 Item12 Item13 Item14 Item15 Item16 Item17 Item18 Item19 Item20  #>  0.078  0.077  0.070  0.065  0.069  0.254  0.173  0.147  0.112  0.125  #>  #> Mean of RMSEA item fit: 0.138  #> ----------------------------------------------------------------- #> Model Implied Conditional Item Probabilities  #>  #>      item  rule nessskill itemno skillcomb   prob #> 1   Item1 GDINA      Att1      1        A0 0.1684 #> 2   Item1 GDINA      Att1      1        A1 0.5487 #> 3   Item2 GDINA      Att1      2        A0 0.1361 #> 4   Item2 GDINA      Att1      2        A1 0.4861 #> 5   Item3 GDINA      Att1      3        A0 0.2200 #> 6   Item3 GDINA      Att1      3        A1 0.6287 #> 7   Item4 GDINA      Att1      4        A0 0.1925 #> 8   Item4 GDINA      Att1      4        A1 0.5888 #> 9   Item5 GDINA      Att1      5        A0 0.1720 #> 10  Item5 GDINA      Att1      5        A1 0.5551 #> 11  Item6 GDINA      Att2      6        A0 0.1874 #> 12  Item6 GDINA      Att2      6        A1 0.7199 #> 13  Item7 GDINA      Att2      7        A0 0.1823 #> 14  Item7 GDINA      Att2      7        A1 0.7131 #> 15  Item8 GDINA      Att2      8        A0 0.2758 #> 16  Item8 GDINA      Att2      8        A1 0.8094 #> 17  Item9 GDINA      Att2      9        A0 0.2528 #> 18  Item9 GDINA      Att2      9        A1 0.7904 #> 19 Item10 GDINA      Att2     10        A0 0.2285 #> 20 Item10 GDINA      Att2     10        A1 0.7675 #> 21 Item11 GDINA      Att3     11        A0 0.2272 #> 22 Item11 GDINA      Att3     11        A1 0.8510 #> 23 Item12 GDINA      Att3     12        A0 0.1649 #> 24 Item12 GDINA      Att3     12        A1 0.7932 #> 25 Item13 GDINA      Att3     13        A0 0.1947 #> 26 Item13 GDINA      Att3     13        A1 0.8244 #> 27 Item14 GDINA      Att3     14        A0 0.2356 #> 28 Item14 GDINA      Att3     14        A1 0.8569 #> 29 Item15 GDINA      Att3     15        A0 0.1901 #> 30 Item15 GDINA      Att3     15        A1 0.8201 #> 31 Item16 GDINA      Att4     16        A0 0.2292 #> 32 Item16 GDINA      Att4     16        A1 0.8274 #> 33 Item17 GDINA      Att4     17        A0 0.1555 #> 34 Item17 GDINA      Att4     17        A1 0.7480 #> 35 Item18 GDINA      Att4     18        A0 0.2124 #> 36 Item18 GDINA      Att4     18        A1 0.8131 #> 37 Item19 GDINA      Att4     19        A0 0.1688 #> 38 Item19 GDINA      Att4     19        A1 0.7660 #> 39 Item20 GDINA      Att4     20        A0 0.2137 #> 40 Item20 GDINA      Att4     20        A1 0.8142 #> ----------------------------------------------------------------- #>  #> Skill Probabilities  #>  #>      skill.prob0 skill.prob1 #> Att1      0.5803      0.4197 #> Att2      0.4352      0.5648 #> Att3      0.5938      0.4062 #> Att4      0.2399      0.7601 #> ----------------------------------------------------------------- #>  #> Polychoric Correlations  #>  #> Group 1 #>      Att1 Att2 Att3 Att4 #> Att1    1    0    0    0 #> Att2    0    1    0    0 #> Att3    0    0    1    0 #> Att4    0    0    0    1 #>  #>  ----------------------------------------------------------------- #>  #> Skill Pattern Probabilities  #>  #>   0000   1000   0100   1100   0010   1010   0110   1110   0001   1001  #> 0.0360 0.0260 0.0467 0.0338 0.0246 0.0178 0.0319 0.0231 0.1140 0.0824  #>   0101   1101   0011   1011   0111   1111  #> 0.1479 0.1070 0.0780 0.0564 0.1012 0.0732  #>  #>  ----------------------------------------------------------------- #> Higher Order GDINA Model  #>   Attribute Response Function Parameters  #>  #>       b.Gr1 a.Gr1 int.Gr1 #> Att1  0.744     0    -Inf #> Att2 -0.047     0     Inf #> Att3  0.190     0    -Inf #> Att4 -0.698     0     Inf #demonstrate 1-PLCDM sum score sufficiency for each attribute subscores <- cbind(rowSums(dat5[, 1:5]), rowSums(dat5[, 6:10]), rowSums(dat5[, 11:15]), rowSums(dat5[, 16:20])) colnames(subscores) <- c(\"Att1\", \"Att2\", \"Att3\", \"Att4\") proficiency <- cbind(m2$pattern[, 6] > .50, m2$pattern[, 7] > .50, m2$pattern[, 8] > .50, m2$pattern[, 9] > .5) * 1 table(subscores[, 1], proficiency[, 1]) #>     #>       0   1 #>   0 150   0 #>   1 250   0 #>   2   0 156 #>   3   0  95 #>   4   0  71 #>   5   0  28 table(subscores[, 2], proficiency[, 2]) #>     #>       0   1 #>   0  88   0 #>   1 149   0 #>   2 106   0 #>   3   0 138 #>   4   0 163 #>   5   0 106 table(subscores[, 3], proficiency[, 3]) #>     #>       0   1 #>   0 136   0 #>   1 209   0 #>   2  74   0 #>   3   0  86 #>   4   0 131 #>   5   0 114 table(subscores[, 4], proficiency[, 4]) #>     #>       0   1 #>   0  68   0 #>   1  76   0 #>   2   0  62 #>   3   0 127 #>   4   0 254 #>   5   0 163  #plot sum score sufficiency for each attribute posterior1pl <- m2$pattern[, 6:9] posteriorlcdm <- m1$pattern[, 6:9] par(mfrow = c(2, 2)) for (i in 1:4) {  plot(subscores[, i], posteriorlcdm[, i], pch = 19,las = 1, cex.lab = 1.5,  xlab = \"Sum Scores\", ylab = \"P(proficiency)\",  cex.main = 1.5, col = \"grey\", xaxt = \"n\", yaxt = \"n\", cex = 1.2,  main = paste(\"Attribute \", i, sep = \"\"))  graphics::axis(side = 1, at = c(0, 1, 2, 3, 4, 5), )  graphics::axis(side = 2, at = c(0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1.0), las = 1)  graphics::points(subscores[, i], posterior1pl[, i], col = \"black\", pch = 18, cex = 1.5)  graphics::abline(a = .50, b = 0, col = \"red\")  graphics::legend(\"bottomright\", c(\"1-PLCDM\", \"LCDM\"), col = c(\"black\", \"grey\"),  pch = c(18 ,19), box.lwd = 0, box.col = \"white\", bty = 'n') }"},{"path":"/reference/summary.option1.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility function in TDCM — summary.option1","title":"Utility function in TDCM — summary.option1","text":"Utility function TDCM","code":""},{"path":"/reference/summary.option1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility function in TDCM — summary.option1","text":"","code":"# S3 method for option1 summary(model, num.atts, time.points, attribute.names)"},{"path":"/reference/summary.option1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility function in TDCM — summary.option1","text":"model gdina object tdcm function num.atts number attributes time.points number time points attribute.names optional argument specify attribute names","code":""},{"path":"/reference/summary.option2.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility function in TDCM — summary.option2","title":"Utility function in TDCM — summary.option2","text":"Utility function TDCM","code":""},{"path":"/reference/summary.option2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility function in TDCM — summary.option2","text":"","code":"# S3 method for option2 summary(model, num.atts, time.points, attribute.names)"},{"path":"/reference/summary.option2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility function in TDCM — summary.option2","text":"model gdina object tdcm function num.atts number attributes time.points number time points attribute.names optional argument specify attribute names","code":""},{"path":"/reference/summary.option3.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility function in TDCM — summary.option3","title":"Utility function in TDCM — summary.option3","text":"Utility function TDCM","code":""},{"path":"/reference/summary.option3.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility function in TDCM — summary.option3","text":"","code":"# S3 method for option3 summary(model, num.atts, time.points, attribute.names)"},{"path":"/reference/summary.option3.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility function in TDCM — summary.option3","text":"model gdina object tdcm function num.atts number attributes time.points number time points attribute.names optional argument specify attribute names","code":""},{"path":"/reference/summary.param.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility function in TDCM — summary.param","title":"Utility function in TDCM — summary.param","text":"Utility function TDCM","code":""},{"path":"/reference/summary.param.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility function in TDCM — summary.param","text":"","code":"# S3 method for param summary(model, num.atts, numitems, time.points)"},{"path":"/reference/summary.param.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility function in TDCM — summary.param","text":"model model tdcm estimation num.atts number attributes numitems number items time point time.points number time points","code":""},{"path":"/reference/tdcm-package.html","id":null,"dir":"Reference","previous_headings":"","what":"The Transition Diagnostic Classification Model Framework — TDCM-package","title":"The Transition Diagnostic Classification Model Framework — TDCM-package","text":"conducting longitudinal DCM analysis within TDCM framework.","code":""},{"path":"/reference/tdcm-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The Transition Diagnostic Classification Model Framework — TDCM-package","text":"Diagnostic classification models (DCMs) psychometric models designed classify examinees according proficiency set categorical latent traits, known attributes. Longitudinal DCMs developed psychometric options modeling changes attribute proficiency time. TDCM package implements estimation transition DCM (TDCM; Madison & Bradshaw, 2018a), longitudinal extension log-linear cognitive diagnosis model (LCDM; Henson, Templin, & Willse, 2009). LCDM subsumes many DCMs, many DCMs can estimated longitudinally via TDCM. package includes functions estimate single-group multigroup TDCM, summarize results interest including item parameters, growth proportions, transition probabilities, transitional reliability, attribute correlations, model fit, growth plots.","code":""},{"path":"/reference/tdcm-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"The Transition Diagnostic Classification Model Framework — TDCM-package","text":"de la Torre, J. (2011). generalized DINA model framework. Psychometrika, 76, 179-199. George, . C., Robitzsch, ., Kiefer, T., Gross, J., & Ünlü , . (2016). R package CDM cognitive diagnosis models. Journal Statistical Software, 74(2), 1-24. Henson, R., Templin, J., & Willse, J. (2009). Defining family cognitive diagnosis models using log linear models latent variables. Psychometrika, 74, 191-21. Johnson, M. S., & Sinharay, S. (2020). reliability posterior probability skill attainment diagnostic classification models. Journal Educational Measurement, 47(1), 5 – 31. Kaya, Y., & Leite, W. (2017). Assessing change latent skills across time longitudinal cognitive diagnosis modeling: evaluation model performance. Educational Psychological Measurement, 77(3), 369–388. Li, F., Cohen, ., Bottge, B., & Templin, J. (2015). latent transition analysis model assessing change cognitive skills. Educational Psychological Measurement, 76(2), 181–204. Madison, M. J. (2019). Reliably assessing growth longitudinal diagnostic classification models. Educational Measurement: Issues Practice, 38(2), 68-78. Madison, M. J., & Bradshaw, L. (2018a). Assessing growth diagnostic classification model framework. Psychometrika, 82(4), 963-990. Madison, M. J., & Bradshaw, L. (2018b). Evaluating intervention effects diagnostic classification model framework. Journal Educational Measurement, 55(1), 32-51. Madison, M.J., Chung, S., Kim, J. et al. Approaches estimating longitudinal diagnostic classification models. Behaviormetrika (2023). Rupp, . ., Templin, J., & Henson, R. (2010). Diagnostic measurement: Theory, methods, applications. New York: Guilford. Schellman, M., & Madison, M. J. (2021, July). Estimating reliability skill transition longitudinal DCMs. Paper presented 2021 International Meeting Psychometric Society. Templin, J., & Bradshaw, L. (2013). Measuring reliability diagnostic classification model examinee estimates. Journal Classification, 30, 251-275. Wang. S., Yang. Y., Culpepper, S. ., & Douglas, J. (2018). Tracking Skill Acquisition cognitive diagnosis models: higher-order, hidden Markov model covariates. Journal  Educational Behavioral Statistics, 43(1), 57-87.","code":""},{"path":[]},{"path":"/reference/tdcm-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"The Transition Diagnostic Classification Model Framework — TDCM-package","text":"Matthew J. Madison, University Georgia, mjmadison@uga.edu Sergio Haab, University Iowa Minjeong Jeon, University California - Los Angeles Michael E. Cotterell, University Georgia","code":""},{"path":"/reference/tdcm.base.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility function for base estimation in TDCMs. — tdcm.base","title":"Utility function for base estimation in TDCMs. — tdcm.base","text":"Utility function base estimation TDCMs.","code":""},{"path":"/reference/tdcm.base.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility function for base estimation in TDCMs. — tdcm.base","text":"","code":"tdcm.base(data, qnew, dcmrule)"},{"path":"/reference/tdcm.base.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility function for base estimation in TDCMs. — tdcm.base","text":"data item response data qnew stacked Q-matrix dcmrule specific DCM estimate","code":""},{"path":"/reference/tdcm.compare.html","id":null,"dir":"Reference","previous_headings":"","what":"Comparing the fit of two TDCMs — tdcm.compare","title":"Comparing the fit of two TDCMs — tdcm.compare","text":"Provides comparison two TDCMs. Can used compare different measurement models assess measurement invariance time groups multigroup TDCM case. accepts two models.","code":""},{"path":"/reference/tdcm.compare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Comparing the fit of two TDCMs — tdcm.compare","text":"","code":"tdcm.compare(model1, model2)"},{"path":"/reference/tdcm.compare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Comparing the fit of two TDCMs — tdcm.compare","text":"model1 gdina object returned tdcm mg.tdcm function. model2 second gdina object returned tdcm mg.tdcm function","code":""},{"path":"/reference/tdcm.compare.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Comparing the fit of two TDCMs — tdcm.compare","text":"function returns data frame model fit statistics (AIC/BIC) results likelihood ratio deviance test.","code":""},{"path":"/reference/tdcm.compare.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Comparing the fit of two TDCMs — tdcm.compare","text":"Currently, function currently accepts two models comparison. models must fit item responses Q-matrix. function provide results two non-nested models. Please ensure models nested interpreting likelihood ratio test nested models. likelihood ratio test valid model comparisons (e.g., LCDM vs DINA) model constraints.","code":""},{"path":"/reference/tdcm.compare.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Comparing the fit of two TDCMs — tdcm.compare","text":"","code":"## Example 1: T = 2, A = 4 data(data.tdcm01, package = \"TDCM\") dat1 <- data.tdcm01$data qmat1 <- data.tdcm01$qmatrix  # estimate TDCM with invariance assumed and full LCDM m1 <- TDCM::tdcm(dat1, qmat1, time.points = 2, invariance = TRUE, dcmrule = \"GDINA\")  # estimate TDCM with invariance not assumed m2 <- TDCM::tdcm(dat1, qmat1, time.points = 2, invariance = FALSE, dcmrule = \"GDINA\")  # compare models to assess measurement invariance. TDCM::tdcm.compare(m1, m2) #>   Model   loglike Deviance Npars      AIC      BIC Chisq df      p #> 1    m1 -21429.51 42859.02    93 43045.02 43501.44 58.14 56 0.3965 #> 2    m2 -21400.44 42800.88   149 43098.88 43830.14    NA NA     NA"},{"path":"/reference/tdcm.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimating the transition diagnostic classification model (TDCM) — tdcm","title":"Estimating the transition diagnostic classification model (TDCM) — tdcm","text":"Function calibrate transition diagnostic classification model (TDCM; Madison & Bradshaw, 2018a), longitudinal extension log-linear cognitive diagnosis model (LCDM; Henson, Templin, & Willse, 2009). Allows specification many specific DCMs via dcmrule option. multigroup TDCM, see mg.tdcm.","code":""},{"path":"/reference/tdcm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimating the transition diagnostic classification model (TDCM) — tdcm","text":"","code":"tdcm(   data,   qmatrix,   time.points,   invariance = TRUE,   dcmrule = \"GDINA\",   number.q = 1,   num.items = c(),   anchor = c(),   progress = FALSE )"},{"path":"/reference/tdcm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimating the transition diagnostic classification model (TDCM) — tdcm","text":"data required \\(N \\times T \\times \\) matrix. time point, binary item responses columns. qmatrix required \\(\\times \\) matrix indicating items measure attributes. multiple Q-matrices, must number attributes must stacked top estimation (specify multiple Q-matrices, see number.q, num.items, anchor). time.points number time points (.e., measurement/testing occasions), integer \\(\\ge 2\\). invariance boolean indicating whether item parameter invariance constrained equal time point. Default = T. specified false, item parameters assumed equal time. dcmrule specific DCM employed. Currently accepts “GDINA”, “ACDM”, “DINA”, \"DINO\", \"RRUM\", “GDINA1”, “GDINA2”, . Default “GDINA”, implemented logit link estimate LCDM. “ACDM” rule estimate LCDM main effects. “DINA” rule estimate DINA model (Haertel, 1989; Junker & Sijtsma, 2001). “GDINA1” estimate LCDM main effects, equivalent “ACDM”. “GDINA2” estimate LCDM two-way interaction effects. dcmrule entered single string, DCM assumed item. entered vector, DCM can specified item. Note 1: dcmrule = \"DINO\" display LCDM main effects, negated interaction term. Note 2: dcmrule = \"RRUM\" display item parameters RRUM parametrization, statistically equivalent ACDM form. number.q number Q-matrices. many applications, assessment administered time point number 1 (default  = 1). different Q-matrices time point, argument must specified equal number time points. example, three time points, Q-matrix time point different, number.q = 3. three time points, Q-matrix different time point 3, number.q still specified 3. num.items multiple Q-matrices, number items Q-matrix specified T-length vector. example, three time points, Q-matrices time point 8, 10, 12 items, respectively, num.items = c(8, 10, 12). Default empty vector indicate one Q-matrix. anchor different tests time point, optional anchor argument vector pairs item numbers indicating items across time points held invariant. example, three Q-matrices 10 items , Items 1, 11, 21 , Items 14 24 , anchor = c(1,11,1,21,14,24). Default empty vector indicate one Q-matrix. progress optional logical indicating whether function print progress estimation.","code":""},{"path":"/reference/tdcm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimating the transition diagnostic classification model (TDCM) — tdcm","text":"object class gdina entries indicated CDM package. TDCM-specific results (e.g., growth, transitions), results summarized using tdcm.summary function.","code":""},{"path":"/reference/tdcm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimating the transition diagnostic classification model (TDCM) — tdcm","text":"Estimation TDCM via CDM package (George, et al., 2016), based EM algorithm described de la Torre (2011). estimation approach detailed Madison et al. (2023).","code":""},{"path":"/reference/tdcm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimating the transition diagnostic classification model (TDCM) — tdcm","text":"de la Torre, J. (2011). generalized DINA model framework. Psychometrika, 76, 179-199. George, . C., Robitzsch, ., Kiefer, T., Gross, J., & Ünlü , . (2016). R package CDM cognitive diagnosis models. Journal Statistical Software, 74(2), 1-24. Henson, R., Templin, J., & Willse, J. (2009). Defining family cognitive diagnosis models using log linear models latent variables. Psychometrika, 74, 191-21. Madison, M. J., & Bradshaw, L. (2018a). Assessing growth diagnostic classification model framework. Psychometrika, 82(4), 963-990. Madison, M. J., & Bradshaw, L. (2018b). Evaluating intervention effects diagnostic classification model framework. Journal Educational Measurement, 55(1), 32-51. Madison, M.J., Chung, S., Kim, J., & Bradshaw, L. (2023). Approaches estimating longitudinal diagnostic classification models. Behaviormetrika. Rupp, . ., Templin, J., & Henson, R. (2010). Diagnostic measurement: Theory, methods, applications. New York: Guilford.","code":""},{"path":"/reference/tdcm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimating the transition diagnostic classification model (TDCM) — tdcm","text":"","code":"## Example 1: T = 2, A = 4 data(data.tdcm01, package = \"TDCM\") dat1 <- data.tdcm01$data qmat1 <- data.tdcm01$qmatrix  # estimate TDCM with invariance assumed and full LCDM m1 <- TDCM::tdcm(dat1, qmat1, time.points = 2, invariance = TRUE, dcmrule = \"GDINA\")  # summarize results with tdcm.summary function results <- TDCM::tdcm.summary(m1, time.points = 2) results$item.parameters #>         λ0     λ1,1  λ1,2  λ1,3  λ1,4  λ2,12 λ2,13 λ2,14 λ2,23 λ2,24 #> Item 1  -1.923 2.616   --    --    --    --    --    --    --    --  #> Item 2  -2.071 2.506   --    --    --    --    --    --    --    --  #> Item 3  -1.936 2.506   --    --    --    --    --    --    --    --  #> Item 4  -1.891 1.051 1.471   --    --  1.115   --    --    --    --  #> Item 5  -2.157 1.705   --  1.732   --    --  0.835   --    --    --  #> Item 6  -1.841   --  2.175   --    --    --    --    --    --    --  #> Item 7  -1.841   --  2.272   --    --    --    --    --    --    --  #> Item 8  -1.965   --  2.475   --    --    --    --    --    --    --  #> Item 9  -2.029   --  1.242 1.531   --    --    --    --  1.628   --  #> Item 10 -2.004   --  1.921   --  1.239   --    --    --    --  0.999 #> Item 11 -1.851   --    --  2.349   --    --    --    --    --    --  #> Item 12 -2.045   --    --  2.566   --    --    --    --    --    --  #> Item 13 -2.083   --    --  2.576   --    --    --    --    --    --  #> Item 14 -2.125   --    --  1.739 2.104   --    --    --    --    --  #> Item 15 -1.805 0.777   --  1.31    --    --  1.896   --    --    --  #> Item 16 -2.156   --    --    --  2.736   --    --    --    --    --  #> Item 17 -2.089   --    --    --  2.679   --    --    --    --    --  #> Item 18 -2.087   --    --    --  2.476   --    --    --    --    --  #> Item 19 -2.11  2.219   --    --  1.46    --    --  0.558   --    --  #> Item 20 -2.047   --  2.408   --  1.49    --    --    --    --  0.154 #>         λ2,34 #> Item 1    --  #> Item 2    --  #> Item 3    --  #> Item 4    --  #> Item 5    --  #> Item 6    --  #> Item 7    --  #> Item 8    --  #> Item 9    --  #> Item 10   --  #> Item 11   --  #> Item 12   --  #> Item 13   --  #> Item 14 0.493 #> Item 15   --  #> Item 16   --  #> Item 17   --  #> Item 18   --  #> Item 19   --  #> Item 20   --  results$growth #>             T1[1] T2[1] #> Attribute 1 0.201 0.372 #> Attribute 2 0.327 0.492 #> Attribute 3 0.397 0.573 #> Attribute 4 0.252 0.696 results$transition.probabilities #> , , Attribute 1: Time 1 to Time 2 #>  #>        T2 [0] T2 [1] #> T1 [0]  0.678  0.322 #> T1 [1]  0.432  0.568 #>  #> , , Attribute 2: Time 1 to Time 2 #>  #>        T2 [0] T2 [1] #> T1 [0]  0.578  0.422 #> T1 [1]  0.363  0.637 #>  #> , , Attribute 3: Time 1 to Time 2 #>  #>        T2 [0] T2 [1] #> T1 [0]   0.55   0.45 #> T1 [1]   0.24   0.76 #>  #> , , Attribute 4: Time 1 to Time 2 #>  #>        T2 [0] T2 [1] #> T1 [0]  0.365  0.635 #> T1 [1]  0.123  0.877 #>   # estimate TDCM with invariance assumed and only main effects m2 <- TDCM::tdcm(dat1, qmat1, time.points = 2, invariance = TRUE, dcmrule = \"GDINA1\")  # estimate TDCM with invariance not assumed m3 <- TDCM::tdcm(dat1, qmat1, time.points = 2, invariance = FALSE, dcmrule = \"GDINA\")  # compare models to assess measurement invariance. TDCM::tdcm.compare(m1, m3) #>   Model   loglike Deviance Npars      AIC      BIC Chisq df      p #> 1    m1 -21429.51 42859.02    93 43045.02 43501.44 58.14 56 0.3965 #> 2    m3 -21400.44 42800.88   149 43098.88 43830.14    NA NA     NA  ## Example 2: T = 3, A = 2 data(data.tdcm02, package = \"TDCM\") dat2 <- data.tdcm02$data qmat2 <- data.tdcm02$qmatrix  # estimate TDCM with invariance assumed and full LCDM m1 <- TDCM::tdcm(dat2, qmat2, time.points = 3)  # estimate TDCM with invariance not assumed m2 <- TDCM::tdcm(dat2, qmat2, time.points = 3, invariance = FALSE)  # compare models to assess measurement invariance TDCM::tdcm.compare(m1, m2) #>   Model   loglike Deviance Npars      AIC      BIC Chisq df      p #> 1    m1 -46110.97 92221.95    50 92321.95 92613.15  73.8 56 0.0556 #> 2    m2 -46074.07 92148.13   106 92360.13 92977.48    NA NA     NA  ## Example 3: T = 3, A = 2, Q = 3 (multiple Q-matrices) data(data.tdcm03, package = \"TDCM\") dat3 <- data.tdcm03$data qmat3 <- data.tdcm03$qmatrix123  # estimate TDCM with full LCDM and three Q-matrices with 10 items each m1 <- TDCM::tdcm(dat3, qmat3, time.points = 3, number.q = 3, num.items = c(10, 10, 10))  # estimate TDCM with full LCDM and three Q-matrices with 10 items each and anchor items m2 <- TDCM::tdcm(dat3, qmat3, time.points = 3, number.q = 3, num.items = c(10, 10, 10), anchor = c(1, 11, 1, 21, 14, 24))  # compare models to assess measurement invariance of anchor items TDCM::tdcm.compare(m1, m2) #>   Model   loglike Deviance Npars      AIC      BIC Chisq df     p #> 1    m1 -27895.61 55791.23   106 56003.23 56566.43 10.16  8 0.254 #> 2    m2 -27900.69 55801.39    98 55997.39 56518.08    NA NA    NA"},{"path":"/reference/tdcm.mq.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility function to estimate TDCM with multiple Q-matrices. — tdcm.mq","title":"Utility function to estimate TDCM with multiple Q-matrices. — tdcm.mq","text":"Utility function estimate TDCM multiple Q-matrices.","code":""},{"path":"/reference/tdcm.mq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility function to estimate TDCM with multiple Q-matrices. — tdcm.mq","text":"","code":"tdcm.mq(   data,   qmatrix,   time.points,   invariance = TRUE,   dcmrule = \"GDINA\",   number.q = 1,   num.items = c(),   anchor = c() )"},{"path":"/reference/tdcm.mq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility function to estimate TDCM with multiple Q-matrices. — tdcm.mq","text":"data item response data qmatrix specified qumatrices time.points number time points invariance invariance assumption (T F) dcmrule specific DCM estimate number.q number Q-matrices num.items number items Q-matrix anchor anchor items specified pairs vector","code":""},{"path":"/reference/tdcm.plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plotting TDCM Results — tdcm.plot","title":"Plotting TDCM Results — tdcm.plot","text":"Function visualizing results TDCM analyses.","code":""},{"path":"/reference/tdcm.plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plotting TDCM Results — tdcm.plot","text":"","code":"tdcm.plot(results, attribute.names = c(), group.names = c())"},{"path":"/reference/tdcm.plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plotting TDCM Results — tdcm.plot","text":"results results tdcm.summary mg.tdcm.summary attribute.names optional vector attribute names include plots. group.names optional vector group names include plots.","code":""},{"path":"/reference/tdcm.plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plotting TDCM Results — tdcm.plot","text":"","code":"## Example 1: T = 2, A = 4 data(data.tdcm01, package = \"TDCM\") dat1 = data.tdcm01$data qmat1 = data.tdcm01$qmatrix  #estimate TDCM with invariance assumed and full LCDM m1 = TDCM::tdcm(dat1, qmat1, time.points = 2, invariance = TRUE, dcmrule = \"GDINA\")  #summarize results with tdcm.summary function results1 = TDCM::tdcm.summary(m1, time.points = 2)  #plot results TDCM::tdcm.plot(results1, attribute.names = c(\"Addition\", \"Subtraction\", \"Multiplication\", \"Division\"))   #> [1] **Check plots window for line and bar plots for growth proportions."},{"path":"/reference/tdcm.plot.mg.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility function in TDCM — tdcm.plot.mg","title":"Utility function in TDCM — tdcm.plot.mg","text":"Utility function TDCM","code":""},{"path":"/reference/tdcm.plot.mg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility function in TDCM — tdcm.plot.mg","text":"","code":"tdcm.plot.mg(results, attribute.names = c(), group.names = c())"},{"path":"/reference/tdcm.plot.mg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility function in TDCM — tdcm.plot.mg","text":"results results mg.tdcm.summary attribute.names optional vector attribute names include plots. group.names optional vector group names include plots.","code":""},{"path":"/reference/tdcm.rel.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility function to compute transition reliability. — tdcm.rel","title":"Utility function to compute transition reliability. — tdcm.rel","text":"Utility function compute transition reliability.","code":""},{"path":"/reference/tdcm.rel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility function to compute transition reliability. — tdcm.rel","text":"","code":"tdcm.rel(model, numatts, time.points, transition.option, attribute.names = c())"},{"path":"/reference/tdcm.rel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility function to compute transition reliability. — tdcm.rel","text":"model gdina object tdcm estimation numatts number attributes time.points number time points transition.option transition.option specified summary function attribute.names optional attribute names","code":""},{"path":"/reference/tdcm.rel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utility function to compute transition reliability. — tdcm.rel","text":"Several reliability metrics","code":""},{"path":"/reference/tdcm.rel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Utility function to compute transition reliability. — tdcm.rel","text":"Includes longitudinal DCM reliability metrics developed Schellman Madison (2021).","code":""},{"path":"/reference/tdcm.rel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Utility function to compute transition reliability. — tdcm.rel","text":"Schellman, M., & Madison, M. J. (2021, July). Estimating reliability skill transition longitudinal DCMs. Paper presented 2021 International Meeting Psychometric Society.","code":""},{"path":"/reference/tdcm.score.html","id":null,"dir":"Reference","previous_headings":"","what":"DCM scoring function. — tdcm.score","title":"DCM scoring function. — tdcm.score","text":"Function score responses fixed item parameters previously calibrated LCDM.","code":""},{"path":"/reference/tdcm.score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DCM scoring function. — tdcm.score","text":"","code":"tdcm.score(   calibration.model,   newdata,   qmatrix,   attr.prob.fixed = NULL,   progress = TRUE )"},{"path":"/reference/tdcm.score.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"DCM scoring function. — tdcm.score","text":"calibration.model previously calibrated model; object class gdina. newdata required \\(N \\times \\) matrix. Binary item responses columns. qmatrix required \\(\\times \\) matrix indicating items measure attributes. attr.prob.fixed optional argument attribute profile proportions. Default uniform distribution profiles. progress optional logical indicating whether function print progress estimation.","code":""},{"path":"/reference/tdcm.score.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"DCM scoring function. — tdcm.score","text":"object class gdina entries indicated CDM package.","code":""},{"path":"/reference/tdcm.score.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"DCM scoring function. — tdcm.score","text":"Obtain classifications new responses items previously calibrated. calibrate--score approach detailed Madison et al. (2023).","code":""},{"path":"/reference/tdcm.score.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"DCM scoring function. — tdcm.score","text":"George, . C., Robitzsch, ., Kiefer, T., Gross, J., & Ünlü , . (2016). R package CDM cognitive diagnosis models. Journal Statistical Software, 74(2), 1-24. Henson, R., Templin, J., & Willse, J. (2009). Defining family cognitive diagnosis models using log linear models latent variables. Psychometrika, 74, 191-21. Madison, M.J., Chung, S., Kim, J., & Bradshaw, L. (2023). Approaches estimating longitudinal diagnostic classification models. Behaviormetrika.","code":""},{"path":"/reference/tdcm.score.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"DCM scoring function. — tdcm.score","text":"","code":"## Example 1: T = 2, A = 4 data(data.tdcm01, package = \"TDCM\") dat1 <- data.tdcm01$data qmat1 <- data.tdcm01$qmatrix pre <- dat1[, 1:20] post <- dat1[, 21:40]  # calibrate LCDM with post-test data m1 <- CDM::gdina(data = post, q.matrix = qmat1, linkfct = \"logit\", method = \"ML\") #> ----------------------------------------------------------------- #> CDM 8.2-6 (2022-08-25 15:43:23)  #> GDINA Model  #>  Link function: logit  #>   ** 2024-02-01 00:11:03.309093  #> ----------------------------------------------------------------- #> ........................................................... #> Iteration 1     2024-02-01 00:11:03.328689  #> Deviance = 23644.81 #> Maximum parameter change: 0.140968  #> ........................................................... #> Iteration 2     2024-02-01 00:11:03.379382  #> Deviance = 22969.9 | Deviance change = 674.9129 #> Maximum parameter change: 0.062143  #> ........................................................... #> Iteration 3     2024-02-01 00:11:03.406802  #> Deviance = 22884.6 | Deviance change = 85.29917 #> Maximum parameter change: 0.210699  #> ........................................................... #> Iteration 4     2024-02-01 00:11:03.442021  #> Deviance = 22826.78 | Deviance change = 57.81809 #> Maximum parameter change: 0.066469  #> ........................................................... #> Iteration 5     2024-02-01 00:11:03.465776  #> Deviance = 22819.87 | Deviance change = 6.913551 #> Maximum parameter change: 0.135432  #> ........................................................... #> Iteration 6     2024-02-01 00:11:03.494275  #> Deviance = 22814.36 | Deviance change = 5.510097 #> Maximum parameter change: 0.024009  #> ........................................................... #> Iteration 7     2024-02-01 00:11:03.520929  #> Deviance = 22813.63 | Deviance change = 0.7295209 #> Maximum parameter change: 0.06209  #> ........................................................... #> Iteration 8     2024-02-01 00:11:03.54833  #> Deviance = 22813.24 | Deviance change = 0.3872104 #> Maximum parameter change: 0.013044  #> ........................................................... #> Iteration 9     2024-02-01 00:11:03.567765  #> Deviance = 22813.04 | Deviance change = 0.1989579 #> Maximum parameter change: 0.058037  #> ........................................................... #> Iteration 10     2024-02-01 00:11:03.609051  #> Deviance = 22812.9 | Deviance change = 0.1402681 #> Maximum parameter change: 0.014272  #> ........................................................... #> Iteration 11     2024-02-01 00:11:03.627869  #> Deviance = 22812.82 | Deviance change = 0.0847859 #> Maximum parameter change: 0.01271  #> ........................................................... #> Iteration 12     2024-02-01 00:11:03.650511  #> Deviance = 22812.78 | Deviance change = 0.0379766 #> Maximum parameter change: 0.005112  #> ........................................................... #> Iteration 13     2024-02-01 00:11:03.675503  #> Deviance = 22812.76 | Deviance change = 0.013586 #> Maximum parameter change: 0.014065  #> ........................................................... #> Iteration 14     2024-02-01 00:11:03.70249  #> Deviance = 22812.74 | Deviance change = 0.0194937 #> Maximum parameter change: 0.002715  #> ........................................................... #> Iteration 15     2024-02-01 00:11:03.720494  #> Deviance = 22812.74 | Deviance change = 0.0023854 #> Maximum parameter change: 0.002621  #> ........................................................... #> Iteration 16     2024-02-01 00:11:03.74225  #> Deviance = 22812.74 | Deviance change = 0.0011401 #> Maximum parameter change: 0.00174  #> ........................................................... #> Iteration 17     2024-02-01 00:11:03.760018  #> Deviance = 22812.74 | Deviance change = 0.0009162 #> Maximum parameter change: 0.003531  #> ........................................................... #> Iteration 18     2024-02-01 00:11:03.785514  #> Deviance = 22812.74 | Deviance change = 0.0009083 #> Maximum parameter change: 0.00087  #> ........................................................... #> Iteration 19     2024-02-01 00:11:03.806981  #> Deviance = 22812.74 | Deviance change = 0.0001264 #> Maximum parameter change: 0.000805  #> ........................................................... #> Iteration 20     2024-02-01 00:11:03.821516  #> Deviance = 22812.74 | Deviance change = 0.0001038 #> Maximum parameter change: 0.000744  #> ........................................................... #> Iteration 21     2024-02-01 00:11:03.834951  #> Deviance = 22812.74 | Deviance change = 8.88e-05 #> Maximum parameter change: 0.000685  #> ........................................................... #> Iteration 22     2024-02-01 00:11:03.848394  #> Deviance = 22812.74 | Deviance change = 7.72e-05 #> Maximum parameter change: 0.00063  #> ........................................................... #> Iteration 23     2024-02-01 00:11:03.861404  #> Deviance = 22812.74 | Deviance change = 6.78e-05 #> Maximum parameter change: 0.000578  #> ........................................................... #> Iteration 24     2024-02-01 00:11:03.874613  #> Deviance = 22812.74 | Deviance change = 6e-05 #> Maximum parameter change: 0.00053  #> ........................................................... #> Iteration 25     2024-02-01 00:11:03.88779  #> Deviance = 22812.74 | Deviance change = 5.34e-05 #> Maximum parameter change: 0.000486  #> ........................................................... #> Iteration 26     2024-02-01 00:11:03.901092  #> Deviance = 22812.74 | Deviance change = 4.78e-05 #> Maximum parameter change: 0.000445  #> ........................................................... #> Iteration 27     2024-02-01 00:11:03.913928  #> Deviance = 22812.74 | Deviance change = 4.29e-05 #> Maximum parameter change: 0.000407  #> ........................................................... #> Iteration 28     2024-02-01 00:11:03.926712  #> Deviance = 22812.74 | Deviance change = 3.87e-05 #> Maximum parameter change: 0.000372  #> ........................................................... #> Iteration 29     2024-02-01 00:11:03.945995  #> Deviance = 22812.74 | Deviance change = 3.5e-05 #> Maximum parameter change: 0.000341  #> ........................................................... #> Iteration 30     2024-02-01 00:11:03.958679  #> Deviance = 22812.74 | Deviance change = 3.17e-05 #> Maximum parameter change: 0.000311  #> ........................................................... #> Iteration 31     2024-02-01 00:11:03.97117  #> Deviance = 22812.74 | Deviance change = 2.88e-05 #> Maximum parameter change: 0.000285  #> ........................................................... #> Iteration 32     2024-02-01 00:11:03.983747  #> Deviance = 22812.74 | Deviance change = 2.63e-05 #> Maximum parameter change: 0.00026  #> ........................................................... #> Iteration 33     2024-02-01 00:11:03.996292  #> Deviance = 22812.74 | Deviance change = 2.4e-05 #> Maximum parameter change: 0.000237  #> ........................................................... #> Iteration 34     2024-02-01 00:11:04.00891  #> Deviance = 22812.74 | Deviance change = 2.19e-05 #> Maximum parameter change: 0.000217  #> ........................................................... #> Iteration 35     2024-02-01 00:11:04.021121  #> Deviance = 22812.74 | Deviance change = 2.01e-05 #> Maximum parameter change: 0.000198  #> ........................................................... #> Iteration 36     2024-02-01 00:11:04.033436  #> Deviance = 22812.74 | Deviance change = 1.84e-05 #> Maximum parameter change: 0.000181  #> ........................................................... #> Iteration 37     2024-02-01 00:11:04.04582  #> Deviance = 22812.74 | Deviance change = 1.69e-05 #> Maximum parameter change: 0.000165  #> ........................................................... #> Iteration 38     2024-02-01 00:11:04.057737  #> Deviance = 22812.74 | Deviance change = 1.55e-05 #> Maximum parameter change: 0.00015  #> ........................................................... #> Iteration 39     2024-02-01 00:11:04.069762  #> Deviance = 22812.74 | Deviance change = 1.43e-05 #> Maximum parameter change: 0.000137  #> ........................................................... #> Iteration 40     2024-02-01 00:11:04.088938  #> Deviance = 22812.74 | Deviance change = 1.32e-05 #> Maximum parameter change: 0.000125  #> ........................................................... #> Iteration 41     2024-02-01 00:11:04.100976  #> Deviance = 22812.74 | Deviance change = 1.21e-05 #> Maximum parameter change: 0.000114  #> ........................................................... #> Iteration 42     2024-02-01 00:11:04.112766  #> Deviance = 22812.74 | Deviance change = 1.12e-05 #> Maximum parameter change: 0.000104  #> ........................................................... #> Iteration 43     2024-02-01 00:11:04.124593  #> Deviance = 22812.74 | Deviance change = 1.03e-05 #> Maximum parameter change: 9.4e-05  #> ----------------------------------------------------------------- #> Time difference of 0.8831816 secs  # score pre-test responses m2 <- TDCM::tdcm.score(m1, newdata = pre, qmatrix = qmat1) #> [1] Scoring responses with item parameters from previously calibrated model. #> [1] Scoring complete. Check results with the CDM summary function. summary(m2) #> ----------------------------------------------------------------- #> CDM 8.2-6 (2022-08-25 15:43:23)  #>  #> Call: #> CDM::gdina(data = newdata, q.matrix = qmatrix, linkfct = \"logit\",  #>     delta.fixed = calibration.model$delta, attr.prob.fixed = dist,  #>     progress = FALSE) #>  #> Date of Analysis: 2024-02-01 00:11:04.386102  #> Time difference of 0.1290834 secs #> Computation Time: 0.1290834  #>  #> Generalized DINA Model  #>  #> Number of iterations = 7 #> Iteration with minimal deviance = 7  #>  #> Estimation method: WLS #> Optimizer: CDM #> Monotonicity constraints: FALSE #> Number of items at boundary monotonicity constraint: NA #>  #> Parameter regularization: FALSE #>  #> Deviance = 20323.52  | Log likelihood = -10161.76  #>  #> Number of persons = 1000  #> Number of groups = 1  #> Number of items = 20  #> Number of estimated parameters = 0  #> Number of estimated item parameters = 0  #> Number of estimated skill class parameters = 0 ( 16 latent skill classes) #>  #> AIC = 20324  | penalty = 0    | AIC = -2*LL + 2*p   #> BIC = 20324  | penalty = 0    | BIC = -2*LL + log(n)*p    #> CAIC = 20324  | penalty = 0    | CAIC = -2*LL + [log(n)+1]*p  (consistent AIC)    #>  #> ----------------------------------------------------------------- #> Used Q-matrix  #>  #>         Att1 Att2 Att3 Att4 #> t1tem1     1    0    0    0 #> t1tem2     1    0    0    0 #> t1tem3     1    0    0    0 #> t1tem4     1    1    0    0 #> t1tem5     1    0    1    0 #> t1tem6     0    1    0    0 #> t1tem7     0    1    0    0 #> t1tem8     0    1    0    0 #> t1tem9     0    1    1    0 #> t1tem10    0    1    0    1 #> t1tem11    0    0    1    0 #> t1tem12    0    0    1    0 #> t1tem13    0    0    1    0 #> t1tem14    0    0    1    1 #> t1tem15    1    0    1    0 #> t1tem16    0    0    0    1 #> t1tem17    0    0    0    1 #> t1tem18    0    0    0    1 #> t1tem19    1    0    0    1 #> t1tem20    0    1    0    1 #>  #> ----------------------------------------------------------------- #>  #> Item Parameter Estimates  #>  #>     link    item itemno partype  rule     est se partype.attr #> 1  logit  t1tem1      1       0 GDINA -1.8500  0              #> 2  logit  t1tem1      1       1 GDINA  2.5268  0         Att1 #> 3  logit  t1tem2      2       0 GDINA -2.0396  0              #> 4  logit  t1tem2      2       1 GDINA  2.4801  0         Att1 #> 5  logit  t1tem3      3       0 GDINA -1.8284  0              #> 6  logit  t1tem3      3       1 GDINA  2.4484  0         Att1 #> 7  logit  t1tem4      4       0 GDINA -1.6953  0              #> 8  logit  t1tem4      4       1 GDINA  0.3820  0         Att1 #> 9  logit  t1tem4      4       2 GDINA  1.2483  0         Att2 #> 10 logit  t1tem4      4     1-2 GDINA  1.9649  0    Att1-Att2 #> 11 logit  t1tem5      5       0 GDINA -2.1359  0              #> 12 logit  t1tem5      5       1 GDINA  1.1610  0         Att1 #> 13 logit  t1tem5      5       2 GDINA  1.7450  0         Att3 #> 14 logit  t1tem5      5     1-2 GDINA  1.2464  0    Att1-Att3 #> 15 logit  t1tem6      6       0 GDINA -1.8011  0              #> 16 logit  t1tem6      6       1 GDINA  2.0532  0         Att2 #> 17 logit  t1tem7      7       0 GDINA -1.8086  0              #> 18 logit  t1tem7      7       1 GDINA  2.1732  0         Att2 #> 19 logit  t1tem8      8       0 GDINA -1.9797  0              #> 20 logit  t1tem8      8       1 GDINA  2.4459  0         Att2 #> 21 logit  t1tem9      9       0 GDINA -1.7141  0              #> 22 logit  t1tem9      9       1 GDINA  0.4422  0         Att2 #> 23 logit  t1tem9      9       2 GDINA  1.0810  0         Att3 #> 24 logit  t1tem9      9     1-2 GDINA  2.5658  0    Att2-Att3 #> 25 logit t1tem10     10       0 GDINA -1.9624  0              #> 26 logit t1tem10     10       1 GDINA  2.2848  0         Att2 #> 27 logit t1tem10     10       2 GDINA  1.2193  0         Att4 #> 28 logit t1tem10     10     1-2 GDINA  0.6186  0    Att2-Att4 #> 29 logit t1tem11     11       0 GDINA -1.7213  0              #> 30 logit t1tem11     11       1 GDINA  2.1766  0         Att3 #> 31 logit t1tem12     12       0 GDINA -1.9910  0              #> 32 logit t1tem12     12       1 GDINA  2.4624  0         Att3 #> 33 logit t1tem13     13       0 GDINA -2.3122  0              #> 34 logit t1tem13     13       1 GDINA  2.7951  0         Att3 #> 35 logit t1tem14     14       0 GDINA -2.2933  0              #> 36 logit t1tem14     14       1 GDINA  1.6906  0         Att3 #> 37 logit t1tem14     14       2 GDINA  2.2520  0         Att4 #> 38 logit t1tem14     14     1-2 GDINA  0.3171  0    Att3-Att4 #> 39 logit t1tem15     15       0 GDINA -1.6254  0              #> 40 logit t1tem15     15       1 GDINA  0.3066  0         Att1 #> 41 logit t1tem15     15       2 GDINA  1.1053  0         Att3 #> 42 logit t1tem15     15     1-2 GDINA  2.4272  0    Att1-Att3 #> 43 logit t1tem16     16       0 GDINA -2.3967  0              #> 44 logit t1tem16     16       1 GDINA  2.9574  0         Att4 #> 45 logit t1tem17     17       0 GDINA -2.1822  0              #> 46 logit t1tem17     17       1 GDINA  2.8343  0         Att4 #> 47 logit t1tem18     18       0 GDINA -2.1807  0              #> 48 logit t1tem18     18       1 GDINA  2.5299  0         Att4 #> 49 logit t1tem19     19       0 GDINA -2.0672  0              #> 50 logit t1tem19     19       1 GDINA  1.9131  0         Att1 #> 51 logit t1tem19     19       2 GDINA  1.4612  0         Att4 #> 52 logit t1tem19     19     1-2 GDINA  0.6771  0    Att1-Att4 #> 53 logit t1tem20     20       0 GDINA -1.8524  0              #> 54 logit t1tem20     20       1 GDINA  3.5267  0         Att2 #> 55 logit t1tem20     20       2 GDINA  1.1167  0         Att4 #> 56 logit t1tem20     20     1-2 GDINA -0.8459  0    Att2-Att4 #>  #> RMSD (RMSEA) Item Fit Statistics #>  t1tem1  t1tem2  t1tem3  t1tem4  t1tem5  t1tem6  t1tem7  t1tem8  t1tem9  #>   0.036   0.055   0.041   0.054   0.037   0.063   0.050   0.055   0.061  #> t1tem10 t1tem11 t1tem12 t1tem13 t1tem14 t1tem15 t1tem16 t1tem17 t1tem18  #>   0.063   0.067   0.043   0.057   0.056   0.045   0.035   0.048   0.053  #> t1tem19 t1tem20  #>   0.044   0.128  #>  #> Mean of RMSEA item fit: 0.055  #> ----------------------------------------------------------------- #> Model Implied Conditional Item Probabilities  #>  #>       item  rule nessskill itemno skillcomb   prob #> 1   t1tem1 GDINA      Att1      1        A0 0.1359 #> 2   t1tem1 GDINA      Att1      1        A1 0.6630 #> 3   t1tem2 GDINA      Att1      2        A0 0.1151 #> 4   t1tem2 GDINA      Att1      2        A1 0.6084 #> 5   t1tem3 GDINA      Att1      3        A0 0.1384 #> 6   t1tem3 GDINA      Att1      3        A1 0.6502 #> 7   t1tem4 GDINA Att1-Att2      4       A00 0.1551 #> 8   t1tem4 GDINA Att1-Att2      4       A10 0.2119 #> 9   t1tem4 GDINA Att1-Att2      4       A01 0.3901 #> 10  t1tem4 GDINA Att1-Att2      4       A11 0.8699 #> 11  t1tem5 GDINA Att1-Att3      5       A00 0.1057 #> 12  t1tem5 GDINA Att1-Att3      5       A10 0.2739 #> 13  t1tem5 GDINA Att1-Att3      5       A01 0.4035 #> 14  t1tem5 GDINA Att1-Att3      5       A11 0.8825 #> 15  t1tem6 GDINA      Att2      6        A0 0.1417 #> 16  t1tem6 GDINA      Att2      6        A1 0.5627 #> 17  t1tem7 GDINA      Att2      7        A0 0.1408 #> 18  t1tem7 GDINA      Att2      7        A1 0.5902 #> 19  t1tem8 GDINA      Att2      8        A0 0.1214 #> 20  t1tem8 GDINA      Att2      8        A1 0.6145 #> 21  t1tem9 GDINA Att2-Att3      9       A00 0.1526 #> 22  t1tem9 GDINA Att2-Att3      9       A10 0.2189 #> 23  t1tem9 GDINA Att2-Att3      9       A01 0.3468 #> 24  t1tem9 GDINA Att2-Att3      9       A11 0.9149 #> 25 t1tem10 GDINA Att2-Att4     10       A00 0.1232 #> 26 t1tem10 GDINA Att2-Att4     10       A10 0.5799 #> 27 t1tem10 GDINA Att2-Att4     10       A01 0.3223 #> 28 t1tem10 GDINA Att2-Att4     10       A11 0.8966 #> 29 t1tem11 GDINA      Att3     11        A0 0.1517 #> 30 t1tem11 GDINA      Att3     11        A1 0.6119 #> 31 t1tem12 GDINA      Att3     12        A0 0.1202 #> 32 t1tem12 GDINA      Att3     12        A1 0.6157 #> 33 t1tem13 GDINA      Att3     13        A0 0.0901 #> 34 t1tem13 GDINA      Att3     13        A1 0.6185 #> 35 t1tem14 GDINA Att3-Att4     14       A00 0.0917 #> 36 t1tem14 GDINA Att3-Att4     14       A10 0.3537 #> 37 t1tem14 GDINA Att3-Att4     14       A01 0.4897 #> 38 t1tem14 GDINA Att3-Att4     14       A11 0.8772 #> 39 t1tem15 GDINA Att1-Att3     15       A00 0.1645 #> 40 t1tem15 GDINA Att1-Att3     15       A10 0.2110 #> 41 t1tem15 GDINA Att1-Att3     15       A01 0.3728 #> 42 t1tem15 GDINA Att1-Att3     15       A11 0.9015 #> 43 t1tem16 GDINA      Att4     16        A0 0.0834 #> 44 t1tem16 GDINA      Att4     16        A1 0.6366 #> 45 t1tem17 GDINA      Att4     17        A0 0.1014 #> 46 t1tem17 GDINA      Att4     17        A1 0.6575 #> 47 t1tem18 GDINA      Att4     18        A0 0.1015 #> 48 t1tem18 GDINA      Att4     18        A1 0.5864 #> 49 t1tem19 GDINA Att1-Att4     19       A00 0.1123 #> 50 t1tem19 GDINA Att1-Att4     19       A10 0.4616 #> 51 t1tem19 GDINA Att1-Att4     19       A01 0.3530 #> 52 t1tem19 GDINA Att1-Att4     19       A11 0.8791 #> 53 t1tem20 GDINA Att2-Att4     20       A00 0.1356 #> 54 t1tem20 GDINA Att2-Att4     20       A10 0.8421 #> 55 t1tem20 GDINA Att2-Att4     20       A01 0.3240 #> 56 t1tem20 GDINA Att2-Att4     20       A11 0.8749 #> ----------------------------------------------------------------- #>  #> Skill Probabilities  #>  #>      skill.prob0 skill.prob1 #> Att1      0.8120      0.1880 #> Att2      0.7066      0.2934 #> Att3      0.5968      0.4032 #> Att4      0.7418      0.2582 #> ----------------------------------------------------------------- #>  #> Polychoric Correlations  #>  #> Group 1 #>       Att1  Att2  Att3  Att4 #> Att1 1.000 0.790 0.805 0.758 #> Att2 0.790 1.000 0.771 0.789 #> Att3 0.805 0.771 1.000 0.721 #> Att4 0.758 0.789 0.721 1.000 #>  #>  ----------------------------------------------------------------- #>  #> Skill Pattern Probabilities  #>  #>   0000   1000   0100   1100   0010   1010   0110   1110   0001   1001  #> 0.4982 0.0087 0.0356 0.0027 0.1131 0.0156 0.0422 0.0257 0.0324 0.0021  #>   0101   1101   0011   1011   0111   1111  #> 0.0134 0.0038 0.0243 0.0122 0.0527 0.1173  m2$pattern #>       pattern mle.est  mle.post map.est  map.post   post.attr1 #> 1    P1000001    0101 0.7732531    0101 0.6104801 0.0071967608 #> 2    P1000002    1011 0.8558210    1011 0.7576715 0.8167576712 #> 3    P1000003    0101 0.6510035    0111 0.5904542 0.0211450661 #> 4    P1000004    0000 0.6993881    0000 0.9863499 0.0070291677 #> 5    P1000005    0001 0.5333399    0001 0.4864266 0.0060133546 #> 6    P1000006    0110 0.4067857    0000 0.6211876 0.0004680533 #> 7    P1000007    0110 0.9054671    0110 0.8947340 0.0282740130 #> 8    P1000008    0010 0.7399214    0010 0.7014972 0.0002670151 #> 9    P1000009    1001 0.5864788    0001 0.7395102 0.0879363063 #> 10   P1000010    0000 0.7403778    0000 0.9758418 0.0005663039 #> 11   P1000011    0011 0.8692736    0011 0.8401266 0.0291971023 #> 12   P1000012    1101 0.5734254    1111 0.9289315 0.9768768571 #> 13   P1000013    0001 0.6029390    0000 0.4747336 0.0097737400 #> 14   P1000014    0111 0.9913832    0111 0.9928569 0.0025453071 #> 15   P1000015    0000 0.8800457    0000 0.9823247 0.0007988135 #> 16   P1000016    0100 0.4666722    0100 0.4350244 0.0005838629 #> 17   P1000017    0000 0.5886043    0000 0.9700354 0.0065131105 #> 18   P1000018    0001 0.8121305    0000 0.7278233 0.0005848300 #> 19   P1000019    0010 0.5697808    0010 0.8037094 0.0163362005 #> 20   P1000020    0000 0.6248140    0000 0.9483963 0.0018153609 #> 21   P1000021    0011 0.9352733    0011 0.7850855 0.0028506757 #> 22   P1000022    0101 0.4982022    0111 0.7677061 0.0325301578 #> 23   P1000023    1110 0.6297541    1111 0.6875192 0.9702553670 #> 24   P1000024    0000 0.7293857    0000 0.9758475 0.0038118734 #> 25   P1000025    0100 0.8830164    0100 0.5197908 0.0005685068 #> 26   P1000026    1110 0.6352891    1111 0.6915339 0.9757032749 #> 27   P1000027    0100 0.4769848    0000 0.4668873 0.0018364782 #> 28   P1000028    0000 0.8927890    0000 0.9898609 0.0005653722 #> 29   P1000029    0000 0.8321481    0000 0.9775210 0.0005611642 #> 30   P1000030    0000 0.7945936    0000 0.9543939 0.0005500125 #> 31   P1000031    0110 0.9410119    0110 0.9534871 0.0265704455 #> 32   P1000032    0110 0.9423740    0110 0.9530811 0.0193057530 #> 33   P1000033    0000 0.7889528    0000 0.9813444 0.0008876094 #> 34   P1000034    0010 0.4575519    0000 0.6580946 0.0214033744 #> 35   P1000035    0111 0.9821800    0111 0.9679669 0.0310038370 #> 36   P1000036    0110 0.4397752    0000 0.4598777 0.0018410926 #> 37   P1000037    0111 0.6522722    0111 0.6452758 0.3012268868 #> 38   P1000038    1111 0.4678224    1111 0.7235106 0.7994082969 #> 39   P1000039    1111 0.9623706    1111 0.9959749 0.9985756182 #> 40   P1000040    0000 0.6048937    0000 0.9709655 0.0094570720 #> 41   P1000041    1110 0.9665860    1110 0.8744583 0.9997354719 #> 42   P1000042    0000 0.6491303    0000 0.9539699 0.0026806904 #> 43   P1000043    0000 0.7964507    0000 0.9679898 0.0018112151 #> 44   P1000044    0000 0.7640355    0000 0.9512184 0.0005500379 #> 45   P1000045    0010 0.9069260    0010 0.7513435 0.0018522468 #> 46   P1000046    0010 0.8470506    0010 0.7852821 0.0022364381 #> 47   P1000047    0000 0.9282932    0000 0.9927706 0.0005653600 #> 48   P1000048    0001 0.4082578    0000 0.4097714 0.0041941502 #> 49   P1000049    0000 0.4742477    0000 0.8473264 0.0018198784 #> 50   P1000050    1010 0.7208434    0010 0.7304077 0.2636072492 #> 51   P1000051    1100 0.7768980    1100 0.3176005 0.7082873059 #> 52   P1000052    1000 0.5070371    0000 0.4882974 0.4635880640 #> 53   P1000053    0001 0.6994365    0001 0.4534844 0.0011484714 #> 54   P1000054    0010 0.6230747    0000 0.6471134 0.0050915492 #> 55   P1000055    0000 0.8246581    0000 0.9767836 0.0005611320 #> 56   P1000056    1000 0.4292132    0000 0.4645460 0.4832588781 #> 57   P1000057    0000 0.5302356    0000 0.9455020 0.0005686134 #> 58   P1000058    0000 0.4255044    0000 0.9319264 0.0040787531 #> 59   P1000059    0000 0.5259698    0000 0.8428973 0.0010523073 #> 60   P1000060    0110 0.8812441    0110 0.7804605 0.0023670931 #> 61   P1000061    0010 0.5788743    0000 0.6324374 0.0014156337 #> 62   P1000062    0001 0.6237463    0000 0.4938124 0.0070986964 #> 63   P1000063    0000 0.7812679    0000 0.9803424 0.0005662810 #> 64   P1000064    0100 0.5862579    0000 0.8645425 0.0020219299 #> 65   P1000065    1000 0.3452524    0000 0.8415725 0.0449549139 #> 66   P1000066    0000 0.8743368    0000 0.9882626 0.0005653790 #> 67   P1000067    0011 0.6061862    0010 0.3226205 0.0019529561 #> 68   P1000068    0010 0.6266949    0010 0.6527694 0.0005812934 #> 69   P1000069    0000 0.6825445    0000 0.9833533 0.0067104327 #> 70   P1000070    0100 0.6040637    0000 0.8686217 0.0007988752 #> 71   P1000071    0000 0.7750027    0000 0.9531274 0.0008131460 #> 72   P1000072    0101 0.7326647    0111 0.5463995 0.0049193727 #> 73   P1000073    0100 0.5023390    0100 0.5658059 0.0447515347 #> 74   P1000074    0110 0.7429286    0110 0.7407794 0.1052641484 #> 75   P1000075    0000 0.6774872    0000 0.9834589 0.0070293189 #> 76   P1000076    0110 0.4632056    0010 0.5432969 0.0233145411 #> 77   P1000077    1111 0.6638173    1111 0.8182832 0.8192415852 #> 78   P1000078    1000 0.8770771    0000 0.7629921 0.2081168321 #> 79   P1000079    0100 0.2677862    0000 0.6456829 0.0011621169 #> 80   P1000080    0000 0.5808218    0000 0.9696082 0.0067252590 #> 81   P1000081    0000 0.7231970    0000 0.9685878 0.0011828714 #> 82   P1000082    0000 0.7945936    0000 0.9543939 0.0005500125 #> 83   P1000083    0001 0.3636160    0000 0.6896402 0.0007845622 #> 84   P1000084    0010 0.6331003    0000 0.6700080 0.0026990549 #> 85   P1000085    0000 0.7576885    0000 0.9859370 0.0038387685 #> 86   P1000086    0010 0.5603143    0000 0.7372754 0.0018242094 #> 87   P1000087    1010 0.8299851    1010 0.8553675 0.9972464197 #> 88   P1000088    0000 0.8500130    0000 0.9863794 0.0005655706 #> 89   P1000089    0000 0.5115906    0000 0.9207455 0.0064755684 #> 90   P1000090    0001 0.6728006    0000 0.8232751 0.0005665587 #> 91   P1000091    0010 0.9143631    0010 0.9598727 0.0001768704 #> 92   P1000092    0000 0.9282932    0000 0.9927706 0.0005653600 #> 93   P1000093    1011 0.7274563    1111 0.7585009 0.9848402725 #> 94   P1000094    0000 0.4320419    0000 0.8725673 0.0009322190 #> 95   P1000095    0000 0.6993881    0000 0.9863499 0.0070291677 #> 96   P1000096    1000 0.3766359    0000 0.9172392 0.0205736217 #> 97   P1000097    0000 0.7138207    0000 0.9868733 0.0065023196 #> 98   P1000098    1111 0.9231462    1111 0.9834344 0.9998704011 #> 99   P1000099    0010 0.6165796    0010 0.7053257 0.0364101635 #> 100  P1000100    0100 0.2209131    0000 0.8035640 0.0179646075 #> 101  P1000101    0100 0.3626016    0000 0.7783928 0.0005412067 #> 102  P1000102    0001 0.5564963    0000 0.7668799 0.0005427693 #> 103  P1000103    0010 0.7345548    0000 0.5668334 0.0015540192 #> 104  P1000104    0101 0.7539704    0101 0.8436084 0.0778808593 #> 105  P1000105    1011 0.7410256    1011 0.6285640 0.8494488787 #> 106  P1000106    1011 0.9460126    1011 0.7400259 0.9907978948 #> 107  P1000107    0000 0.9282932    0000 0.9927706 0.0005653600 #> 108  P1000108    0100 0.9140156    0100 0.4980186 0.0005675600 #> 109  P1000109    0110 0.4020499    0000 0.4408389 0.0310444014 #> 110  P1000110    0001 0.4414481    0000 0.4451910 0.0019776923 #> 111  P1000111    0100 0.3740971    0000 0.8176001 0.0174224097 #> 112  P1000112    0001 0.3376003    0000 0.8884903 0.0010828079 #> 113  P1000113    0000 0.6482239    0000 0.9715551 0.0066607716 #> 114  P1000114    0000 0.4309271    0000 0.9393520 0.0070693539 #> 115  P1000115    0000 0.5338827    0000 0.8455217 0.0005065560 #> 116  P1000116    0110 0.9555023    0110 0.9180644 0.0025694289 #> 117  P1000117    1111 0.6343455    1111 0.9623388 0.9979995625 #> 118  P1000118    0010 0.4906085    0010 0.5793446 0.0020293829 #> 119  P1000119    0111 0.9678577    0111 0.9770025 0.0022101700 #> 120  P1000120    0100 0.8038465    0000 0.6836515 0.0007989297 #> 121  P1000121    0000 0.8500130    0000 0.9863794 0.0005655706 #> 122  P1000122    0000 0.5105792    0000 0.9549282 0.0091891419 #> 123  P1000123    1111 0.9907190    1111 0.9972182 0.9984863759 #> 124  P1000124    0000 0.8872653    0000 0.9825946 0.0005613861 #> 125  P1000125    0101 0.7191298    0101 0.3899688 0.0005747305 #> 126  P1000126    0000 0.4239916    0000 0.9315077 0.0040788602 #> 127  P1000127    0000 0.6792520    0000 0.9823919 0.0065025364 #> 128  P1000128    0101 0.6105764    0101 0.3193158 0.0062289102 #> 129  P1000129    0000 0.8500130    0000 0.9863794 0.0005655706 #> 130  P1000130    0010 0.7390947    0000 0.4957239 0.0025064879 #> 131  P1000131    0000 0.4239916    0000 0.9315077 0.0040788602 #> 132  P1000132    0101 0.3936399    0111 0.2406203 0.0003927184 #> 133  P1000133    1000 0.2650237    0010 0.4766614 0.1377273804 #> 134  P1000134    0000 0.7481017    0000 0.9615633 0.0005571424 #> 135  P1000135    0010 0.8081508    0010 0.7244238 0.0002700317 #> 136  P1000136    0010 0.7941289    0010 0.8289936 0.0210799438 #> 137  P1000137    1101 0.7795936    1111 0.8608579 0.9770478186 #> 138  P1000138    1111 0.9857401    1111 0.9982513 0.9998726677 #> 139  P1000139    0001 0.7790536    0000 0.5143564 0.0058584999 #> 140  P1000140    1000 0.6023101    0000 0.8962872 0.0411803015 #> 141  P1000141    0000 0.7200332    0000 0.9583250 0.0005571652 #> 142  P1000142    1010 0.6048609    0010 0.5449715 0.3605585214 #> 143  P1000143    0010 0.8835115    0010 0.6902118 0.0020280791 #> 144  P1000144    0000 0.7945936    0000 0.9543939 0.0005500125 #> 145  P1000145    0000 0.6258451    0000 0.9355598 0.0005513799 #> 146  P1000146    0100 0.5544053    0000 0.8313412 0.0094572659 #> 147  P1000147    0000 0.4376480    0000 0.9398533 0.0065395136 #> 148  P1000148    0010 0.5999075    0000 0.6764723 0.0004419627 #> 149  P1000149    1111 0.6140733    1111 0.7986578 0.8159996299 #> 150  P1000150    0000 0.6160175    0000 0.9745095 0.0065128489 #> 151  P1000151    0000 0.7576885    0000 0.9859370 0.0038387685 #> 152  P1000152    1101 0.6015309    1111 0.8749061 0.9777353796 #> 153  P1000153    0110 0.7519478    0110 0.8167658 0.1557442303 #> 154  P1000154    0100 0.3807894    0000 0.8592876 0.0008996989 #> 155  P1000155    0000 0.5846474    0000 0.9514334 0.0005655339 #> 156  P1000156    0100 0.5546391    0100 0.4755225 0.0018470215 #> 157  P1000157    0000 0.5600839    0000 0.9335726 0.0037858460 #> 158  P1000158    0000 0.7565539    0000 0.9766102 0.0005655825 #> 159  P1000159    0010 0.8498609    0010 0.7316372 0.0003998286 #> 160  P1000160    1111 0.8804742    1111 0.9735933 0.9984779431 #> 161  P1000161    0111 0.7695710    0111 0.9192694 0.0002197592 #> 162  P1000162    1111 0.8310868    1111 0.9505425 0.9820682899 #> 163  P1000163    0000 0.6045954    0000 0.9739919 0.0070405441 #> 164  P1000164    1000 0.6072300    1010 0.4534402 0.8888374681 #> 165  P1000165    0010 0.6764767    0000 0.6481419 0.0004284208 #> 166  P1000166    0000 0.9282932    0000 0.9927706 0.0005653600 #> 167  P1000167    0000 0.6993881    0000 0.9863499 0.0070291677 #> 168  P1000168    0000 0.8800457    0000 0.9823247 0.0007988135 #> 169  P1000169    1000 0.4084561    0000 0.8917205 0.0205977677 #> 170  P1000170    0000 0.4852453    0000 0.8852378 0.0005368399 #> 171  P1000171    0000 0.6975588    0000 0.9200437 0.0005362753 #> 172  P1000172    0010 0.9264947    0010 0.8075907 0.0018554404 #> 173  P1000173    0010 0.5999075    0000 0.6764723 0.0004419627 #> 174  P1000174    1010 0.4183234    0010 0.6999213 0.1314361654 #> 175  P1000175    0110 0.4908577    0110 0.4472350 0.1764210994 #> 176  P1000176    0000 0.5583010    0000 0.9143976 0.0066697744 #> 177  P1000177    0000 0.4796603    0000 0.9268116 0.0008009628 #> 178  P1000178    1011 0.6188980    1111 0.8466780 0.9971685961 #> 179  P1000179    1000 0.8243994    0000 0.8367840 0.1339650537 #> 180  P1000180    1111 0.7871859    1111 0.9589082 0.9804952881 #> 181  P1000181    0001 0.4218773    0000 0.8180603 0.0064948212 #> 182  P1000182    0000 0.6104470    0000 0.9559778 0.0005655147 #> 183  P1000183    1111 0.8673094    1111 0.9674656 0.9983540810 #> 184  P1000184    0100 0.6829081    0000 0.7612217 0.0065169127 #> 185  P1000185    0000 0.5663675    0000 0.9225210 0.0008665283 #> 186  P1000186    0100 0.6343971    0000 0.8606250 0.0015068150 #> 187  P1000187    0010 0.9158398    0010 0.9782031 0.0018695692 #> 188  P1000188    0000 0.6433656    0000 0.9708226 0.0066603912 #> 189  P1000189    0011 0.8608848    0011 0.6807684 0.0002366124 #> 190  P1000190    1000 0.8076813    0000 0.9159021 0.0779498286 #> 191  P1000191    0000 0.6425092    0000 0.9378200 0.0005512158 #> 192  P1000192    0111 0.9665964    0111 0.9603804 0.0217086486 #> 193  P1000193    0111 0.8978130    0111 0.9296439 0.0232010370 #> 194  P1000194    1010 0.3975496    0010 0.5042417 0.2168857856 #> 195  P1000195    1111 0.9317693    1111 0.9799355 0.9844030079 #> 196  P1000196    0000 0.9282932    0000 0.9927706 0.0005653600 #> 197  P1000197    0000 0.8872653    0000 0.9825946 0.0005613861 #> 198  P1000198    0000 0.8878243    0000 0.9894369 0.0005653740 #> 199  P1000199    0100 0.6967337    0100 0.5224093 0.0012312231 #> 200  P1000200    0000 0.6975588    0000 0.9200437 0.0005362753 #> 201  P1000201    0000 0.7080554    0000 0.9866667 0.0067102673 #> 202  P1000202    0000 0.7964507    0000 0.9679898 0.0018112151 #> 203  P1000203    0001 0.7297460    0001 0.8868584 0.0083789328 #> 204  P1000204    0010 0.9457177    0010 0.9178552 0.0018621032 #> 205  P1000205    0000 0.5200367    0000 0.9657392 0.0096088731 #> 206  P1000206    1110 0.9188770    1110 0.8350695 0.9610292198 #> 207  P1000207    1110 0.7267442    1110 0.6247343 0.7021631463 #> 208  P1000208    0000 0.7361847    0000 0.9756201 0.0005666309 #> 209  P1000209    0000 0.9282932    0000 0.9927706 0.0005653600 #> 210  P1000210    0000 0.7117645    0000 0.9727170 0.0005666466 #> 211  P1000211    0111 0.7604103    0111 0.8055328 0.0019732741 #> 212  P1000212    0100 0.4509748    0100 0.4147062 0.0005647247 #> 213  P1000213    0000 0.8800457    0000 0.9823247 0.0007988135 #> 214  P1000214    0000 0.7694047    0000 0.9651686 0.0018112483 #> 215  P1000215    0100 0.8448684    0100 0.7343282 0.0005251731 #> 216  P1000216    0110 0.9631930    0110 0.9382281 0.0025731135 #> 217  P1000217    0110 0.6106986    0010 0.5811352 0.0025956941 #> 218  P1000218    1011 0.5718536    1111 0.7605685 0.9569087408 #> 219  P1000219    0001 0.8991307    0001 0.5400580 0.0006059526 #> 220  P1000220    0001 0.5349858    0000 0.4147944 0.0011241469 #> 221  P1000221    0100 0.8126916    0100 0.5690814 0.0005336014 #> 222  P1000222    0000 0.7138207    0000 0.9868733 0.0065023196 #> 223  P1000223    0000 0.6265679    0000 0.9486843 0.0065291975 #> 224  P1000224    0000 0.5693980    0000 0.9307658 0.0067729640 #> 225  P1000225    0101 0.5411109    0111 0.3333780 0.0048456491 #> 226  P1000226    0111 0.6949965    0111 0.6442468 0.2974427742 #> 227  P1000227    0010 0.4952722    0000 0.5228925 0.0009096264 #> 228  P1000228    1000 0.7222695    0000 0.8676814 0.0997143626 #> 229  P1000229    1111 0.9954497    1111 0.9983533 0.9984882205 #> 230  P1000230    0100 0.2805822    0000 0.6417003 0.0070150475 #> 231  P1000231    1111 0.9808698    1111 0.9967279 0.9984802810 #> 232  P1000232    0101 0.6887166    0101 0.7600245 0.0841157797 #> 233  P1000233    0011 0.4310922    0010 0.4366317 0.0003321542 #> 234  P1000234    0011 0.7187106    0010 0.4596268 0.0020368128 #> 235  P1000235    0000 0.9282932    0000 0.9927706 0.0005653600 #> 236  P1000236    0011 0.5404962    0010 0.7210474 0.0002020171 #> 237  P1000237    0000 0.5219344    0000 0.9544264 0.0122102314 #> 238  P1000238    0010 0.8443737    0010 0.6793146 0.0019899636 #> 239  P1000239    0001 0.7546063    0000 0.8037132 0.0008578890 #> 240  P1000240    0100 0.5836153    0100 0.4655717 0.0208041199 #> 241  P1000241    1111 0.7787963    1111 0.9548848 0.9983567818 #> 242  P1000242    0000 0.6882252    0000 0.9435148 0.0008634217 #> 243  P1000243    1111 0.5594245    1111 0.8473149 0.9781730874 #> 244  P1000244    0101 0.2750182    0000 0.3686201 0.0014359973 #> 245  P1000245    0001 0.3574870    0000 0.6658347 0.0060628474 #> 246  P1000246    0010 0.8699781    0010 0.8334387 0.0018611434 #> 247  P1000247    0101 0.6937243    0101 0.4048754 0.0071010724 #> 248  P1000248    1010 0.8206934    1010 0.8428138 0.9534772610 #> 249  P1000249    0111 0.5211777    0111 0.8048473 0.0033619438 #> 250  P1000250    0010 0.4470991    0010 0.8027400 0.0285462253 #> 251  P1000251    0010 0.8630789    0010 0.8765406 0.0024983859 #> 252  P1000252    0000 0.8743368    0000 0.9882626 0.0005653790 #> 253  P1000253    0001 0.8991307    0001 0.5400580 0.0006059526 #> 254  P1000254    1000 0.6290946    1000 0.4936888 0.9308296227 #> 255  P1000255    0110 0.1873123    0110 0.3017182 0.1586699742 #> 256  P1000256    0000 0.5038222    0000 0.9526801 0.0067143359 #> 257  P1000257    0010 0.8382810    0010 0.8547050 0.0024089582 #> 258  P1000258    0000 0.4580631    0000 0.9208430 0.0005631689 #> 259  P1000259    0000 0.6133821    0000 0.9244534 0.0005457648 #> 260  P1000260    0010 0.3063247    0000 0.7589993 0.0060905719 #> 261  P1000261    0000 0.8878243    0000 0.9894369 0.0005653740 #> 262  P1000262    0000 0.6517862    0000 0.9548023 0.0028640131 #> 263  P1000263    1000 0.7318668    0000 0.9012499 0.0780691143 #> 264  P1000264    0010 0.7682341    0010 0.7025409 0.0002650671 #> 265  P1000265    0001 0.7500722    0000 0.6977198 0.0005684640 #> 266  P1000266    0101 0.2848300    0111 0.3321328 0.0250054227 #> 267  P1000267    0001 0.8207454    0000 0.5703452 0.0005836948 #> 268  P1000268    0000 0.5410043    0000 0.9438973 0.0005657758 #> 269  P1000269    0011 0.7289184    0011 0.6767935 0.0020884504 #> 270  P1000270    0110 0.4296951    0110 0.4355975 0.0329421366 #> 271  P1000271    0011 0.4023258    0010 0.5534995 0.0096449288 #> 272  P1000272    1111 0.9515667    1111 0.9806320 0.9827262569 #> 273  P1000273    0010 0.7262474    0000 0.5679689 0.0003970971 #> 274  P1000274    0000 0.6856959    0000 0.9837747 0.0067104117 #> 275  P1000275    0111 0.7053744    0111 0.6472198 0.2984554005 #> 276  P1000276    0000 0.7080554    0000 0.9866667 0.0067102673 #> 277  P1000277    0000 0.4876287    0000 0.9205699 0.0018124567 #> 278  P1000278    1001 0.5744276    0000 0.2668370 0.2013632102 #> 279  P1000279    0011 0.6000751    0011 0.5523600 0.0264696976 #> 280  P1000280    0000 0.6651915    0000 0.9159384 0.0005363223 #> 281  P1000281    0110 0.8369005    0110 0.7654269 0.0225068134 #> 282  P1000282    0000 0.9282932    0000 0.9927706 0.0005653600 #> 283  P1000283    1111 0.5238034    1111 0.7513690 0.8018520892 #> 284  P1000284    0000 0.4192915    0000 0.8630007 0.0122570771 #> 285  P1000285    0001 0.3319028    0000 0.8776767 0.0005709562 #> 286  P1000286    0111 0.7788969    0111 0.9327055 0.0022902913 #> 287  P1000287    1000 0.9021161    1000 0.6894180 0.7257831930 #> 288  P1000288    0000 0.5532166    0000 0.9567499 0.0064633440 #> 289  P1000289    1111 0.8971024    1111 0.9690204 0.9815090670 #> 290  P1000290    1111 0.8125886    1111 0.9747313 0.9982781152 #> 291  P1000291    0000 0.7565539    0000 0.9766102 0.0005655825 #> 292  P1000292    0010 0.7923946    0010 0.9547705 0.0218823449 #> 293  P1000293    1101 0.2546680    0000 0.2979842 0.1220995896 #> 294  P1000294    1111 0.9253173    1111 0.9793084 0.9836850662 #> 295  P1000295    0000 0.7083291    0000 0.9722940 0.0005666489 #> 296  P1000296    0010 0.8925623    0010 0.9396841 0.0021865199 #> 297  P1000297    0110 0.6971522    0110 0.5101931 0.0018713308 #> 298  P1000298    0000 0.8477960    0000 0.9794526 0.0007988094 #> 299  P1000299    0111 0.9276940    0111 0.9426315 0.0316914138 #> 300  P1000300    0000 0.8927890    0000 0.9898609 0.0005653722 #> 301  P1000301    1111 0.8960875    1111 0.9771250 0.9984426198 #> 302  P1000302    0000 0.8878243    0000 0.9894369 0.0005653740 #> 303  P1000303    1010 0.6861561    0010 0.7237958 0.2536966894 #> 304  P1000304    0010 0.8022284    0000 0.5007281 0.0003685841 #> 305  P1000305    0011 0.7784888    0011 0.7324233 0.0020923531 #> 306  P1000306    0111 0.5783095    0111 0.7039986 0.0246081146 #> 307  P1000307    1101 0.8016523    1101 0.7556679 0.8852811300 #> 308  P1000308    0000 0.9282932    0000 0.9927706 0.0005653600 #> 309  P1000309    0000 0.9282932    0000 0.9927706 0.0005653600 #> 310  P1000310    0110 0.3705342    0111 0.3724039 0.0200239862 #> 311  P1000311    1111 0.8757402    1111 0.9691959 0.9835349403 #> 312  P1000312    1000 0.8076813    0000 0.9159021 0.0779498286 #> 313  P1000313    1000 0.5057397    0000 0.9482153 0.0222025561 #> 314  P1000314    0000 0.6651915    0000 0.9159384 0.0005363223 #> 315  P1000315    0010 0.6021533    0010 0.6794543 0.0019932381 #> 316  P1000316    0000 0.8743368    0000 0.9882626 0.0005653790 #> 317  P1000317    0001 0.6665143    0000 0.7998761 0.0068744256 #> 318  P1000318    0000 0.5123537    0000 0.9069932 0.0061810476 #> 319  P1000319    0001 0.9336519    0001 0.9351409 0.0006211326 #> 320  P1000320    0000 0.7481017    0000 0.9615633 0.0005571424 #> 321  P1000321    0000 0.9020697    0000 0.9914361 0.0008358458 #> 322  P1000322    0100 0.5948426    0000 0.6264955 0.0021732411 #> 323  P1000323    0000 0.6889520    0000 0.9699562 0.0005668228 #> 324  P1000324    0100 0.9030736    0100 0.4933843 0.0007982522 #> 325  P1000325    1000 0.6618217    0000 0.9474920 0.0426824262 #> 326  P1000326    0110 0.9242368    0110 0.9406809 0.0263217690 #> 327  P1000327    0000 0.8500130    0000 0.9863794 0.0005655706 #> 328  P1000328    1011 0.9098369    1011 0.8359824 0.8378608435 #> 329  P1000329    0111 0.6480745    0111 0.7501071 0.0243762021 #> 330  P1000330    0000 0.5983449    0000 0.9718914 0.0095714457 #> 331  P1000331    0110 0.4745207    0000 0.4415193 0.0003582580 #> 332  P1000332    1111 0.9898435    1111 0.9971620 0.9985325910 #> 333  P1000333    0000 0.5978652    0000 0.9222213 0.0005459257 #> 334  P1000334    1000 0.3440085    0000 0.8688949 0.0465880658 #> 335  P1000335    0011 0.4367185    0010 0.4630996 0.0003367117 #> 336  P1000336    0000 0.7361847    0000 0.9756201 0.0005666309 #> 337  P1000337    0010 0.3892403    0000 0.7844519 0.0134555497 #> 338  P1000338    0110 0.4649238    0010 0.4176218 0.0019094556 #> 339  P1000339    0000 0.6215984    0000 0.9121439 0.0005372676 #> 340  P1000340    1101 0.7410992    1111 0.7019567 0.8153156436 #> 341  P1000341    0010 0.2163764    0000 0.5140615 0.0524335928 #> 342  P1000342    1010 0.5765186    1010 0.4945288 0.7388150152 #> 343  P1000343    0010 0.7447752    0000 0.4933197 0.0003690318 #> 344  P1000344    0110 0.4377848    0110 0.3993733 0.0001895841 #> 345  P1000345    0000 0.3960571    0000 0.8333020 0.0124240601 #> 346  P1000346    0000 0.7964507    0000 0.9679898 0.0018112151 #> 347  P1000347    0000 0.7193428    0000 0.9814456 0.0038389835 #> 348  P1000348    1110 0.8666259    1110 0.9055630 0.9669032247 #> 349  P1000349    0110 0.5069378    0110 0.4734317 0.0247838668 #> 350  P1000350    1110 0.5298108    1111 0.7654269 0.9799156946 #> 351  P1000351    0000 0.5773816    0000 0.9527143 0.0064086208 #> 352  P1000352    0111 0.9521976    0111 0.9464303 0.0339268241 #> 353  P1000353    0000 0.4930752    0000 0.9518063 0.0094822074 #> 354  P1000354    1111 0.8526323    1111 0.9762522 0.9820343944 #> 355  P1000355    0110 0.9305045    0110 0.9336057 0.0231145555 #> 356  P1000356    0000 0.6531383    0000 0.9717570 0.0064543477 #> 357  P1000357    0111 0.4347065    0111 0.5241837 0.0250920534 #> 358  P1000358    0000 0.4469406    0000 0.9229335 0.0039546565 #> 359  P1000359    1111 0.9106762    1111 0.9747364 0.9778761099 #> 360  P1000360    0000 0.7138207    0000 0.9868733 0.0065023196 #> 361  P1000361    1010 0.5478980    1010 0.3576179 0.7255064928 #> 362  P1000362    0000 0.6502410    0000 0.9799977 0.0070317689 #> 363  P1000363    0000 0.5944533    0000 0.9349591 0.0067724767 #> 364  P1000364    0100 0.5915588    0000 0.8496104 0.0007997973 #> 365  P1000365    1111 0.8875797    1111 0.9661808 0.9806868762 #> 366  P1000366    0000 0.9282932    0000 0.9927706 0.0005653600 #> 367  P1000367    0000 0.5489771    0000 0.9120417 0.0063674323 #> 368  P1000368    1010 0.5932085    0010 0.7284063 0.2130663762 #> 369  P1000369    0110 0.5771928    0010 0.5861364 0.0021365403 #> 370  P1000370    1101 0.4304170    0001 0.4977632 0.2760823104 #> 371  P1000371    0010 0.8558435    0010 0.8600689 0.0002097929 #> 372  P1000372    1110 0.6485169    1111 0.7061995 0.9979289548 #> 373  P1000373    0000 0.6517862    0000 0.9548023 0.0028640131 #> 374  P1000374    1000 0.8908843    0000 0.5911744 0.3532967285 #> 375  P1000375    0000 0.6114595    0000 0.9743052 0.0067211311 #> 376  P1000376    1110 0.7353731    1110 0.7613884 0.9579486722 #> 377  P1000377    1011 0.7786109    1111 0.7011020 0.9996367545 #> 378  P1000378    0000 0.9282932    0000 0.9927706 0.0005653600 #> 379  P1000379    0000 0.9282932    0000 0.9927706 0.0005653600 #> 380  P1000380    0010 0.4455720    0000 0.4962023 0.0046446127 #> 381  P1000381    0000 0.5247195    0000 0.9379435 0.0105888674 #> 382  P1000382    1011 0.9565217    1011 0.9406011 0.9858868053 #> 383  P1000383    0000 0.8500130    0000 0.9863794 0.0005655706 #> 384  P1000384    1111 0.9683147    1111 0.9954594 0.9983948028 #> 385  P1000385    1111 0.8860781    1111 0.9861720 0.9982938024 #> 386  P1000386    0000 0.3794625    0000 0.8328501 0.0018526038 #> 387  P1000387    0001 0.6635084    0000 0.8220546 0.0008387556 #> 388  P1000388    0000 0.5108075    0000 0.9403866 0.0005683049 #> 389  P1000389    0100 0.8765830    0100 0.9109119 0.0067690182 #> 390  P1000390    1011 0.6735759    1111 0.7311852 0.9835581553 #> 391  P1000391    1000 0.6130119    0000 0.8770541 0.0437403031 #> 392  P1000392    1111 0.6809372    1111 0.8346571 0.8387269811 #> 393  P1000393    1000 0.6657226    0000 0.8649557 0.1180795575 #> 394  P1000394    1111 0.5580312    1111 0.7923717 0.8040289896 #> 395  P1000395    0000 0.6659797    0000 0.9818709 0.0070294020 #> 396  P1000396    0000 0.6804043    0000 0.9624649 0.0008006940 #> 397  P1000397    0110 0.9327480    0110 0.8992459 0.0018082708 #> 398  P1000398    1000 0.7955976    0000 0.9213202 0.0724954423 #> 399  P1000399    1100 0.4985856    0100 0.5519919 0.0597632721 #> 400  P1000400    0100 0.6642995    0000 0.8386081 0.0007988259 #> 401  P1000401    0011 0.5807925    0111 0.5824944 0.0001981655 #> 402  P1000402    0000 0.5978652    0000 0.9222213 0.0005459257 #> 403  P1000403    0000 0.8432778    0000 0.9790341 0.0007988087 #> 404  P1000404    1000 0.5944197    0000 0.8770902 0.0728824316 #> 405  P1000405    0000 0.9282932    0000 0.9927706 0.0005653600 #> 406  P1000406    0010 0.5990201    0010 0.7766073 0.0018818993 #> 407  P1000407    1111 0.5472297    1111 0.7527310 0.7698067044 #> 408  P1000408    0011 0.9287084    0011 0.9396997 0.0313803169 #> 409  P1000409    0000 0.5212701    0000 0.9421989 0.0010777585 #> 410  P1000410    0000 0.6579169    0000 0.9803125 0.0067127513 #> 411  P1000411    0110 0.3682924    0110 0.3205840 0.0030851488 #> 412  P1000412    1110 0.8739298    1110 0.7036628 0.9997278314 #> 413  P1000413    1111 0.8303428    1111 0.9570156 0.9983340884 #> 414  P1000414    0011 0.8534066    0011 0.8739739 0.0456490054 #> 415  P1000415    1111 0.8472874    1111 0.9756169 0.9998663498 #> 416  P1000416    0000 0.8477960    0000 0.9794526 0.0007988094 #> 417  P1000417    0011 0.7507246    0011 0.5772924 0.0020379256 #> 418  P1000418    1000 0.5057397    0000 0.9482153 0.0222025561 #> 419  P1000419    0000 0.9282932    0000 0.9927706 0.0005653600 #> 420  P1000420    0000 0.7080554    0000 0.9866667 0.0067102673 #> 421  P1000421    1111 0.4255808    1111 0.7810025 0.8020343701 #> 422  P1000422    1111 0.8642864    1111 0.9665900 0.9984281468 #> 423  P1000423    0000 0.8085346    0000 0.9760061 0.0007990958 #> 424  P1000424    0100 0.6382076    0100 0.7840936 0.0067844071 #> 425  P1000425    0010 0.9158398    0010 0.9782031 0.0018695692 #> 426  P1000426    1000 0.8028698    0000 0.9181345 0.0757024595 #> 427  P1000427    0000 0.9282932    0000 0.9927706 0.0005653600 #> 428  P1000428    1110 0.8907498    1110 0.9124804 0.9951290910 #> 429  P1000429    1000 0.6144483    0000 0.8992816 0.0411775238 #> 430  P1000430    0110 0.4609722    0010 0.4406504 0.0003066340 #> 431  P1000431    1111 0.8083034    1111 0.9620484 0.9808321206 #> 432  P1000432    0000 0.6348207    0000 0.9344336 0.0036981301 #> 433  P1000433    0100 0.6195184    0000 0.8776157 0.0005659880 #> 434  P1000434    0000 0.5644601    0000 0.9667229 0.0067254443 #> 435  P1000435    0010 0.5553114    0000 0.6367344 0.0053417410 #> 436  P1000436    1111 0.9511837    1111 0.9794670 0.9813680241 #> 437  P1000437    1111 0.8897423    1111 0.9767149 0.9998680389 #> 438  P1000438    1010 0.7147248    0010 0.7030439 0.2548518742 #> 439  P1000439    0011 0.7127133    0011 0.4799771 0.0031368048 #> 440  P1000440    0010 0.9201075    0010 0.9623900 0.0002610120 #> 441  P1000441    0100 0.5602879    0000 0.8328616 0.0005457173 #> 442  P1000442    0011 0.8860721    0011 0.8031623 0.0002103427 #> 443  P1000443    1111 0.9922386    1111 0.9984440 0.9998729558 #> 444  P1000444    0000 0.7750027    0000 0.9531274 0.0008131460 #> 445  P1000445    1110 0.4320030    1110 0.4837165 0.9992876173 #> 446  P1000446    0000 0.7228608    0000 0.9663645 0.0007990357 #> 447  P1000447    0000 0.6975588    0000 0.9200437 0.0005362753 #> 448  P1000448    0100 0.7738579    0100 0.8787733 0.0040461553 #> 449  P1000449    0000 0.5544508    0000 0.9009633 0.0005374592 #> 450  P1000450    1000 0.7836651    0000 0.8248105 0.1030437780 #> 451  P1000451    0001 0.6375571    0001 0.8300185 0.0083986347 #> 452  P1000452    0010 0.6964399    0000 0.5691282 0.0045728433 #> 453  P1000453    0010 0.5036036    0000 0.7902812 0.0018213039 #> 454  P1000454    0100 0.5324460    0000 0.8436495 0.0005456175 #> 455  P1000455    0000 0.7945936    0000 0.9543939 0.0005500125 #> 456  P1000456    1110 0.5155970    1110 0.5542450 0.6561920229 #> 457  P1000457    0010 0.5264908    0000 0.7428723 0.0004687890 #> 458  P1000458    1111 0.8601880    1111 0.9566951 0.9808482800 #> 459  P1000459    0001 0.6609309    0001 0.6377825 0.0011921278 #> 460  P1000460    0010 0.4898535    0010 0.6038008 0.0018551199 #> 461  P1000461    0000 0.6274110    0000 0.9489226 0.0018158760 #> 462  P1000462    0000 0.5338827    0000 0.8455217 0.0005065560 #> 463  P1000463    0100 0.6821812    0100 0.4296600 0.0004814399 #> 464  P1000464    0011 0.9008553    0011 0.8237868 0.0027966088 #> 465  P1000465    0000 0.6629355    0000 0.9523010 0.0018119031 #> 466  P1000466    0010 0.8806777    0010 0.8785518 0.0002096822 #> 467  P1000467    1110 0.7187863    1110 0.5420974 0.9703835330 #> 468  P1000468    1010 0.4430228    0010 0.7349055 0.1817622016 #> 469  P1000469    0000 0.6049125    0000 0.9323930 0.0005514098 #> 470  P1000470    0000 0.4125302    0000 0.8810743 0.0066745147 #> 471  P1000471    0000 0.4187017    0000 0.8385817 0.0005122479 #> 472  P1000472    0010 0.9752522    0010 0.9770730 0.0018650632 #> 473  P1000473    1111 0.6203051    1111 0.7952958 0.7966944516 #> 474  P1000474    0110 0.8684739    0110 0.9148263 0.0235802616 #> 475  P1000475    1000 0.6480675    0000 0.9442985 0.0426841250 #> 476  P1000476    0000 0.5859735    0000 0.9554343 0.0069276488 #> 477  P1000477    0000 0.8743368    0000 0.9882626 0.0005653790 #> 478  P1000478    1010 0.5142240    1010 0.4506999 0.7397490401 #> 479  P1000479    1111 0.9911429    1111 0.9974143 0.9983123301 #> 480  P1000480    1111 0.9122101    1111 0.9778491 0.9848703794 #> 481  P1000481    0010 0.3383178    0000 0.4897435 0.0016068862 #> 482  P1000482    0110 0.7568255    0110 0.7161079 0.0019505177 #> 483  P1000483    0110 0.4152831    0110 0.4558602 0.2500773439 #> 484  P1000484    1011 0.9853086    1011 0.9120705 0.9986596084 #> 485  P1000485    0010 0.5098443    0010 0.5102775 0.0042944831 #> 486  P1000486    0000 0.7155833    0000 0.9732810 0.0005668043 #> 487  P1000487    0000 0.4874239    0000 0.8501141 0.0018198385 #> 488  P1000488    0011 0.8633941    0011 0.7734393 0.0026189591 #> 489  P1000489    0111 0.9351304    0111 0.9441653 0.0214397546 #> 490  P1000490    0001 0.7238456    0000 0.5717544 0.0010893855 #> 491  P1000491    0001 0.4883367    0000 0.9233256 0.0005702641 #> 492  P1000492    0000 0.7168890    0000 0.9366025 0.0005446242 #> 493  P1000493    0110 0.7197260    0110 0.5659166 0.0165518363 #> 494  P1000494    0111 0.9310603    0111 0.9582248 0.0235599552 #> 495  P1000495    0000 0.6885021    0000 0.9632729 0.0005628098 #> 496  P1000496    0010 0.8458233    0010 0.7303377 0.0002707006 #> 497  P1000497    0000 0.5503824    0000 0.9118389 0.0061700934 #> 498  P1000498    0000 0.7576885    0000 0.9859370 0.0038387685 #> 499  P1000499    0000 0.7361847    0000 0.9756201 0.0005666309 #> 500  P1000500    1110 0.8488275    1110 0.7750277 0.7831217680 #> 501  P1000501    0001 0.5224212    0000 0.8521331 0.0070150455 #> 502  P1000502    1100 0.7089816    1100 0.3830200 0.7825766258 #> 503  P1000503    0100 0.5326614    0100 0.7712107 0.0551241076 #> 504  P1000504    0001 0.3934106    0000 0.8848436 0.0005542585 #> 505  P1000505    1111 0.8777480    1111 0.9745195 0.9998678116 #> 506  P1000506    1011 0.5435815    1111 0.7908795 0.9641969376 #> 507  P1000507    0001 0.5001339    0000 0.9075202 0.0042056486 #> 508  P1000508    0000 0.8045695    0000 0.9747438 0.0005610428 #> 509  P1000509    0110 0.9080631    0110 0.9000154 0.0137539757 #> 510  P1000510    0010 0.7873939    0010 0.9537716 0.0229056594 #> 511  P1000511    0000 0.9282932    0000 0.9927706 0.0005653600 #> 512  P1000512    0000 0.5795022    0000 0.9423001 0.0068421868 #> 513  P1000513    0000 0.8743368    0000 0.9882626 0.0005653790 #> 514  P1000514    0000 0.6049525    0000 0.9354371 0.0062647466 #> 515  P1000515    0010 0.4606021    0000 0.7918133 0.0004885616 #> 516  P1000516    0000 0.4165326    0000 0.8552901 0.0068092503 #> 517  P1000517    0000 0.8518045    0000 0.9808973 0.0011807218 #> 518  P1000518    1101 0.4514165    1111 0.5494470 0.6316624779 #> 519  P1000519    1010 0.5281710    1110 0.5892937 0.9933396755 #> 520  P1000520    1010 0.4389169    0010 0.7272222 0.1736347537 #> 521  P1000521    0000 0.8500130    0000 0.9863794 0.0005655706 #> 522  P1000522    0010 0.6842118    0000 0.5640079 0.0015524695 #> 523  P1000523    0001 0.2696699    0000 0.4224541 0.0666798849 #> 524  P1000524    0111 0.3455441    0111 0.4535814 0.2764399508 #> 525  P1000525    0000 0.5151086    0000 0.9319055 0.0068544207 #> 526  P1000526    0100 0.7728963    0000 0.4787146 0.0031623186 #> 527  P1000527    1101 0.7749529    1101 0.4489395 0.6218016102 #> 528  P1000528    0000 0.6290902    0000 0.9740999 0.0091648353 #> 529  P1000529    0000 0.5721889    0000 0.9039919 0.0005374204 #> 530  P1000530    0000 0.9282932    0000 0.9927706 0.0005653600 #> 531  P1000531    1011 0.7268486    1011 0.5681315 0.8091678078 #> 532  P1000532    0010 0.9106417    0010 0.9743294 0.0025772876 #> 533  P1000533    0000 0.6441063    0000 0.9512108 0.0018153167 #> 534  P1000534    0000 0.7481017    0000 0.9615633 0.0005571424 #> 535  P1000535    0000 0.3677247    0000 0.8990504 0.0039599655 #> 536  P1000536    0001 0.4397362    0000 0.9135447 0.0061535709 #> 537  P1000537    0100 0.5192734    0100 0.6561093 0.0009849623 #> 538  P1000538    1110 0.7125394    1110 0.5218934 0.7283419829 #> 539  P1000539    0010 0.8988429    0010 0.9198922 0.0001920824 #> 540  P1000540    0110 0.6482478    0110 0.7282220 0.2255191720 #> 541  P1000541    0111 0.7673962    0111 0.7381637 0.2533497366 #> 542  P1000542    0100 0.4601587    0000 0.6336882 0.0296314436 #> 543  P1000543    1111 0.6194552    1111 0.9237889 0.9846848356 #> 544  P1000544    1010 0.9395694    1010 0.7857928 0.8060809428 #> 545  P1000545    0110 0.9285108    0110 0.9349357 0.0316222856 #> 546  P1000546    0100 0.4429764    0100 0.4552966 0.0003907624 #> 547  P1000547    0000 0.6975588    0000 0.9200437 0.0005362753 #> 548  P1000548    0111 0.8049442    0111 0.8913263 0.0346667472 #> 549  P1000549    0000 0.7552530    0000 0.9636190 0.0018112666 #> 550  P1000550    1111 0.8868100    1111 0.9848451 0.9982977067 #> 551  P1000551    0000 0.4538115    0000 0.9270907 0.0005693041 #> 552  P1000552    0001 0.3642471    0000 0.9148927 0.0067625465 #> 553  P1000553    0001 0.3015113    0000 0.8421600 0.0010422873 #> 554  P1000554    1110 0.6423322    1111 0.7064602 0.9979887136 #> 555  P1000555    1111 0.5380866    1111 0.8447713 0.9982705363 #> 556  P1000556    0000 0.7576885    0000 0.9859370 0.0038387685 #> 557  P1000557    0010 0.7676036    0010 0.9177336 0.0172258950 #> 558  P1000558    1000 0.7839845    0000 0.9139631 0.0757048074 #> 559  P1000559    0010 0.9662072    0010 0.9736669 0.0018651045 #> 560  P1000560    0100 0.5980483    0100 0.4993775 0.0036688612 #> 561  P1000561    1110 0.7601441    1110 0.9424141 0.9971000321 #> 562  P1000562    0011 0.8478413    0011 0.7999384 0.0002719935 #> 563  P1000563    1000 0.7254290    0000 0.9228521 0.0665722498 #> 564  P1000564    0110 0.3601238    0110 0.3520747 0.0306378035 #> 565  P1000565    0000 0.7945936    0000 0.9543939 0.0005500125 #> 566  P1000566    0000 0.5345388    0000 0.9722230 0.0101741259 #> 567  P1000567    0100 0.5463193    0000 0.8674133 0.0018128721 #> 568  P1000568    0100 0.6648953    0000 0.6335432 0.0081079548 #> 569  P1000569    0000 0.8518045    0000 0.9808973 0.0011807218 #> 570  P1000570    0111 0.9710396    0111 0.9609290 0.0339846038 #> 571  P1000571    0000 0.7565539    0000 0.9766102 0.0005655825 #> 572  P1000572    0001 0.4947287    0000 0.7215062 0.0018559563 #> 573  P1000573    0111 0.9539980    0111 0.9635132 0.0262489535 #> 574  P1000574    1000 0.6128965    0000 0.5822944 0.3796321786 #> 575  P1000575    0001 0.7716261    0000 0.7119592 0.0018738013 #> 576  P1000576    0000 0.9020697    0000 0.9914361 0.0008358458 #> 577  P1000577    0111 0.6602141    0111 0.8767395 0.0305392185 #> 578  P1000578    0010 0.4552975    0010 0.7353884 0.0282372565 #> 579  P1000579    0110 0.9843032    0110 0.9770572 0.0017629507 #> 580  P1000580    0101 0.7314013    0101 0.5374693 0.0070773093 #> 581  P1000581    0111 0.7168234    0111 0.7067971 0.2613934763 #> 582  P1000582    0011 0.5297358    0011 0.6491753 0.2852741776 #> 583  P1000583    1000 0.6497901    0000 0.9447047 0.0426839090 #> 584  P1000584    0010 0.7273216    0000 0.4988601 0.0003702594 #> 585  P1000585    1111 0.9964621    1111 0.9995616 0.9998730871 #> 586  P1000586    0000 0.5920966    0000 0.9715920 0.0098765700 #> 587  P1000587    1111 0.9651629    1111 0.9953475 0.9983927691 #> 588  P1000588    1111 0.8747513    1111 0.9604234 0.9809437175 #> 589  P1000589    0010 0.4326950    0000 0.6844142 0.0162101169 #> 590  P1000590    0100 0.5310854    0000 0.7971827 0.0005383005 #> 591  P1000591    0100 0.7885307    0000 0.7078586 0.0007989435 #> 592  P1000592    1111 0.9602795    1111 0.9825318 0.9827719604 #> 593  P1000593    1110 0.9401380    1110 0.7756312 0.9981417426 #> 594  P1000594    1110 0.9602653    1110 0.9565036 0.9745320119 #> 595  P1000595    0111 0.7245318    0111 0.7780914 0.0019835044 #> 596  P1000596    0110 0.5046143    0110 0.5288935 0.2290452704 #> 597  P1000597    0010 0.7390947    0000 0.4957239 0.0025064879 #> 598  P1000598    0000 0.4376480    0000 0.9398533 0.0065395136 #> 599  P1000599    0001 0.3424502    0000 0.8083330 0.0005214449 #> 600  P1000600    0000 0.5509096    0000 0.9643974 0.0067274944 #> 601  P1000601    0100 0.6351599    0100 0.7182406 0.0052267107 #> 602  P1000602    1110 0.4157443    1111 0.6207432 0.7933668644 #> 603  P1000603    1000 0.8091932    0000 0.8504676 0.1084339483 #> 604  P1000604    0010 0.6870885    0000 0.5624668 0.0006328483 #> 605  P1000605    0000 0.7747484    0000 0.9798860 0.0008950895 #> 606  P1000606    1000 0.6266384    0000 0.9118913 0.0415711396 #> 607  P1000607    1000 0.8939117    1000 0.5429463 0.5806590168 #> 608  P1000608    1111 0.8584434    1111 0.9606252 0.9840334197 #> 609  P1000609    0010 0.6491865    0000 0.6712587 0.0018280610 #> 610  P1000610    0000 0.8743368    0000 0.9882626 0.0005653790 #> 611  P1000611    0000 0.7481017    0000 0.9615633 0.0005571424 #> 612  P1000612    0010 0.8459709    0010 0.6750597 0.0004544411 #> 613  P1000613    0010 0.5517252    0000 0.5508450 0.0208192791 #> 614  P1000614    1000 0.5913753    0000 0.8758978 0.0418293103 #> 615  P1000615    0011 0.5361257    0010 0.3282702 0.0187583983 #> 616  P1000616    1110 0.8844799    1110 0.9056468 0.9689508257 #> 617  P1000617    0000 0.8878243    0000 0.9894369 0.0005653740 #> 618  P1000618    0000 0.7361847    0000 0.9756201 0.0005666309 #> 619  P1000619    0100 0.8723601    0100 0.8754195 0.0005723912 #> 620  P1000620    0001 0.6963939    0001 0.6323708 0.0123738440 #> 621  P1000621    0000 0.5525193    0000 0.9122229 0.0061700428 #> 622  P1000622    0001 0.2756652    0000 0.2541412 0.0017584998 #> 623  P1000623    0100 0.3145241    0000 0.3883455 0.0184256954 #> 624  P1000624    0010 0.8055830    0010 0.9404306 0.0273408925 #> 625  P1000625    0100 0.4857891    0000 0.7773624 0.0035895900 #> 626  P1000626    0000 0.5999204    0000 0.9470679 0.0026833595 #> 627  P1000627    0010 0.4506039    0000 0.6574211 0.0224048032 #> 628  P1000628    0000 0.4454466    0000 0.8754380 0.0005369583 #> 629  P1000629    0000 0.6837336    0000 0.9630126 0.0008009501 #> 630  P1000630    0000 0.7799658    0000 0.9532099 0.0008513357 #> 631  P1000631    0000 0.5302356    0000 0.9455020 0.0005686134 #> 632  P1000632    0000 0.7565539    0000 0.9766102 0.0005655825 #> 633  P1000633    0100 0.5745958    0000 0.6423557 0.0005722043 #> 634  P1000634    1111 0.9777140    1111 0.9963280 0.9985260821 #> 635  P1000635    1111 0.6620215    1111 0.8257997 0.8283478359 #> 636  P1000636    0011 0.8719551    0011 0.7452931 0.0304495209 #> 637  P1000637    0000 0.8872653    0000 0.9825946 0.0005613861 #> 638  P1000638    1111 0.9959830    1111 0.9983714 0.9984885086 #> 639  P1000639    0110 0.5537806    0110 0.5225916 0.1641882662 #> 640  P1000640    0110 0.8478481    0110 0.6835634 0.0025063751 #> 641  P1000641    0000 0.7481017    0000 0.9615633 0.0005571424 #> 642  P1000642    1111 0.2942821    1111 0.6035305 0.7500301569 #> 643  P1000643    0000 0.9282932    0000 0.9927706 0.0005653600 #> 644  P1000644    0000 0.5465660    0000 0.9342318 0.0005587884 #> 645  P1000645    0000 0.6659797    0000 0.9818709 0.0070294020 #> 646  P1000646    0000 0.5537933    0000 0.8711270 0.0009910953 #> 647  P1000647    1010 0.5008513    0010 0.7187189 0.2257207749 #> 648  P1000648    0111 0.8084284    0111 0.7054375 0.2798862084 #> 649  P1000649    0111 0.7693200    0111 0.8087073 0.0020768466 #> 650  P1000650    0000 0.5191252    0000 0.9203535 0.0062678827 #> 651  P1000651    1101 0.7698671    1111 0.6553109 0.8067405790 #> 652  P1000652    0000 0.7028819    0000 0.9653303 0.0008006936 #> 653  P1000653    0000 0.9282932    0000 0.9927706 0.0005653600 #> 654  P1000654    0000 0.4704682    0000 0.8316430 0.0005034014 #> 655  P1000655    0000 0.5527617    0000 0.8706543 0.0005182244 #> 656  P1000656    0110 0.9066613    0110 0.8366968 0.0015850764 #> 657  P1000657    0000 0.6787328    0000 0.9423833 0.0005508845 #> 658  P1000658    1000 0.3251259    0000 0.8983898 0.0206139013 #> 659  P1000659    0001 0.2914234    0000 0.8551139 0.0110271184 #> 660  P1000660    0001 0.3961301    0000 0.4598741 0.0004457440 #> 661  P1000661    0000 0.6803959    0000 0.9558307 0.0018141874 #> 662  P1000662    0000 0.9282932    0000 0.9927706 0.0005653600 #> 663  P1000663    0000 0.9282932    0000 0.9927706 0.0005653600 #> 664  P1000664    0110 0.6086993    0010 0.6081924 0.0001787328 #> 665  P1000665    0000 0.8878243    0000 0.9894369 0.0005653740 #> 666  P1000666    0100 0.5941708    0100 0.8077193 0.0072398691 #> 667  P1000667    0110 0.5678676    0110 0.3911292 0.0046671213 #> 668  P1000668    0010 0.7544499    0000 0.5715157 0.0003968932 #> 669  P1000669    0010 0.8066376    0010 0.9160029 0.0266028625 #> 670  P1000670    0000 0.9282932    0000 0.9927706 0.0005653600 #> 671  P1000671    0000 0.8800457    0000 0.9823247 0.0007988135 #> 672  P1000672    0011 0.7845487    0011 0.6909931 0.0002734852 #> 673  P1000673    1110 0.8593579    1110 0.7803706 0.9708802140 #> 674  P1000674    0000 0.6045954    0000 0.9739919 0.0070405441 #> 675  P1000675    0000 0.6993881    0000 0.9863499 0.0070291677 #> 676  P1000676    0001 0.4352282    0000 0.9205970 0.0005697921 #> 677  P1000677    1111 0.6633538    1111 0.8257889 0.8289087483 #> 678  P1000678    0100 0.5902861    0000 0.8308240 0.0015301906 #> 679  P1000679    0000 0.4047307    0000 0.9456276 0.0147970630 #> 680  P1000680    0000 0.6133821    0000 0.9244534 0.0005457648 #> 681  P1000681    0110 0.5506304    0110 0.5224430 0.0028524873 #> 682  P1000682    1111 0.9399615    1111 0.9785749 0.9817914494 #> 683  P1000683    0001 0.3473169    0000 0.8862949 0.0132395250 #> 684  P1000684    1111 0.7314775    1111 0.9667063 0.9793115223 #> 685  P1000685    0000 0.6279213    0000 0.9262412 0.0005454679 #> 686  P1000686    0100 0.7771710    0100 0.5499266 0.0037738156 #> 687  P1000687    0110 0.6007382    0110 0.3750470 0.0124251379 #> 688  P1000688    0000 0.3218732    0000 0.8540525 0.0062113934 #> 689  P1000689    0100 0.8435643    0100 0.4914399 0.0038909753 #> 690  P1000690    0000 0.8800457    0000 0.9823247 0.0007988135 #> 691  P1000691    0010 0.8634421    0010 0.8279455 0.0028821687 #> 692  P1000692    0001 0.6687797    0000 0.7762431 0.0068923590 #> 693  P1000693    0101 0.6746320    0111 0.4930822 0.0054664576 #> 694  P1000694    0001 0.6053504    0000 0.6934373 0.0067317613 #> 695  P1000695    0101 0.9644368    0101 0.9475309 0.0064825470 #> 696  P1000696    0000 0.4848045    0000 0.9164606 0.0067890487 #> 697  P1000697    1000 0.8289361    0000 0.8850660 0.1080350368 #> 698  P1000698    0010 0.5999068    0010 0.4912137 0.0157465666 #> 699  P1000699    0100 0.5566640    0100 0.5240657 0.0018514859 #> 700  P1000700    0100 0.4874547    0100 0.7365190 0.0587432667 #> 701  P1000701    1011 0.9352637    1011 0.8216680 0.9798966031 #> 702  P1000702    0000 0.7812679    0000 0.9803424 0.0005662810 #> 703  P1000703    0101 0.6149068    0111 0.5276475 0.0513686908 #> 704  P1000704    0000 0.6989474    0000 0.9347917 0.0005447987 #> 705  P1000705    1110 0.4937392    1111 0.6614127 0.9981609369 #> 706  P1000706    0010 0.7514150    0010 0.8470149 0.0024183191 #> 707  P1000707    0000 0.8927890    0000 0.9898609 0.0005653722 #> 708  P1000708    0001 0.7850017    0000 0.7853981 0.0005807271 #> 709  P1000709    1111 0.8942349    1111 0.9747246 0.9986389269 #> 710  P1000710    0000 0.5309588    0000 0.9519824 0.0094485994 #> 711  P1000711    0111 0.8843963    0111 0.9150738 0.0316259028 #> 712  P1000712    0010 0.7531333    0000 0.4977257 0.0025056268 #> 713  P1000713    1110 0.5239280    1111 0.5903972 0.9963131361 #> 714  P1000714    0000 0.7812679    0000 0.9803424 0.0005662810 #> 715  P1000715    1111 0.9798888    1111 0.9960851 0.9984034372 #> 716  P1000716    1010 0.9330035    1010 0.7820879 0.8065444221 #> 717  P1000717    0111 0.7079287    0111 0.7487440 0.0208364013 #> 718  P1000718    0010 0.3611856    0000 0.7568027 0.0082121513 #> 719  P1000719    0000 0.9282932    0000 0.9927706 0.0005653600 #> 720  P1000720    1001 0.6775810    0001 0.4643624 0.2432816314 #> 721  P1000721    0010 0.8998024    0010 0.9650171 0.0018692537 #> 722  P1000722    1110 0.8903084    1110 0.7029903 0.9708285202 #> 723  P1000723    1001 0.8457611    1001 0.6344224 0.9485747024 #> 724  P1000724    0000 0.8872653    0000 0.9825946 0.0005613861 #> 725  P1000725    0000 0.6470421    0000 0.9289599 0.0005454399 #> 726  P1000726    1001 0.5271034    0001 0.4403920 0.0663557087 #> 727  P1000727    0000 0.7293857    0000 0.9758475 0.0038118734 #> 728  P1000728    1111 0.9811121    1111 0.9968864 0.9984810816 #> 729  P1000729    0000 0.7080554    0000 0.9866667 0.0067102673 #> 730  P1000730    0001 0.7649721    0000 0.8049462 0.0005792785 #> 731  P1000731    0000 0.9282932    0000 0.9927706 0.0005653600 #> 732  P1000732    0010 0.7525064    0010 0.8447209 0.0024160546 #> 733  P1000733    1000 0.6642869    0000 0.7112746 0.2145021785 #> 734  P1000734    0000 0.6787328    0000 0.9423833 0.0005508845 #> 735  P1000735    0010 0.5036036    0000 0.7902812 0.0018213039 #> 736  P1000736    0000 0.4962052    0000 0.9500985 0.0067120927 #> 737  P1000737    0000 0.7964507    0000 0.9679898 0.0018112151 #> 738  P1000738    0001 0.8246897    0001 0.4964776 0.0061530588 #> 739  P1000739    0000 0.3983603    0000 0.9263338 0.0067300128 #> 740  P1000740    1111 0.8651588    1111 0.9667779 0.9984783630 #> 741  P1000741    0110 0.6113799    0110 0.4583380 0.0003556592 #> 742  P1000742    0110 0.4780191    0010 0.5442421 0.0001810192 #> 743  P1000743    1111 0.9338170    1111 0.9875029 0.9984446664 #> 744  P1000744    0000 0.6804043    0000 0.9624649 0.0008006940 #> 745  P1000745    0101 0.9502877    0101 0.9317083 0.0073820397 #> 746  P1000746    1111 0.7880733    1111 0.9895554 0.9985633055 #> 747  P1000747    1110 0.6247183    1110 0.5240782 0.6455275019 #> 748  P1000748    1010 0.6356015    0010 0.6714742 0.2409280676 #> 749  P1000749    0001 0.6860807    0000 0.8059173 0.0008405061 #> 750  P1000750    1000 0.6682169    0000 0.9461917 0.0439961939 #> 751  P1000751    0100 0.3638373    0000 0.8619452 0.0162202378 #> 752  P1000752    0000 0.8927890    0000 0.9898609 0.0005653722 #> 753  P1000753    1111 0.6807760    1111 0.8346416 0.8387170822 #> 754  P1000754    0000 0.5348349    0000 0.9586757 0.0067116646 #> 755  P1000755    1000 0.8911317    0000 0.7654173 0.2080591229 #> 756  P1000756    0010 0.4361013    0000 0.7932763 0.0057892728 #> 757  P1000757    0100 0.3116120    0100 0.6021164 0.0646808229 #> 758  P1000758    1110 0.6535106    1111 0.7085078 0.9998277996 #> 759  P1000759    1000 0.7285287    0000 0.9062972 0.0725219142 #> 760  P1000760    0000 0.7964507    0000 0.9679898 0.0018112151 #> 761  P1000761    0010 0.3567183    0000 0.6255816 0.0131202965 #> 762  P1000762    0000 0.5468626    0000 0.9116578 0.0063674844 #> 763  P1000763    0010 0.8195020    0010 0.7330043 0.0021381355 #> 764  P1000764    0111 0.5590021    0111 0.7730528 0.0213586524 #> 765  P1000765    1010 0.8672077    1010 0.8294412 0.9978798275 #> 766  P1000766    0000 0.9282932    0000 0.9927706 0.0005653600 #> 767  P1000767    1111 0.9838947    1111 0.9982173 0.9998720377 #> 768  P1000768    0000 0.8743368    0000 0.9882626 0.0005653790 #> 769  P1000769    0000 0.5800606    0000 0.9046546 0.0008683551 #> 770  P1000770    0000 0.9282932    0000 0.9927706 0.0005653600 #> 771  P1000771    0000 0.5785747    0000 0.9191098 0.0005459594 #> 772  P1000772    0010 0.6702493    0000 0.5616826 0.0015520367 #> 773  P1000773    1010 0.8208440    1010 0.8300784 0.9721731823 #> 774  P1000774    0001 0.4005422    0001 0.4181136 0.0227895955 #> 775  P1000775    0111 0.9645253    0111 0.9759722 0.0029310391 #> 776  P1000776    0100 0.6794738    0000 0.8472275 0.0005661125 #> 777  P1000777    1111 0.9360058    1111 0.9789632 0.9817572972 #> 778  P1000778    1000 0.4287573    0000 0.8928755 0.0487436587 #> 779  P1000779    0000 0.8743368    0000 0.9882626 0.0005653790 #> 780  P1000780    0110 0.5357517    0110 0.5025473 0.0259116528 #> 781  P1000781    0000 0.7300813    0000 0.9602715 0.0008237620 #> 782  P1000782    1111 0.9773416    1111 0.9959061 0.9982968479 #> 783  P1000783    1000 0.5057397    0000 0.9482153 0.0222025561 #> 784  P1000784    0000 0.7155833    0000 0.9732810 0.0005668043 #> 785  P1000785    1111 0.9866593    1111 0.9965154 0.9984845732 #> 786  P1000786    0000 0.5539239    0000 0.9217792 0.0005504543 #> 787  P1000787    0000 0.4902297    0000 0.9489688 0.0065064802 #> 788  P1000788    0011 0.5343819    0010 0.7061714 0.0024798933 #> 789  P1000789    1100 0.8895724    1100 0.8334613 0.9958136618 #> 790  P1000790    0111 0.8183390    0111 0.6905889 0.3034068323 #> 791  P1000791    0010 0.6940056    0010 0.4933258 0.0018428294 #> 792  P1000792    0000 0.8500130    0000 0.9863794 0.0005655706 #> 793  P1000793    0100 0.5055338    0100 0.7434630 0.0060974692 #> 794  P1000794    0000 0.6975588    0000 0.9200437 0.0005362753 #> 795  P1000795    1110 0.8444039    1110 0.7303626 0.9960896851 #> 796  P1000796    0011 0.7324954    0011 0.7156392 0.0272634786 #> 797  P1000797    0000 0.7537781    0000 0.9500998 0.0005500468 #> 798  P1000798    0000 0.4580857    0000 0.8962556 0.0066858593 #> 799  P1000799    0000 0.7080554    0000 0.9866667 0.0067102673 #> 800  P1000800    0011 0.5095948    0011 0.6523477 0.2877183714 #> 801  P1000801    0010 0.7507007    0010 0.9427481 0.0278892560 #> 802  P1000802    0010 0.9064654    0010 0.9413896 0.0018673940 #> 803  P1000803    1000 0.7052402    1000 0.6718765 0.9561223542 #> 804  P1000804    1000 0.4688084    0000 0.5406614 0.0543623619 #> 805  P1000805    0010 0.5818501    0010 0.7956679 0.0077379735 #> 806  P1000806    0000 0.6082734    0000 0.9708370 0.0091647807 #> 807  P1000807    1111 0.7358549    1111 0.9638576 0.9986660382 #> 808  P1000808    0000 0.7361847    0000 0.9756201 0.0005666309 #> 809  P1000809    0000 0.5675920    0000 0.9148579 0.0061696961 #> 810  P1000810    0001 0.6411735    0001 0.4512001 0.0006039048 #> 811  P1000811    0010 0.8664862    0010 0.9552670 0.0025696422 #> 812  P1000812    0100 0.4638348    0000 0.6417334 0.0265402448 #> 813  P1000813    0000 0.6989708    0000 0.9711226 0.0005666553 #> 814  P1000814    1000 0.4416602    0000 0.9372252 0.0212440998 #> 815  P1000815    0000 0.7117645    0000 0.9727170 0.0005666466 #> 816  P1000816    1000 0.8076813    0000 0.9159021 0.0779498286 #> 817  P1000817    0000 0.4361474    0000 0.9347999 0.0040780180 #> 818  P1000818    0111 0.9296249    0111 0.9602132 0.0023913674 #> 819  P1000819    0001 0.7484117    0000 0.6146251 0.0053947465 #> 820  P1000820    0000 0.6491560    0000 0.9141575 0.0005364903 #> 821  P1000821    0000 0.7945936    0000 0.9543939 0.0005500125 #> 822  P1000822    0000 0.6549616    0000 0.9392131 0.0005509128 #> 823  P1000823    0000 0.9282932    0000 0.9927706 0.0005653600 #> 824  P1000824    1111 0.3762709    1111 0.6632598 0.7994634388 #> 825  P1000825    0000 0.6993881    0000 0.9863499 0.0070291677 #> 826  P1000826    0010 0.4174341    0000 0.7727544 0.0011389529 #> 827  P1000827    1111 0.8082649    1111 0.9695062 0.9982954196 #> 828  P1000828    0010 0.6892591    0000 0.6501465 0.0004283389 #> 829  P1000829    1000 0.3677150    0000 0.7160118 0.0326954601 #> 830  P1000830    1111 0.6708758    1111 0.8198124 0.8200536722 #> 831  P1000831    1111 0.9059556    1111 0.9774433 0.9984487180 #> 832  P1000832    1110 0.5335360    1111 0.6809776 0.9735681869 #> 833  P1000833    0000 0.7138207    0000 0.9868733 0.0065023196 #> 834  P1000834    0111 0.9139912    0111 0.9168102 0.0301621212 #> 835  P1000835    1000 0.5893154    0000 0.6176272 0.0864749086 #> 836  P1000836    0000 0.7193428    0000 0.9814456 0.0038389835 #> 837  P1000837    1111 0.8620459    1111 0.9678265 0.9998679201 #> 838  P1000838    1111 0.9598263    1111 0.9825032 0.9827684581 #> 839  P1000839    1111 0.4217841    1111 0.6973649 0.8034086967 #> 840  P1000840    0010 0.3160926    0000 0.7605720 0.0034670918 #> 841  P1000841    1001 0.5678210    0001 0.6700543 0.0832416492 #> 842  P1000842    1111 0.8583916    1111 0.9668388 0.9998672207 #> 843  P1000843    0000 0.8309927    0000 0.9778750 0.0007988070 #> 844  P1000844    0100 0.4159585    0000 0.7059003 0.0011338678 #> 845  P1000845    1111 0.8650316    1111 0.9666492 0.9984288796 #> 846  P1000846    0100 0.6129824    0000 0.8351336 0.0022208486 #> 847  P1000847    1111 0.9327810    1111 0.9788512 0.9825002607 #> 848  P1000848    0000 0.7576885    0000 0.9859370 0.0038387685 #> 849  P1000849    0000 0.7359227    0000 0.9617702 0.0018118864 #> 850  P1000850    1111 0.9037831    1111 0.9773618 0.9986427319 #> 851  P1000851    0000 0.7565539    0000 0.9766102 0.0005655825 #> 852  P1000852    0000 0.4527370    0000 0.8297501 0.0010543841 #> 853  P1000853    1111 0.8869433    1111 0.9746018 0.9985525938 #> 854  P1000854    0000 0.8927890    0000 0.9898609 0.0005653722 #> 855  P1000855    0000 0.9282932    0000 0.9927706 0.0005653600 #> 856  P1000856    1000 0.6439497    0000 0.8648981 0.0747075840 #> 857  P1000857    0000 0.5978045    0000 0.9546433 0.0005657239 #> 858  P1000858    0000 0.4852453    0000 0.8852378 0.0005368399 #> 859  P1000859    0010 0.7026147    0010 0.8863573 0.0273941421 #> 860  P1000860    0000 0.8800457    0000 0.9823247 0.0007988135 #> 861  P1000861    1010 0.9292315    1010 0.7600233 0.8062053541 #> 862  P1000862    1011 0.6112086    1011 0.8852585 0.9972240968 #> 863  P1000863    1011 0.9084012    1011 0.8085071 0.9829786709 #> 864  P1000864    0100 0.3576982    0000 0.6895131 0.0004912674 #> 865  P1000865    0000 0.7193428    0000 0.9814456 0.0038389835 #> 866  P1000866    0000 0.5070868    0000 0.9528797 0.0065062629 #> 867  P1000867    0010 0.7897240    0010 0.8297953 0.0227605589 #> 868  P1000868    0010 0.7273216    0000 0.4988601 0.0003702594 #> 869  P1000869    0110 0.9375559    0110 0.9454457 0.0022885018 #> 870  P1000870    0000 0.9282932    0000 0.9927706 0.0005653600 #> 871  P1000871    1010 0.7134292    0010 0.7260240 0.2636864183 #> 872  P1000872    0000 0.7361847    0000 0.9756201 0.0005666309 #> 873  P1000873    0010 0.7629647    0010 0.9466223 0.0279380051 #> 874  P1000874    0000 0.6129665    0000 0.9604363 0.0008986971 #> 875  P1000875    0010 0.3188115    0000 0.7714894 0.0213262782 #> 876  P1000876    0111 0.9452770    0111 0.9818684 0.0021220687 #> 877  P1000877    1111 0.7950505    1111 0.9881727 0.9980463956 #> 878  P1000878    0000 0.6096313    0000 0.9122609 0.0046029849 #> 879  P1000879    0000 0.6989708    0000 0.9711226 0.0005666553 #> 880  P1000880    0111 0.5097944    0111 0.5594361 0.0016119671 #> 881  P1000881    0000 0.7481017    0000 0.9615633 0.0005571424 #> 882  P1000882    0010 0.8594290    0010 0.6860286 0.0020286885 #> 883  P1000883    0011 0.3439814    0111 0.4568351 0.3032421732 #> 884  P1000884    0000 0.4167322    0000 0.8617809 0.0117091144 #> 885  P1000885    0111 0.7478306    0111 0.6898186 0.2860677632 #> 886  P1000886    0001 0.9023619    0001 0.8386370 0.0006151855 #> 887  P1000887    0010 0.6230747    0000 0.6471134 0.0050915492 #> 888  P1000888    0101 0.3874928    0111 0.5108271 0.0002905953 #> 889  P1000889    1000 0.7954531    0000 0.9132162 0.0779513853 #> 890  P1000890    0000 0.9282932    0000 0.9927706 0.0005653600 #> 891  P1000891    0001 0.4947287    0000 0.7215062 0.0018559563 #> 892  P1000892    0000 0.7576885    0000 0.9859370 0.0038387685 #> 893  P1000893    0100 0.8732978    0100 0.5385926 0.0036041765 #> 894  P1000894    1000 0.4346793    0000 0.9317361 0.0222518054 #> 895  P1000895    0000 0.5905408    0000 0.8767153 0.0009908226 #> 896  P1000896    0000 0.9282932    0000 0.9927706 0.0005653600 #> 897  P1000897    0010 0.4992733    0010 0.8137896 0.0019068834 #> 898  P1000898    1110 0.4764513    1110 0.5228087 0.9912367932 #> 899  P1000899    0000 0.6885021    0000 0.9632729 0.0005628098 #> 900  P1000900    1111 0.9642037    1111 0.9945124 0.9986750553 #> 901  P1000901    0111 0.9289346    0111 0.9688395 0.0001937527 #> 902  P1000902    1010 0.8659547    1010 0.6788962 0.7299487929 #> 903  P1000903    1000 0.7360498    0000 0.9031623 0.0757300067 #> 904  P1000904    0000 0.9020697    0000 0.9914361 0.0008358458 #> 905  P1000905    0000 0.6654502    0000 0.9646077 0.0005654785 #> 906  P1000906    0000 0.7080554    0000 0.9866667 0.0067102673 #> 907  P1000907    0000 0.5347872    0000 0.9309935 0.0018123124 #> 908  P1000908    0100 0.6625230    0000 0.6494121 0.0024178087 #> 909  P1000909    1111 0.9941190    1111 0.9982281 0.9984870134 #> 910  P1000910    0000 0.9282932    0000 0.9927706 0.0005653600 #> 911  P1000911    0000 0.8878243    0000 0.9894369 0.0005653740 #> 912  P1000912    0000 0.7945936    0000 0.9543939 0.0005500125 #> 913  P1000913    0000 0.5468626    0000 0.9116578 0.0063674844 #> 914  P1000914    0000 0.5932980    0000 0.9138313 0.0036418719 #> 915  P1000915    0110 0.4764084    0110 0.4453690 0.1979600290 #> 916  P1000916    1100 0.8762272    1100 0.4937123 0.9945372906 #> 917  P1000917    0100 0.8591474    0100 0.5899983 0.0039074917 #> 918  P1000918    0010 0.7351365    0010 0.7794779 0.0233041669 #> 919  P1000919    0000 0.9282932    0000 0.9927706 0.0005653600 #> 920  P1000920    1001 0.4324221    0001 0.4982948 0.0676204347 #> 921  P1000921    0000 0.3512104    0000 0.8221457 0.0130380935 #> 922  P1000922    0000 0.5638893    0000 0.9146762 0.0063670745 #> 923  P1000923    0011 0.6461754    0011 0.4470079 0.0112008609 #> 924  P1000924    0011 0.5770077    0011 0.4700397 0.0133360802 #> 925  P1000925    1111 0.9548360    1111 0.9820406 0.9839271454 #> 926  P1000926    0000 0.7540634    0000 0.9408216 0.0005445847 #> 927  P1000927    0000 0.7200332    0000 0.9583250 0.0005571652 #> 928  P1000928    1010 0.5929871    0010 0.3741950 0.2411221334 #> 929  P1000929    0110 0.3881979    0111 0.4122674 0.0249640284 #> 930  P1000930    1111 0.8164891    1111 0.9566707 0.9998647430 #> 931  P1000931    0000 0.9282932    0000 0.9927706 0.0005653600 #> 932  P1000932    1111 0.9702778    1111 0.9953689 0.9983953998 #> 933  P1000933    1110 0.4777458    1110 0.5615966 0.9691311339 #> 934  P1000934    1111 0.6480532    1111 0.9207238 0.9837644879 #> 935  P1000935    0010 0.6574088    0010 0.8346857 0.0423681269 #> 936  P1000936    0000 0.7325251    0000 0.9830379 0.0038389073 #> 937  P1000937    0101 0.7475752    0101 0.5549036 0.0077833654 #> 938  P1000938    1111 0.7656652    1111 0.9737267 0.9823426469 #> 939  P1000939    0010 0.7369208    0010 0.9193584 0.0274205216 #> 940  P1000940    0011 0.4248609    0010 0.5642888 0.0215484523 #> 941  P1000941    0010 0.7345548    0000 0.5668334 0.0015540192 #> 942  P1000942    0010 0.3698104    0000 0.7600576 0.0008240283 #> 943  P1000943    0000 0.7565539    0000 0.9766102 0.0005655825 #> 944  P1000944    0100 0.5548431    0000 0.8293206 0.0013858738 #> 945  P1000945    0110 0.9468729    0110 0.9148369 0.0001706061 #> 946  P1000946    0000 0.9020697    0000 0.9914361 0.0008358458 #> 947  P1000947    1111 0.4192301    1111 0.7943164 0.9692845181 #> 948  P1000948    0000 0.7155833    0000 0.9732810 0.0005668043 #> 949  P1000949    0001 0.7816691    0000 0.6654463 0.0005771856 #> 950  P1000950    1000 0.6579908    0000 0.9367735 0.0437002905 #> 951  P1000951    0000 0.3761596    0000 0.8608793 0.0180104829 #> 952  P1000952    0011 0.8089118    0011 0.7427845 0.0027719419 #> 953  P1000953    0100 0.9027894    0100 0.6131801 0.0005689384 #> 954  P1000954    0001 0.4315006    0000 0.8807375 0.0040507759 #> 955  P1000955    0000 0.6215984    0000 0.9121439 0.0005372676 #> 956  P1000956    0000 0.5902171    0000 0.9072086 0.0007941461 #> 957  P1000957    0000 0.6975588    0000 0.9200437 0.0005362753 #> 958  P1000958    1111 0.9789862    1111 0.9977218 0.9998724183 #> 959  P1000959    1111 0.9877654    1111 0.9967845 0.9985321715 #> 960  P1000960    0000 0.9282932    0000 0.9927706 0.0005653600 #> 961  P1000961    1110 0.6483400    1111 0.7062299 0.9979928789 #> 962  P1000962    0000 0.5445402    0000 0.9107753 0.0061702333 #> 963  P1000963    0010 0.6143040    0000 0.6398793 0.0004289690 #> 964  P1000964    0001 0.7850017    0000 0.7853981 0.0005807271 #> 965  P1000965    0101 0.6719850    0101 0.3806610 0.0076672511 #> 966  P1000966    0010 0.8862591    0010 0.8301469 0.0002309276 #> 967  P1000967    0000 0.7117645    0000 0.9727170 0.0005666466 #> 968  P1000968    0111 0.7139610    0111 0.7760184 0.0242355932 #> 969  P1000969    0000 0.5212701    0000 0.9421989 0.0010777585 #> 970  P1000970    0110 0.6795218    0110 0.7649210 0.1840290991 #> 971  P1000971    0000 0.8800457    0000 0.9823247 0.0007988135 #> 972  P1000972    1101 0.7784202    1111 0.8842568 0.9997171357 #> 973  P1000973    0010 0.6940056    0010 0.4933258 0.0018428294 #> 974  P1000974    0000 0.5912252    0000 0.9709972 0.0067213307 #> 975  P1000975    0000 0.7481017    0000 0.9615633 0.0005571424 #> 976  P1000976    0000 0.5259698    0000 0.8428973 0.0010523073 #> 977  P1000977    1111 0.9544796    1111 0.9810086 0.9819315031 #> 978  P1000978    0000 0.4178932    0000 0.9061062 0.0005591313 #> 979  P1000979    0010 0.6304870    0010 0.5594970 0.0207831671 #> 980  P1000980    1000 0.6497798    1000 0.7443040 0.8678010479 #> 981  P1000981    0001 0.6728006    0000 0.8232751 0.0005665587 #> 982  P1000982    1111 0.5872173    1111 0.8679200 0.9998525942 #> 983  P1000983    0001 0.6953883    0000 0.8071269 0.0005676583 #> 984  P1000984    0110 0.5735777    0110 0.5505366 0.1782432855 #> 985  P1000985    0000 0.7540634    0000 0.9408216 0.0005445847 #> 986  P1000986    0100 0.7789881    0000 0.6129656 0.0005452231 #> 987  P1000987    0110 0.9791692    0110 0.9741184 0.0018823485 #> 988  P1000988    1111 0.9287272    1111 0.9776399 0.9811303775 #> 989  P1000989    0000 0.5923462    0000 0.9557367 0.0066133234 #> 990  P1000990    0001 0.6098091    0000 0.8023130 0.0065285947 #> 991  P1000991    0101 0.9155589    0101 0.7999032 0.0006319023 #> 992  P1000992    0000 0.7234958    0000 0.9587369 0.0005571623 #> 993  P1000993    1111 0.3807391    1111 0.8306354 0.9973371810 #> 994  P1000994    0101 0.6712957    0101 0.4284992 0.0006175669 #> 995  P1000995    0000 0.6754253    0000 0.9762841 0.0069800770 #> 996  P1000996    0010 0.8862591    0010 0.8301469 0.0002309276 #> 997  P1000997    0100 0.7907016    0100 0.8593407 0.0041566469 #> 998  P1000998    0000 0.6993881    0000 0.9863499 0.0070291677 #> 999  P1000999    0100 0.4000176    0000 0.4189349 0.0057324173 #> 1000 P1001000    0010 0.6621689    0000 0.5672144 0.0069611236 #>        post.attr2  post.attr3  post.attr4 #> 1    0.6514881225 0.035150582 0.971302786 #> 2    0.0107672033 0.999794858 0.936926366 #> 3    0.9828893114 0.626429305 0.978044317 #> 4    0.0004327554 0.005121344 0.001098307 #> 5    0.0006620112 0.314809026 0.741864979 #> 6    0.2925355687 0.250887856 0.003257354 #> 7    0.9579821075 0.999944997 0.039302741 #> 8    0.0392505038 0.754486183 0.020909895 #> 9    0.0122348973 0.005365168 0.833024605 #> 10   0.0050263779 0.005147985 0.013656279 #> 11   0.0110318711 0.925242689 0.946173669 #> 12   0.9973208904 0.953250807 0.999894378 #> 13   0.0752470910 0.016476126 0.495270510 #> 14   0.9996203258 0.999533548 0.996232497 #> 15   0.0004316733 0.015412189 0.001098978 #> 16   0.5805682511 0.004564928 0.218812044 #> 17   0.0050266399 0.005126476 0.013666705 #> 18   0.0046697940 0.005326803 0.265216218 #> 19   0.0716549320 0.944097299 0.069248065 #> 20   0.0033944921 0.028817597 0.018462449 #> 21   0.0112500811 0.998338107 0.798491762 #> 22   0.9989476380 0.798364751 0.999756340 #> 23   0.9998172518 0.999908556 0.703196331 #> 24   0.0007664296 0.015078296 0.004743039 #> 25   0.5310478620 0.004502870 0.014178583 #> 26   0.9999798484 0.999996582 0.704236024 #> 27   0.4818204100 0.265695299 0.027032460 #> 28   0.0033623759 0.005141124 0.001100228 #> 29   0.0059236066 0.015704243 0.001104422 #> 30   0.0004287568 0.043602023 0.001103228 #> 31   0.9998400341 0.998731563 0.019121267 #> 32   0.9986735326 0.991982788 0.019080775 #> 33   0.0116773757 0.005129836 0.001108355 #> 34   0.0003995357 0.326628131 0.001149393 #> 35   0.9996209721 0.999503294 0.999781328 #> 36   0.1837032216 0.517483381 0.001375255 #> 37   0.9372335378 0.991516701 0.997590679 #> 38   0.9953242523 0.999863189 0.904886892 #> 39   0.9980413508 0.999455482 0.999868079 #> 40   0.0033541008 0.015699948 0.001103117 #> 41   0.9992947201 0.999774199 0.124417905 #> 42   0.0015391137 0.028812331 0.013663068 #> 43   0.0004302944 0.028770488 0.001101155 #> 44   0.0037545614 0.043568550 0.001106466 #> 45   0.0003552849 0.753937675 0.001211446 #> 46   0.0055473763 0.805580424 0.015018691 #> 47   0.0004327347 0.005144710 0.001097383 #> 48   0.0005344310 0.354991114 0.400078195 #> 49   0.0037002691 0.138987274 0.011157900 #> 50   0.0003309124 0.995020166 0.001290839 #> 51   0.8222996979 0.341358730 0.089164145 #> 52   0.0065666033 0.003516099 0.123597062 #> 53   0.0096496368 0.164759328 0.556679067 #> 54   0.0003973349 0.347501435 0.001150100 #> 55   0.0066735177 0.015791354 0.001105177 #> 56   0.0548884191 0.003421891 0.130209098 #> 57   0.0047004052 0.005170578 0.045029182 #> 58   0.0035264711 0.005167316 0.056494154 #> 59   0.0004172187 0.155160763 0.001120270 #> 60   0.8210883657 0.926850256 0.012676475 #> 61   0.0028335300 0.353262285 0.021734558 #> 62   0.0949190915 0.005312099 0.442994491 #> 63   0.0004375259 0.005153585 0.013602339 #> 64   0.1199545223 0.015012594 0.001215415 #> 65   0.0040126648 0.042642021 0.078640642 #> 66   0.0049715865 0.005139155 0.001101790 #> 67   0.0075080884 0.631546839 0.446514055 #> 68   0.1228691608 0.772503439 0.001348929 #> 69   0.0037894502 0.005118406 0.001101523 #> 70   0.1141353517 0.015002904 0.003275838 #> 71   0.0014998142 0.043583331 0.001104309 #> 72   0.9790100408 0.550624463 0.998785358 #> 73   0.6164196684 0.004270095 0.009412167 #> 74   0.8617404371 0.976770213 0.015189089 #> 75   0.0033625360 0.005117774 0.001101154 #> 76   0.2641415400 0.815633585 0.001515755 #> 77   0.9978175645 0.999885043 0.999877743 #> 78   0.0042522010 0.028935620 0.003856107 #> 79   0.1066486444 0.246647996 0.047467586 #> 80   0.0004393716 0.005134644 0.018368320 #> 81   0.0015300122 0.015447732 0.013635446 #> 82   0.0004287568 0.043602023 0.001103228 #> 83   0.0138617920 0.207926610 0.128264875 #> 84   0.0014135157 0.326442818 0.001147583 #> 85   0.0004341389 0.005135443 0.004735277 #> 86   0.0035610824 0.257761509 0.001139133 #> 87   0.0074604279 0.999437092 0.135821139 #> 88   0.0042696555 0.005141882 0.003742391 #> 89   0.0033577962 0.057023526 0.013743694 #> 90   0.0004878402 0.029524625 0.152793782 #> 91   0.0038671441 0.979460311 0.015987385 #> 92   0.0004327347 0.005144710 0.001097383 #> 93   0.7711427590 0.999867956 0.998577064 #> 94   0.0442458508 0.093342606 0.011354251 #> 95   0.0004327554 0.005121344 0.001098307 #> 96   0.0321635607 0.028584389 0.004020813 #> 97   0.0004327537 0.005123248 0.001098231 #> 98   0.9998659939 0.999799576 0.983886322 #> 99   0.0015287237 0.756264129 0.022944102 #> 100  0.1254409452 0.004989791 0.083778903 #> 101  0.1001598130 0.076850545 0.060112586 #> 102  0.0154105310 0.088480054 0.158407186 #> 103  0.0032478130 0.431723782 0.001165548 #> 104  0.9862049508 0.064943980 0.996848636 #> 105  0.0117746013 0.997553885 0.725282368 #> 106  0.2360151619 0.999851003 0.982093958 #> 107  0.0004327347 0.005144710 0.001097383 #> 108  0.5016234162 0.004532244 0.003025511 #> 109  0.4192228058 0.409227585 0.014320690 #> 110  0.1964796333 0.005230506 0.500204086 #> 111  0.1611066397 0.032819530 0.001263898 #> 112  0.0484555732 0.005125794 0.060127373 #> 113  0.0059208529 0.015637159 0.001105288 #> 114  0.0047010074 0.005146968 0.045065435 #> 115  0.0015831537 0.152498734 0.001121040 #> 116  0.9338266759 0.982769844 0.003124589 #> 117  0.9997979368 0.985024538 0.978875924 #> 118  0.1232702337 0.686751079 0.043077585 #> 119  0.9956085597 0.999513981 0.983908365 #> 120  0.3025252381 0.014322423 0.006479347 #> 121  0.0042696555 0.005141882 0.003742391 #> 122  0.0004391751 0.015743694 0.020760070 #> 123  0.9999847570 0.999997677 0.998744895 #> 124  0.0007640737 0.015104901 0.001099232 #> 125  0.6188543438 0.094335612 0.626129668 #> 126  0.0039741251 0.005166776 0.056514259 #> 127  0.0049718037 0.005117715 0.001102642 #> 128  0.5805986273 0.004725571 0.514591198 #> 129  0.0042696555 0.005141882 0.003742391 #> 130  0.0044034584 0.497495405 0.005066022 #> 131  0.0039741251 0.005166776 0.056514259 #> 132  0.8155705379 0.501469482 0.496751466 #> 133  0.0003926299 0.593762221 0.064929376 #> 134  0.0004339940 0.027428861 0.010485774 #> 135  0.0052274924 0.747029115 0.022884601 #> 136  0.0030260108 0.850443158 0.001232108 #> 137  0.9995929278 0.882828666 0.997895809 #> 138  0.9998669481 0.999763084 0.998746778 #> 139  0.0006075294 0.034044692 0.468991565 #> 140  0.0037574936 0.055580616 0.004996541 #> 141  0.0038002683 0.027407611 0.010516239 #> 142  0.1028350570 0.951235936 0.046581851 #> 143  0.0003615786 0.693093884 0.001202228 #> 144  0.0004287568 0.043602023 0.001103228 #> 145  0.0004362205 0.043715398 0.020815522 #> 146  0.1447425658 0.015180384 0.003260201 #> 147  0.0047009583 0.005148892 0.045062480 #> 148  0.0004043931 0.315783586 0.012137482 #> 149  0.9997400062 0.999281554 0.974578751 #> 150  0.0004375488 0.005132053 0.013612721 #> 151  0.0004341389 0.005135443 0.004735277 #> 152  0.9941907823 0.921915739 0.966559354 #> 153  0.9840654665 0.998672075 0.015642861 #> 154  0.0970098072 0.070306144 0.004662115 #> 155  0.0420529660 0.005093769 0.001137795 #> 156  0.9005981452 0.425993943 0.012678269 #> 157  0.0043581121 0.043550124 0.016088010 #> 158  0.0144873023 0.005129086 0.003334373 #> 159  0.0012578294 0.744624199 0.014605174 #> 160  0.9989420622 0.999657256 0.976367388 #> 161  0.9994044180 0.936770715 0.981245130 #> 162  0.9998021091 0.999711742 0.967644377 #> 163  0.0004375508 0.005130142 0.013613643 #> 164  0.0003875442 0.463360263 0.001303448 #> 165  0.0034792501 0.348305995 0.001152652 #> 166  0.0004327347 0.005144710 0.001097383 #> 167  0.0004327554 0.005121344 0.001098307 #> 168  0.0004316733 0.015412189 0.001098978 #> 169  0.0089374720 0.083785764 0.001121087 #> 170  0.0356984442 0.077434922 0.004069490 #> 171  0.0004251962 0.078024342 0.001108460 #> 172  0.0003494467 0.810379097 0.001220030 #> 173  0.0004043931 0.315783586 0.012137482 #> 174  0.0003511587 0.811079602 0.006071978 #> 175  0.7028700665 0.975157325 0.131834896 #> 176  0.0004252474 0.077695822 0.001109293 #> 177  0.0380141017 0.015317518 0.021400772 #> 178  0.8498366038 0.999932323 0.996926863 #> 179  0.0004323209 0.028903109 0.005497262 #> 180  0.9758602689 0.999954998 0.999856862 #> 181  0.0409487426 0.028648822 0.120820182 #> 182  0.0374774217 0.005099369 0.001133352 #> 183  0.9997601359 0.999972186 0.969241873 #> 184  0.2269682625 0.004849843 0.005784438 #> 185  0.0309122825 0.052457016 0.003345154 #> 186  0.1332551331 0.004979352 0.001226573 #> 187  0.0003345340 0.996356418 0.016039338 #> 188  0.0066704177 0.015723904 0.001106042 #> 189  0.0065751552 0.881899142 0.767419342 #> 190  0.0004329822 0.004864971 0.001108440 #> 191  0.0004353248 0.043701792 0.018449953 #> 192  0.9998926342 0.999918587 0.981922014 #> 193  0.9804897338 0.993316725 0.975261146 #> 194  0.0003700878 0.656156601 0.014480984 #> 195  0.9967122842 0.999997256 0.998721228 #> 196  0.0004327347 0.005144710 0.001097383 #> 197  0.0007640737 0.015104901 0.001099232 #> 198  0.0037892787 0.005140602 0.001100642 #> 199  0.7638472019 0.250032738 0.002952527 #> 200  0.0004251962 0.078024342 0.001108460 #> 201  0.0004327544 0.005122497 0.001098261 #> 202  0.0004302944 0.028770488 0.001101155 #> 203  0.0852529758 0.005693221 0.983214048 #> 204  0.0061996794 0.926870893 0.001244224 #> 205  0.0016192659 0.005122843 0.018393816 #> 206  0.9928243964 0.996825692 0.121420826 #> 207  0.8303844369 0.999941393 0.030083082 #> 208  0.0004393464 0.005156957 0.018353890 #> 209  0.0004327347 0.005144710 0.001097383 #> 210  0.0034135957 0.005153331 0.018400642 #> 211  0.9985786813 0.995444966 0.811492512 #> 212  0.5775345457 0.051057418 0.219653855 #> 213  0.0004316733 0.015412189 0.001098978 #> 214  0.0033434700 0.028750912 0.001103989 #> 215  0.8568559135 0.114697044 0.011735840 #> 216  0.9543366531 0.984618252 0.003110685 #> 217  0.4064608232 0.998514099 0.021666079 #> 218  0.7872143956 0.983795310 0.998508226 #> 219  0.0099863165 0.005522718 0.551676865 #> 220  0.1020761106 0.159698463 0.447427177 #> 221  0.6667380106 0.092627765 0.015131867 #> 222  0.0004327537 0.005123248 0.001098231 #> 223  0.0004287923 0.043421009 0.001104060 #> 224  0.0049104914 0.056898217 0.001110526 #> 225  0.8300360517 0.455736729 0.695928000 #> 226  0.9659006044 0.996916692 0.959799695 #> 227  0.0852648448 0.421644065 0.001247308 #> 228  0.0004391920 0.018874955 0.021009969 #> 229  0.9999847635 0.999979539 0.999899894 #> 230  0.2168672624 0.041053854 0.176582661 #> 231  0.9998236154 0.999716776 0.998694699 #> 232  0.9542430116 0.029724128 0.901317614 #> 233  0.0385027306 0.609998139 0.216053487 #> 234  0.0724588650 0.938916929 0.473968701 #> 235  0.0004327347 0.005144710 0.001097383 #> 236  0.0073879300 0.928734716 0.213504787 #> 237  0.0004317288 0.028793874 0.004798770 #> 238  0.0047948825 0.688342598 0.005190535 #> 239  0.0017672247 0.005276298 0.190234864 #> 240  0.6118010633 0.228549265 0.015105574 #> 241  0.9878861144 0.999726081 0.968051948 #> 242  0.0115700296 0.043480823 0.001114126 #> 243  0.9973433094 0.999971715 0.865711313 #> 244  0.1809429203 0.344210511 0.396711413 #> 245  0.1226157445 0.131945893 0.191503780 #> 246  0.0030626086 0.850588343 0.015211008 #> 247  0.5057091182 0.004917703 0.681216650 #> 248  0.0081795509 0.880542848 0.011479573 #> 249  0.9926647309 0.826256776 0.982354893 #> 250  0.0033241696 0.998887021 0.170786969 #> 251  0.0003462741 0.897290110 0.020583215 #> 252  0.0049715865 0.005139155 0.001101790 #> 253  0.0099863165 0.005522718 0.551676865 #> 254  0.0030530617 0.444315905 0.010676707 #> 255  0.9419871469 0.711005194 0.440208319 #> 256  0.0323368104 0.005085576 0.004002384 #> 257  0.0451730968 0.902655014 0.001283647 #> 258  0.0251456300 0.018028044 0.040287906 #> 259  0.0004339028 0.057331819 0.018483923 #> 260  0.0137427319 0.199678245 0.034134915 #> 261  0.0037892787 0.005140602 0.001100642 #> 262  0.0132172917 0.028685436 0.001113773 #> 263  0.0038336957 0.004869045 0.013777966 #> 264  0.0561093714 0.757775686 0.001273144 #> 265  0.0060706478 0.045069492 0.266448663 #> 266  0.5862645329 0.741884906 0.770755045 #> 267  0.0084525472 0.033255998 0.410849000 #> 268  0.0471545245 0.005089564 0.004134768 #> 269  0.0098826707 0.687728109 0.994283058 #> 270  0.7783991269 0.821924163 0.328923194 #> 271  0.2440972932 0.973435102 0.269798984 #> 272  0.9998069322 0.999955539 0.998039550 #> 273  0.0038417798 0.427148952 0.003956170 #> 274  0.0033625281 0.005118926 0.001101108 #> 275  0.9666060199 0.999974103 0.961336529 #> 276  0.0004327544 0.005122497 0.001098261 #> 277  0.0469018642 0.028469353 0.004146162 #> 278  0.0044979844 0.381595933 0.544616145 #> 279  0.0006759861 0.607385444 0.934024448 #> 280  0.0048853649 0.077946255 0.001112814 #> 281  0.8376980961 0.949045878 0.039529861 #> 282  0.0004327347 0.005144710 0.001097383 #> 283  0.9993953295 0.999912139 0.935815304 #> 284  0.0048319481 0.123347859 0.001121454 #> 285  0.0541298261 0.005128926 0.074001250 #> 286  0.9980604208 0.936637615 0.999007041 #> 287  0.0082062521 0.029380484 0.008961581 #> 288  0.0088434263 0.016006147 0.013733498 #> 289  0.9976227870 0.999953133 0.989197995 #> 290  0.9778520454 0.999953659 0.998262902 #> 291  0.0144873023 0.005129086 0.003334373 #> 292  0.0067158056 0.998769317 0.016182872 #> 293  0.2386497964 0.458611199 0.257750910 #> 294  0.9956867369 0.999954432 0.999897859 #> 295  0.0038469766 0.005152803 0.018407454 #> 296  0.0064941312 0.962816762 0.015466785 #> 297  0.5907783690 0.745907136 0.052793111 #> 298  0.0033541528 0.015401558 0.001101818 #> 299  0.9747280698 0.999627780 0.999033237 #> 300  0.0033623759 0.005141124 0.001100228 #> 301  0.9999845319 0.999549056 0.979054775 #> 302  0.0037892787 0.005140602 0.001100642 #> 303  0.0003359557 0.989238158 0.016518184 #> 304  0.0003817321 0.498220467 0.001172326 #> 305  0.0120539598 0.745538989 0.995035629 #> 306  0.9998240295 0.946077156 0.756641873 #> 307  0.8614137847 0.049567438 0.998172714 #> 308  0.0004327347 0.005144710 0.001097383 #> 309  0.0004327347 0.005144710 0.001097383 #> 310  0.7285476350 0.996841091 0.498275854 #> 311  0.9932133594 0.999966419 0.992035195 #> 312  0.0004329822 0.004864971 0.001108440 #> 313  0.0004303498 0.028788321 0.001104094 #> 314  0.0048853649 0.077946255 0.001112814 #> 315  0.0055063783 0.748014843 0.082114315 #> 316  0.0049715865 0.005139155 0.001101790 #> 317  0.0005052127 0.005255504 0.190205181 #> 318  0.0011441856 0.076890905 0.010785540 #> 319  0.0007999154 0.041670993 0.977565076 #> 320  0.0004339940 0.027428861 0.010485774 #> 321  0.0015138725 0.005142416 0.001098472 #> 322  0.2807104431 0.073519635 0.051729513 #> 323  0.0038548452 0.005154467 0.020767688 #> 324  0.5010085709 0.013594195 0.003029840 #> 325  0.0004343470 0.004995002 0.004957152 #> 326  0.9998208196 0.985317688 0.019089857 #> 327  0.0042696555 0.005141882 0.003742391 #> 328  0.0006244319 0.999817665 0.998141782 #> 329  0.8866546932 0.969105535 0.870169606 #> 330  0.0027970187 0.015233532 0.001102572 #> 331  0.2264427950 0.526321536 0.016336082 #> 332  0.9998812596 0.999997676 0.998744899 #> 333  0.0004347963 0.057349413 0.020853754 #> 334  0.0004660053 0.005035821 0.087498773 #> 335  0.0050180642 0.596488779 0.191093048 #> 336  0.0004393464 0.005156957 0.018353890 #> 337  0.0004118765 0.207108670 0.001130062 #> 338  0.4831023648 0.939103371 0.169001817 #> 339  0.0011459567 0.077189943 0.010779633 #> 340  0.9993587657 0.878331770 0.999869962 #> 341  0.1265252264 0.424960633 0.089556937 #> 342  0.0105402672 0.999633242 0.284748805 #> 343  0.0127995624 0.497456147 0.003562547 #> 344  0.6063213478 0.969004636 0.352370992 #> 345  0.0004169819 0.157733041 0.001122378 #> 346  0.0004302944 0.028770488 0.001101155 #> 347  0.0049876456 0.005129887 0.004754226 #> 348  0.9322914709 0.990124327 0.002565175 #> 349  0.8656870292 0.999568914 0.444984450 #> 350  0.9996189840 0.998051733 0.782003929 #> 351  0.0038005373 0.027295723 0.010523478 #> 352  0.9970086286 0.998640391 0.983969837 #> 353  0.0034122698 0.015742867 0.020813463 #> 354  0.9998593893 0.995427029 0.998032068 #> 355  0.9943988966 0.999869705 0.038959866 #> 356  0.0059209461 0.015639429 0.001105259 #> 357  0.9436768610 0.955030482 0.584989910 #> 358  0.0039106649 0.027831384 0.043996546 #> 359  0.9999826293 0.998720594 0.998027017 #> 360  0.0004327537 0.005123248 0.001098231 #> 361  0.4250569966 0.992530022 0.146113399 #> 362  0.0042698883 0.005118521 0.003745534 #> 363  0.0004273929 0.056956528 0.001106153 #> 364  0.1266048699 0.014974919 0.011947740 #> 365  0.9998491622 0.999466082 0.985735113 #> 366  0.0004327347 0.005144710 0.001097383 #> 367  0.0033043471 0.077661813 0.001112064 #> 368  0.0029838077 0.943842828 0.016202536 #> 369  0.3655917300 0.960156356 0.020869328 #> 370  0.3927626760 0.031250486 0.980361008 #> 371  0.0375053286 0.896470361 0.004543138 #> 372  0.9984244177 0.999997230 0.708238944 #> 373  0.0132172917 0.028685436 0.001113773 #> 374  0.0037678018 0.059119752 0.006793458 #> 375  0.0004375496 0.005131299 0.013613085 #> 376  0.8310697902 0.999900249 0.065054618 #> 377  0.7084642228 0.999863229 0.987168784 #> 378  0.0004327347 0.005144710 0.001097383 #> 379  0.0004327347 0.005144710 0.001097383 #> 380  0.1184744610 0.488203528 0.001300465 #> 381  0.0073083105 0.046979216 0.001112214 #> 382  0.0149422174 0.997675398 0.970657930 #> 383  0.0042696555 0.005141882 0.003742391 #> 384  0.9986257947 0.999660284 0.998743641 #> 385  0.9880721305 0.999731534 0.999899247 #> 386  0.0478193674 0.120210685 0.003366644 #> 387  0.0017065824 0.029512076 0.152920389 #> 388  0.0143866043 0.005155393 0.040301921 #> 389  0.9364504968 0.003989537 0.016444268 #> 390  0.7678324911 0.998781563 0.964081197 #> 391  0.0004270200 0.075746115 0.005009998 #> 392  0.9970772761 0.999943650 0.997698935 #> 393  0.0218041499 0.004702514 0.001136214 #> 394  0.9996288723 0.988291079 0.989125638 #> 395  0.0049718229 0.005115813 0.001102718 #> 396  0.0034052843 0.015437837 0.018426781 #> 397  0.9342297109 0.951983644 0.002269483 #> 398  0.0004329647 0.004884688 0.001107660 #> 399  0.6205231428 0.014781771 0.009486935 #> 400  0.1447447281 0.014891447 0.003256374 #> 401  0.5934931337 0.984263382 0.998836334 #> 402  0.0004347963 0.057349413 0.020853754 #> 403  0.0037800156 0.015400009 0.001102232 #> 404  0.0047071042 0.004907937 0.045432451 #> 405  0.0004327347 0.005144710 0.001097383 #> 406  0.0662634956 0.906975654 0.084220598 #> 407  0.9999623042 0.998694145 0.973448717 #> 408  0.0123210795 0.997007486 0.985423965 #> 409  0.0489621839 0.005085220 0.003312715 #> 410  0.0042698768 0.005119673 0.003745379 #> 411  0.5159035835 0.779290860 0.338241381 #> 412  0.9764489546 0.999996106 0.280198004 #> 413  0.9997542653 0.999997614 0.958748708 #> 414  0.0027926544 0.933578886 0.984870646 #> 415  0.9998628908 0.997539125 0.978270055 #> 416  0.0033541528 0.015401558 0.001101818 #> 417  0.0006023343 0.725662493 0.775315539 #> 418  0.0004303498 0.028788321 0.001104094 #> 419  0.0004327347 0.005144710 0.001097383 #> 420  0.0004327544 0.005122497 0.001098261 #> 421  0.9996689147 0.978553306 0.998427287 #> 422  0.9998212828 0.999979120 0.968242919 #> 423  0.0042592583 0.015403818 0.003747708 #> 424  0.9386243465 0.022786675 0.138469287 #> 425  0.0003345340 0.996356418 0.016039338 #> 426  0.0004329750 0.004873095 0.001108118 #> 427  0.0004327347 0.005144710 0.001097383 #> 428  0.9366921219 0.999443538 0.021429239 #> 429  0.0004290927 0.055622921 0.004982000 #> 430  0.2228768357 0.655463861 0.017084318 #> 431  0.9795649037 0.999940059 0.999360535 #> 432  0.0004287530 0.057105138 0.004768322 #> 433  0.1143842538 0.005006691 0.003271034 #> 434  0.0034137912 0.005131033 0.018415111 #> 435  0.0031232391 0.347681456 0.014280474 #> 436  0.9999831514 0.999997258 0.998036615 #> 437  0.9979622805 0.999846697 0.978880334 #> 438  0.0003347501 0.957742968 0.001283720 #> 439  0.0081239378 0.761338322 0.632609786 #> 440  0.0011725718 0.979473004 0.015950745 #> 441  0.1131201062 0.055746454 0.003294893 #> 442  0.1493593439 0.955787435 0.994854129 #> 443  0.9998256012 0.999997708 0.998746918 #> 444  0.0014998142 0.043583331 0.001104309 #> 445  0.6719656256 0.998998015 0.293540095 #> 446  0.0144522304 0.015365877 0.003339222 #> 447  0.0004251962 0.078024342 0.001108460 #> 448  0.9914113788 0.044542513 0.069002172 #> 449  0.0037804742 0.078138075 0.018588817 #> 450  0.0024265366 0.072511261 0.001124457 #> 451  0.1452541833 0.005612306 0.986655648 #> 452  0.0003891872 0.426256250 0.001162002 #> 453  0.0004118512 0.207073790 0.001128273 #> 454  0.1016325133 0.055896623 0.003302279 #> 455  0.0004287568 0.043602023 0.001103228 #> 456  0.7760776931 0.811240888 0.027620049 #> 457  0.0004112874 0.248623413 0.011752786 #> 458  0.9998665977 0.999979386 0.974961645 #> 459  0.0606711257 0.167769668 0.826279656 #> 460  0.1943372027 0.743571925 0.006029341 #> 461  0.0004377785 0.028846510 0.020777174 #> 462  0.0015831537 0.152498734 0.001121040 #> 463  0.5529981197 0.224098262 0.031108580 #> 464  0.0759453689 0.947682347 0.939760144 #> 465  0.0144066622 0.028685187 0.003345839 #> 466  0.0003462250 0.897691106 0.020578316 #> 467  0.9249957407 0.998665791 0.389915579 #> 468  0.0071483013 0.989134172 0.099942426 #> 469  0.0038196990 0.043681513 0.020875407 #> 470  0.0368526080 0.077060519 0.001144878 #> 471  0.0449475157 0.138848396 0.003374664 #> 472  0.0003318553 0.980446526 0.001245896 #> 473  0.9996201926 0.998710595 0.999875071 #> 474  0.9832536060 0.949487015 0.003084913 #> 475  0.0038033495 0.004990999 0.004971833 #> 476  0.0004340275 0.027306955 0.010493629 #> 477  0.0049715865 0.005139155 0.001101790 #> 478  0.0104288977 0.997932590 0.340525164 #> 479  0.9999847386 0.999961934 0.999152675 #> 480  0.9945292456 0.999967321 0.998304972 #> 481  0.0037982641 0.443368997 0.140185519 #> 482  0.9165992599 0.904521754 0.149190632 #> 483  0.6339573609 0.993575390 0.041657466 #> 484  0.0813807132 0.999930456 0.994595007 #> 485  0.1071492880 0.576385945 0.014869003 #> 486  0.0004402481 0.005158627 0.020707401 #> 487  0.0004225364 0.139082664 0.011127251 #> 488  0.1792279297 0.956952453 0.996073181 #> 489  0.9858411596 0.999907961 0.978411917 #> 490  0.0453062318 0.032548737 0.381583548 #> 491  0.0049340909 0.005186146 0.067427656 #> 492  0.0049099996 0.057144255 0.001109664 #> 493  0.6266145540 0.882802875 0.035687897 #> 494  0.9899096794 0.991463088 0.999035070 #> 495  0.0007778123 0.015147143 0.020741610 #> 496  0.0031573141 0.744557585 0.014627982 #> 497  0.0037238954 0.077665059 0.001112447 #> 498  0.0004341389 0.005135443 0.004735277 #> 499  0.0004393464 0.005156957 0.018353890 #> 500  0.9827344250 0.999228254 0.002573633 #> 501  0.0004745134 0.028873269 0.117478614 #> 502  0.9216800042 0.324397747 0.249432256 #> 503  0.8298580941 0.003978400 0.002836752 #> 504  0.0141999538 0.043806120 0.060801778 #> 505  0.9986217687 0.999549759 0.976400652 #> 506  0.8277290738 0.999987986 0.959721272 #> 507  0.0004644705 0.005190007 0.083893941 #> 508  0.0087478461 0.016032312 0.001107263 #> 509  0.9949125975 0.993817062 0.078209109 #> 510  0.0067158619 0.998769356 0.016184996 #> 511  0.0004327347 0.005144710 0.001097383 #> 512  0.0042310799 0.043388602 0.003764841 #> 513  0.0049715865 0.005139155 0.001101790 #> 514  0.0004273894 0.056976605 0.001106083 #> 515  0.0004163689 0.199122190 0.011469241 #> 516  0.0042773100 0.122523054 0.016318131 #> 517  0.0015132294 0.015421338 0.001100088 #> 518  0.9991281403 0.684909040 0.998946700 #> 519  0.5920059379 0.999898789 0.002149547 #> 520  0.0524708747 0.994743560 0.080774140 #> 521  0.0042696555 0.005141882 0.003742391 #> 522  0.0003927312 0.429419139 0.012790693 #> 523  0.2198090054 0.350537209 0.312005107 #> 524  0.7560368077 0.999928841 0.818936934 #> 525  0.0004353682 0.043510564 0.018464326 #> 526  0.5119515022 0.074271021 0.003046478 #> 527  0.9991692238 0.189581028 0.950925105 #> 528  0.0004316668 0.015700698 0.001100230 #> 529  0.0004317259 0.078196435 0.018535923 #> 530  0.0004327347 0.005144710 0.001097383 #> 531  0.1155470185 0.990313826 0.802717621 #> 532  0.0003348674 0.993127210 0.016022302 #> 533  0.0004368803 0.028837387 0.018415882 #> 534  0.0004339940 0.027428861 0.010485774 #> 535  0.0296868086 0.027673867 0.044913124 #> 536  0.0016688876 0.005175185 0.075134796 #> 537  0.9390624637 0.099309165 0.223485419 #> 538  0.9941589677 0.999838998 0.243839236 #> 539  0.0063678688 0.941384685 0.015804171 #> 540  0.9659285502 0.996036547 0.014666398 #> 541  0.9999088553 0.988091558 0.996736131 #> 542  0.3494164480 0.004639611 0.013227557 #> 543  0.9494940439 0.999996119 0.987956304 #> 544  0.0067586418 0.998745463 0.017810542 #> 545  0.9810503205 0.998526553 0.014463118 #> 546  0.9969155432 0.467715561 0.168782454 #> 547  0.0004251962 0.078024342 0.001108460 #> 548  0.9683965937 0.965752673 0.981298284 #> 549  0.0049436773 0.028740158 0.001105545 #> 550  0.9880900260 0.999997401 0.998288352 #> 551  0.0143496433 0.005165049 0.053870772 #> 552  0.0143321025 0.005147279 0.060543438 #> 553  0.0478671834 0.057003442 0.060537935 #> 554  0.9996450816 0.999081018 0.708269107 #> 555  0.9999834858 0.999514947 0.846589210 #> 556  0.0004341389 0.005135443 0.004735277 #> 557  0.0491304194 0.988047214 0.005698863 #> 558  0.0049743345 0.004867823 0.001112572 #> 559  0.0038166474 0.980425696 0.001249732 #> 560  0.8006160490 0.374937713 0.016467964 #> 561  0.9920831771 0.965810098 0.016321922 #> 562  0.0074732598 0.817806761 0.983894835 #> 563  0.0021300908 0.004907146 0.005104033 #> 564  0.6139061617 0.992459913 0.427316053 #> 565  0.0004287568 0.043602023 0.001103228 #> 566  0.0122928946 0.005096130 0.001110370 #> 567  0.1022620424 0.028094202 0.003289763 #> 568  0.3385043092 0.026543958 0.013162186 #> 569  0.0015132294 0.015421338 0.001100088 #> 570  0.9970314910 0.998652307 0.999043682 #> 571  0.0144873023 0.005129086 0.003334373 #> 572  0.0004762305 0.148410555 0.160726998 #> 573  0.9991335506 0.994234288 0.995783692 #> 574  0.0004639563 0.003807962 0.079147675 #> 575  0.0005307887 0.029791295 0.265307103 #> 576  0.0015138725 0.005142416 0.001098472 #> 577  0.9876294875 0.909180758 0.997105096 #> 578  0.2005940353 0.998776712 0.074560243 #> 579  0.9856708591 0.995609564 0.003092255 #> 580  0.7009349505 0.241685943 0.999636985 #> 581  0.9723020085 0.986045695 0.996267453 #> 582  0.0107271061 0.990307499 0.932600270 #> 583  0.0033748669 0.004991508 0.004969965 #> 584  0.0036724336 0.495306527 0.013210616 #> 585  0.9998256476 0.999962520 0.999900055 #> 586  0.0028014709 0.015230430 0.001102621 #> 587  0.9986242913 0.999547938 0.998743555 #> 588  0.9999829274 0.999997211 0.978631951 #> 589  0.0209624170 0.304120524 0.001167562 #> 590  0.1249430938 0.075947340 0.012036476 #> 591  0.2778286433 0.014411963 0.006253166 #> 592  0.9998698191 0.999968209 0.999897962 #> 593  0.9999787585 0.999996649 0.222866110 #> 594  0.9828140615 0.999967787 0.003488667 #> 595  0.9973832592 0.991376486 0.786886696 #> 596  0.9858272267 0.964588216 0.276029279 #> 597  0.0044034584 0.497495405 0.005066022 #> 598  0.0047009583 0.005148892 0.045062480 #> 599  0.0158503953 0.126689741 0.070046444 #> 600  0.0034207822 0.005132684 0.020776306 #> 601  0.8590645082 0.023308049 0.135086322 #> 602  0.9999608735 0.999143931 0.778082185 #> 603  0.0024901575 0.040322887 0.001120375 #> 604  0.0133097652 0.426478686 0.004046858 #> 605  0.0131460642 0.005128018 0.001109783 #> 606  0.0004304670 0.042380901 0.004975501 #> 607  0.0004363650 0.035474013 0.014682033 #> 608  0.9970535353 0.999997218 0.978677135 #> 609  0.0003994986 0.326494652 0.001146436 #> 610  0.0049715865 0.005139155 0.001101790 #> 611  0.0004339940 0.027428861 0.010485774 #> 612  0.0164857417 0.691829560 0.001219519 #> 613  0.0032773076 0.436604273 0.001169255 #> 614  0.0037392273 0.075792200 0.005013598 #> 615  0.0005064472 0.630681826 0.432693304 #> 616  0.9291413228 0.999083341 0.002563630 #> 617  0.0037892787 0.005140602 0.001100642 #> 618  0.0004393464 0.005156957 0.018353890 #> 619  0.9200279674 0.004043178 0.044980522 #> 620  0.0121944512 0.108704653 0.735212472 #> 621  0.0033043343 0.077672379 0.001112037 #> 622  0.3756464310 0.491736002 0.413825072 #> 623  0.5163541484 0.274703545 0.125612699 #> 624  0.0064887514 0.975175622 0.001256079 #> 625  0.1849221433 0.094666230 0.001298760 #> 626  0.0015487387 0.028839845 0.020799184 #> 627  0.0003995376 0.326634959 0.001149544 #> 628  0.0463734024 0.077248661 0.004167827 #> 629  0.0004391736 0.015453547 0.020736913 #> 630  0.0009385079 0.044363867 0.001103922 #> 631  0.0047004052 0.005170578 0.045029182 #> 632  0.0144873023 0.005129086 0.003334373 #> 633  0.3238127071 0.004794082 0.075631364 #> 634  0.9998235410 0.999664588 0.998298645 #> 635  0.9947756039 0.999392845 0.999838395 #> 636  0.0005581811 0.990101888 0.776858181 #> 637  0.0007640737 0.015104901 0.001099232 #> 638  0.9999847662 0.999997679 0.999899895 #> 639  0.7812333361 0.996856434 0.140775113 #> 640  0.6978913613 0.950133019 0.003279490 #> 641  0.0004339940 0.027428861 0.010485774 #> 642  0.9158514871 0.994899149 0.786925113 #> 643  0.0004327347 0.005144710 0.001097383 #> 644  0.0045694988 0.027761422 0.034963998 #> 645  0.0049718229 0.005115813 0.001102718 #> 646  0.0041519905 0.121206050 0.003801436 #> 647  0.0785895572 0.980162138 0.020055754 #> 648  0.9965676168 0.996069541 0.988442938 #> 649  0.9995813147 0.998538276 0.811806427 #> 650  0.0143106414 0.056812471 0.003360819 #> 651  0.9935051090 0.837227822 0.998316846 #> 652  0.0004382734 0.015448584 0.018380111 #> 653  0.0004327347 0.005144710 0.001097383 #> 654  0.0179715303 0.160487260 0.001139569 #> 655  0.0106853802 0.123311526 0.001126121 #> 656  0.8726438951 0.998488486 0.039889310 #> 657  0.0004335165 0.043674323 0.013673879 #> 658  0.0378286714 0.028603699 0.019050416 #> 659  0.0178334923 0.057071358 0.069705108 #> 660  0.0125387954 0.346818061 0.319564316 #> 661  0.0004350670 0.028818967 0.013648505 #> 662  0.0004327347 0.005144710 0.001097383 #> 663  0.0004327347 0.005144710 0.001097383 #> 664  0.3673427713 0.974966035 0.001650120 #> 665  0.0037892787 0.005140602 0.001100642 #> 666  0.9918277003 0.004006937 0.176167372 #> 667  0.5592582317 0.485474473 0.009563835 #> 668  0.0003890696 0.427284192 0.001161545 #> 669  0.0029395189 0.946277168 0.001247600 #> 670  0.0004327347 0.005144710 0.001097383 #> 671  0.0004316733 0.015412189 0.001098978 #> 672  0.0793153606 0.809306879 0.914599545 #> 673  0.9539395123 0.999429088 0.152684347 #> 674  0.0004375508 0.005130142 0.013613643 #> 675  0.0004327554 0.005121344 0.001098307 #> 676  0.0143315913 0.005169765 0.060497920 #> 677  0.9968339908 0.999215135 0.997941627 #> 678  0.1548844201 0.032938798 0.001254480 #> 679  0.0126975839 0.015868864 0.013793390 #> 680  0.0004339028 0.057331819 0.018483923 #> 681  0.8316407502 0.556674750 0.012257369 #> 682  0.9984917004 0.999997200 0.998035966 #> 683  0.0004587574 0.029069441 0.075840965 #> 684  0.9969989711 0.989232854 0.998704046 #> 685  0.0033574477 0.057258218 0.013733684 #> 686  0.6448341541 0.089753843 0.009754314 #> 687  0.4762999705 0.587195898 0.031723557 #> 688  0.0141016926 0.078005382 0.054422605 #> 689  0.5011067262 0.004528567 0.012972442 #> 690  0.0004316733 0.015412189 0.001098978 #> 691  0.0003502275 0.843510437 0.015165058 #> 692  0.0058859516 0.005262964 0.210549742 #> 693  0.8868612046 0.509061431 0.994889868 #> 694  0.0458326879 0.005254939 0.271122110 #> 695  0.9870904144 0.032273180 0.998511717 #> 696  0.0004348461 0.057101961 0.020869618 #> 697  0.0025020628 0.004754636 0.001114887 #> 698  0.0033864327 0.519078471 0.022250442 #> 699  0.9967541971 0.463034336 0.017818710 #> 700  0.8288983822 0.021438924 0.026637931 #> 701  0.1553077300 0.994165565 0.999458489 #> 702  0.0004375259 0.005153585 0.013602339 #> 703  0.9960265661 0.544471252 0.994806159 #> 704  0.0042169008 0.057172996 0.003768749 #> 705  0.9364560030 0.998321162 0.702494657 #> 706  0.0037437433 0.899398854 0.050906445 #> 707  0.0033623759 0.005141124 0.001100228 #> 708  0.0005126778 0.005292786 0.209750814 #> 709  0.9996205297 0.999997644 0.976384188 #> 710  0.0015983657 0.027251790 0.010507381 #> 711  0.9627142281 0.999590885 0.981609737 #> 712  0.0003830843 0.497767414 0.005048513 #> 713  0.9105244949 0.999892148 0.622066071 #> 714  0.0004375259 0.005153585 0.013602339 #> 715  0.9989565685 0.999961577 0.998744085 #> 716  0.0067935995 0.999418012 0.023105761 #> 717  0.9792237402 0.999264419 0.776353251 #> 718  0.0223368415 0.224826803 0.014308996 #> 719  0.0004327347 0.005144710 0.001097383 #> 720  0.0007338873 0.356187862 0.959288105 #> 721  0.0066571709 0.989247150 0.016085962 #> 722  0.9941239165 0.999576102 0.267892871 #> 723  0.1188552536 0.016018857 0.777910466 #> 724  0.0007640737 0.015104901 0.001099232 #> 725  0.0004320986 0.057296296 0.013699178 #> 726  0.0006227163 0.058204317 0.517188365 #> 727  0.0007664296 0.015078296 0.004743039 #> 728  0.9999847070 0.999665039 0.998744647 #> 729  0.0004327544 0.005122497 0.001098261 #> 730  0.0005051419 0.005278827 0.190081894 #> 731  0.0004327347 0.005144710 0.001097383 #> 732  0.0113338003 0.899007098 0.045715321 #> 733  0.0142834919 0.029073720 0.055461248 #> 734  0.0004335165 0.043674323 0.013673879 #> 735  0.0004118512 0.207073790 0.001128273 #> 736  0.0374790605 0.005077345 0.001134261 #> 737  0.0004302944 0.028770488 0.001101155 #> 738  0.0006254717 0.005479633 0.504070513 #> 739  0.0427546180 0.005084968 0.021471309 #> 740  0.9999845143 0.999961326 0.968246942 #> 741  0.6532100515 0.534472503 0.010527765 #> 742  0.3940453605 0.976070290 0.119864124 #> 743  0.9968088635 0.999997595 0.992170359 #> 744  0.0034052843 0.015437837 0.018426781 #> 745  0.9562819728 0.004493729 0.985662224 #> 746  0.9997602014 0.991298364 0.999868040 #> 747  0.7037049637 0.999907606 0.044604292 #> 748  0.0483161139 0.958186797 0.016995894 #> 749  0.0017285770 0.029756690 0.169548968 #> 750  0.0004343541 0.004990252 0.004964656 #> 751  0.1220335771 0.004948288 0.004836557 #> 752  0.0033623759 0.005141124 0.001100228 #> 753  0.9970768024 0.999925008 0.997698873 #> 754  0.0287897300 0.005087935 0.001125817 #> 755  0.0037728679 0.028928259 0.001134218 #> 756  0.0018659522 0.199929525 0.001129337 #> 757  0.9893274297 0.127953902 0.251200797 #> 758  0.9998477366 0.999956344 0.708718195 #> 759  0.0144946804 0.004869759 0.003365527 #> 760  0.0004302944 0.028770488 0.001101155 #> 761  0.0004197648 0.328270063 0.059290890 #> 762  0.0037239098 0.077654494 0.001112474 #> 763  0.0003615571 0.750792103 0.020217170 #> 764  0.9960029356 0.872727436 0.901552556 #> 765  0.1419065716 0.982699135 0.013269875 #> 766  0.0004327347 0.005144710 0.001097383 #> 767  0.9984703465 0.999972802 0.999899987 #> 768  0.0049715865 0.005139155 0.001101790 #> 769  0.0168994433 0.077719162 0.001124596 #> 770  0.0004327347 0.005144710 0.001097383 #> 771  0.0038072704 0.057305593 0.020913498 #> 772  0.0045138898 0.429155114 0.012833490 #> 773  0.0089373814 0.996605582 0.134086592 #> 774  0.0051886582 0.401936119 0.749729491 #> 775  0.9966137539 0.998145012 0.983905368 #> 776  0.1450494522 0.004969120 0.003251591 #> 777  0.9984849757 0.999710601 0.998717940 #> 778  0.0004551125 0.005008912 0.059066813 #> 779  0.0049715865 0.005139155 0.001101790 #> 780  0.9826190123 0.959286060 0.451102752 #> 781  0.0015181985 0.027416950 0.010495924 #> 782  0.9984551089 0.999979180 0.999152029 #> 783  0.0004303498 0.028788321 0.001104094 #> 784  0.0004402481 0.005158627 0.020707401 #> 785  0.9999847464 0.999961979 0.998076686 #> 786  0.0320482848 0.043299937 0.004017284 #> 787  0.0363083607 0.005081497 0.004038642 #> 788  0.0004022745 0.904995384 0.211090732 #> 789  0.9969838978 0.023171206 0.140622415 #> 790  0.9956614993 0.999979930 0.996440363 #> 791  0.0037668839 0.508193473 0.019671149 #> 792  0.0042696555 0.005141882 0.003742391 #> 793  0.9977120058 0.004041311 0.247287601 #> 794  0.0004251962 0.078024342 0.001108460 #> 795  0.9489530909 0.999937329 0.222928383 #> 796  0.1469653663 0.861162999 0.995851503 #> 797  0.0049260906 0.043556759 0.001107607 #> 798  0.0004326742 0.077889837 0.020927675 #> 799  0.0004327544 0.005122497 0.001098261 #> 800  0.0091702374 0.944759284 0.999011771 #> 801  0.0003370790 0.993624198 0.023562265 #> 802  0.0003383832 0.958859754 0.015824486 #> 803  0.0136113062 0.263720659 0.031417321 #> 804  0.0003905895 0.414000186 0.001167457 #> 805  0.1739061997 0.989371439 0.023920261 #> 806  0.0037799590 0.015688298 0.001103487 #> 807  0.9672087026 0.999425707 0.998270773 #> 808  0.0004393464 0.005156957 0.018353890 #> 809  0.0004252433 0.077722607 0.001109225 #> 810  0.1325959455 0.005338538 0.516587813 #> 811  0.0066894600 0.987469228 0.023595838 #> 812  0.3204543071 0.039742736 0.003165451 #> 813  0.0050471958 0.005151340 0.018426320 #> 814  0.0004351323 0.028836112 0.013682721 #> 815  0.0034135957 0.005153331 0.018400642 #> 816  0.0004329822 0.004864971 0.001108440 #> 817  0.0004539188 0.005171025 0.056356158 #> 818  0.9745517459 0.999427502 0.987956835 #> 819  0.0005683546 0.032536926 0.365476657 #> 820  0.0041957998 0.077984594 0.003779291 #> 821  0.0004287568 0.043602023 0.001103228 #> 822  0.0037961009 0.043640588 0.013713506 #> 823  0.0004327347 0.005144710 0.001097383 #> 824  0.9992545789 0.999696713 0.826287232 #> 825  0.0004327554 0.005121344 0.001098307 #> 826  0.0274576774 0.202823891 0.001154378 #> 827  0.9813707788 0.999997236 0.989442995 #> 828  0.0003972200 0.348488287 0.001149568 #> 829  0.0016978752 0.258035629 0.001141943 #> 830  0.9996319135 0.999940678 0.999878008 #> 831  0.9998799870 0.999979264 0.979058848 #> 832  0.9968188361 0.986726498 0.702185383 #> 833  0.0004327537 0.005123248 0.001098231 #> 834  0.9965957958 0.999476964 0.949737531 #> 835  0.0021958834 0.298903448 0.012181974 #> 836  0.0049876456 0.005129887 0.004754226 #> 837  0.9998801662 0.999759027 0.968292241 #> 838  0.9998531985 0.999955645 0.999897960 #> 839  0.9994147295 0.999925806 0.844567712 #> 840  0.0004291339 0.201648132 0.047795201 #> 841  0.0122438100 0.045212451 0.786911102 #> 842  0.9986217013 0.999997643 0.968277117 #> 843  0.0049594476 0.015395719 0.001103378 #> 844  0.1095383065 0.199525181 0.003362803 #> 845  0.9998639652 0.999997633 0.968243923 #> 846  0.1476634506 0.014924337 0.005063114 #> 847  0.9973702048 0.999896103 0.998718456 #> 848  0.0004341389 0.005135443 0.004735277 #> 849  0.0042457542 0.028755056 0.003754969 #> 850  0.9996209128 0.999961504 0.979060754 #> 851  0.0144873023 0.005129086 0.003334373 #> 852  0.0032783555 0.155296014 0.013916348 #> 853  0.9999845328 0.999592490 0.976380778 #> 854  0.0033623759 0.005141124 0.001100228 #> 855  0.0004327347 0.005144710 0.001097383 #> 856  0.0288950872 0.025839593 0.010837102 #> 857  0.0363066011 0.005102798 0.004035515 #> 858  0.0356984442 0.077434922 0.004069490 #> 859  0.0608252533 0.976401008 0.004849471 #> 860  0.0004316733 0.015412189 0.001098978 #> 861  0.0556848524 0.999441606 0.001447692 #> 862  0.0116412426 0.896965909 0.999516628 #> 863  0.1416429012 0.991474584 0.965771117 #> 864  0.1090524501 0.196530691 0.033469824 #> 865  0.0049876456 0.005129887 0.004754226 #> 866  0.0323367553 0.005086323 0.004002275 #> 867  0.0003453385 0.850551795 0.001229492 #> 868  0.0036724336 0.495306527 0.013210616 #> 869  0.9992685070 0.966409483 0.018984546 #> 870  0.0004327347 0.005144710 0.001097383 #> 871  0.0032726643 0.995017912 0.004389703 #> 872  0.0004393464 0.005156957 0.018353890 #> 873  0.0067024586 0.996505370 0.016182293 #> 874  0.0133716850 0.005141732 0.020936745 #> 875  0.0047331783 0.206995125 0.001135443 #> 876  0.9963549181 0.988169191 0.999034075 #> 877  0.9998109876 0.991963068 0.998290267 #> 878  0.0004245786 0.084091567 0.001110012 #> 879  0.0050471958 0.005151340 0.018426320 #> 880  0.7951122711 0.985789966 0.645656713 #> 881  0.0004339940 0.027428861 0.010485774 #> 882  0.0035722998 0.692976506 0.004091790 #> 883  0.6568997568 0.999321761 0.999782654 #> 884  0.0041501916 0.123298459 0.003807948 #> 885  0.9995622549 0.982572319 0.988381095 #> 886  0.0119842861 0.040223555 0.886319360 #> 887  0.0003973349 0.347501435 0.001150100 #> 888  0.8583010979 0.758777804 0.728504045 #> 889  0.0033642930 0.004861574 0.001111315 #> 890  0.0004327347 0.005144710 0.001097383 #> 891  0.0004762305 0.148410555 0.160726998 #> 892  0.0004341389 0.005135443 0.004735277 #> 893  0.5450609932 0.004469636 0.001627000 #> 894  0.0004369540 0.028855479 0.018464176 #> 895  0.0004207247 0.121264832 0.001115106 #> 896  0.0004327347 0.005144710 0.001097383 #> 897  0.0075507642 0.989849850 0.170274881 #> 898  0.6792114002 0.999862473 0.197616815 #> 899  0.0007778123 0.015147143 0.020741610 #> 900  0.9970831528 0.999997622 0.998743354 #> 901  0.9739031096 0.995039593 0.999026578 #> 902  0.0116430175 0.849768395 0.004084435 #> 903  0.0144950094 0.004858198 0.003366915 #> 904  0.0015138725 0.005142416 0.001098472 #> 905  0.0287884598 0.005110004 0.001124915 #> 906  0.0004327544 0.005122497 0.001098261 #> 907  0.0361098627 0.028541636 0.004047190 #> 908  0.3093850546 0.004794307 0.050985001 #> 909  0.9998661374 0.999972738 0.999899887 #> 910  0.0004327347 0.005144710 0.001097383 #> 911  0.0037892787 0.005140602 0.001100642 #> 912  0.0004287568 0.043602023 0.001103228 #> 913  0.0037239098 0.077654494 0.001112474 #> 914  0.0004265985 0.077894075 0.004781540 #> 915  0.7178330165 0.993358162 0.134269275 #> 916  0.9578653934 0.455594292 0.020249223 #> 917  0.6036119485 0.004401401 0.009231504 #> 918  0.0003531781 0.815308550 0.015046135 #> 919  0.0004327347 0.005144710 0.001097383 #> 920  0.0007122702 0.393497934 0.921454765 #> 921  0.0004216462 0.158102016 0.013909521 #> 922  0.0004252449 0.077712035 0.001109252 #> 923  0.3943092128 0.962894580 0.768561650 #> 924  0.3281333747 0.793389897 0.984048300 #> 925  0.9998082945 0.999952662 0.998268625 #> 926  0.0004273500 0.057202795 0.001105295 #> 927  0.0038002683 0.027407611 0.010516239 #> 928  0.0334925634 0.610914502 0.023813901 #> 929  0.8594842624 0.894348622 0.482696837 #> 930  0.9981039125 0.999753674 0.958665978 #> 931  0.0004327347 0.005144710 0.001097383 #> 932  0.9984529101 0.999794020 0.998693668 #> 933  0.6907711381 0.976295309 0.140140254 #> 934  0.9667629293 0.999632537 0.967192427 #> 935  0.0168631672 0.900654223 0.015799542 #> 936  0.0033732545 0.005131857 0.004747508 #> 937  0.6430811278 0.034093470 0.883848563 #> 938  0.9999816330 0.990992461 0.999897376 #> 939  0.0066166481 0.975246021 0.023634865 #> 940  0.0048090356 0.740342234 0.201040885 #> 941  0.0032478130 0.431723782 0.001165548 #> 942  0.0485241322 0.224457140 0.001182110 #> 943  0.0144873023 0.005129086 0.003334373 #> 944  0.1186680042 0.055630929 0.001220721 #> 945  0.9526055955 0.998991939 0.039197683 #> 946  0.0015138725 0.005142416 0.001098472 #> 947  0.9595372914 0.997791658 0.841899479 #> 948  0.0004402481 0.005158627 0.020707401 #> 949  0.0074377199 0.031820001 0.312612171 #> 950  0.0007642261 0.014656150 0.004970836 #> 951  0.0016168690 0.124551946 0.001119356 #> 952  0.1450764109 0.887939685 0.975829643 #> 953  0.6264597048 0.004386165 0.014708744 #> 954  0.0004568616 0.043920520 0.075267056 #> 955  0.0011459567 0.077189943 0.010779633 #> 956  0.0015037859 0.078116621 0.013751028 #> 957  0.0004251962 0.078024342 0.001108460 #> 958  0.9999848238 0.999560661 0.998301483 #> 959  0.9999847525 0.999962002 0.998299087 #> 960  0.0004327347 0.005144710 0.001097383 #> 961  0.9984247232 0.999975604 0.708248727 #> 962  0.0048859029 0.077644787 0.001113582 #> 963  0.0031222715 0.348721546 0.014273611 #> 964  0.0005126778 0.005292786 0.209750814 #> 965  0.4757448931 0.004950783 0.673412048 #> 966  0.0003501577 0.844114011 0.015163782 #> 967  0.0034135957 0.005153331 0.018400642 #> 968  0.9962931847 0.982701908 0.810736583 #> 969  0.0489621839 0.005085220 0.003312715 #> 970  0.9870899066 0.987915765 0.038282510 #> 971  0.0004316733 0.015412189 0.001098978 #> 972  0.9965717798 0.888649852 0.998674400 #> 973  0.0037668839 0.508193473 0.019671149 #> 974  0.0038312971 0.005127175 0.013653008 #> 975  0.0004339940 0.027428861 0.010485774 #> 976  0.0004172187 0.155160763 0.001120270 #> 977  0.9996940276 0.999955174 0.999358660 #> 978  0.0345376072 0.027592923 0.037260476 #> 979  0.0029270736 0.587232711 0.013761498 #> 980  0.1025720045 0.016987174 0.028433014 #> 981  0.0004878402 0.029524625 0.152793782 #> 982  0.9997315137 0.999997537 0.868271083 #> 983  0.0004941279 0.029769351 0.169411347 #> 984  0.7200445096 0.993646558 0.002095834 #> 985  0.0004273500 0.057202795 0.001105295 #> 986  0.3766531646 0.058768893 0.001477341 #> 987  0.9955972965 0.999292237 0.019035538 #> 988  0.9982827259 0.999592649 0.998260883 #> 989  0.0004340259 0.027312970 0.010493241 #> 990  0.0004941999 0.029646088 0.169509173 #> 991  0.9477843837 0.004449092 0.845160067 #> 992  0.0033721315 0.027410314 0.010512365 #> 993  0.9704209377 0.985249903 0.867765897 #> 994  0.5224961248 0.035140109 0.860246671 #> 995  0.0007636981 0.015036983 0.001100143 #> 996  0.0003501577 0.844114011 0.015163782 #> 997  0.9300840681 0.004032508 0.067307630 #> 998  0.0004327554 0.005121344 0.001098307 #> 999  0.5265446824 0.280893479 0.087531899 #> 1000 0.0014163555 0.425603427 0.001163308"},{"path":"/reference/tdcm.summary.html","id":null,"dir":"Reference","previous_headings":"","what":"TDCM results compiler and summarizer. — tdcm.summary","title":"TDCM results compiler and summarizer. — tdcm.summary","text":"Function summarize results TDCM analyses.","code":""},{"path":"/reference/tdcm.summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"TDCM results compiler and summarizer. — tdcm.summary","text":"","code":"tdcm.summary(   model,   time.points,   transition.option = 1,   classthreshold = 0.5,   attribute.names = c() )"},{"path":"/reference/tdcm.summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"TDCM results compiler and summarizer. — tdcm.summary","text":"model gdina object returned tdcm function. time.points number time points (.e., measurement/testing occasions), integer \\(\\ge 2\\). transition.option option reporting results. = 1 compares first time point last. = 2 compares first time point every time point. = 3 compares successive time points. Default = 1. classthreshold probability threshold establishing proficiency examinee posterior probabilities. Default .50, maximizes overall classification accuracy. can set lower value minimize false negatives (.e., misclassifying proficient examinees non-proficient) set higher value minimize false positives (.e., misclassifying non-proficient examinees proficient). attribute.names optional vector attribute names include results output.","code":""},{"path":"/reference/tdcm.summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"TDCM results compiler and summarizer. — tdcm.summary","text":"list following items: $item.parameters: LCDM item parameter estimates specified DCM. $growth: proficiency proportions time point attribute $transition.probabilities: conditional attribute proficiency transition probability matrices $posterior.probabilities: examinee marginal attribute posterior probabilities proficiency $transition.posteriors: examinee marginal attribute transition posterior probabilities $.likely.transitions: examinee likely transitions attribute transition $classifications: examinee classifications determined specified threshold applied posterior probabilities $reliability: estimated transition reliability metrics attribute specified transitions. “pt bis” = longitudinal point biserial metric; “info gain” = longitudinal information gain metric; “polychor” = longitudinal tetrachoric metric; “ave max tr” = average maximum transition posterior metric; “P(t>k)” = proportion examinee marginal attribute transition posteriors greater k; “wt pt bis” = weighted longitudinal point biserial; “wt info gain” = weighted longitudinal information gain. $att.corr: estimated attribute correlation matrix $model.fit: Several model fit indices tests output including item root mean square error approximation (RMSEA; von Davier, 2005), mean RMSEA, bivariate item fit statistics (Chen et al., 2013), absolute fit statistics mean absolute deviation observed expected item correlations (MADcor; DiBello, Roussons, & Stout, 2007), standardized root mean square root squared residuals (SRMSR; Maydeu-Olivares, 2013)","code":""},{"path":"/reference/tdcm.summary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"TDCM results compiler and summarizer. — tdcm.summary","text":"Provides summary TDCM results including item parameters, attribute posterior probabilities, transition posterior probabilities, classifications, growth, transition probabilities, attribute correlations, several transition reliability metrics, model fit. Includes longitudinal DCM reliability metrics developed Schellman Madison (2021).","code":""},{"path":"/reference/tdcm.summary.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"TDCM results compiler and summarizer. — tdcm.summary","text":"Chen, J., de la Torre, J. ,& Zhang, Z. (2013). Relative absolute fit evaluation cognitive diagnosis modeling. Journal Educational Measurement, 50, 123-140. DiBello, L. V., Roussos, L. ., & Stout, W. F. (2007). Review cognitively diagnostic assessment summary psychometric models. C. R. Rao S. Sinharay (Eds.), Handbook Statistics, Vol. 26 (pp.979–1030). Amsterdam: Elsevier. Johnson, M. S., & Sinharay, S. (2020). reliability posterior probability skill attainment diagnostic classification models. Journal Educational Measurement, 47(1), 5 – 31. Madison, M. J. (2019). Reliably assessing growth longitudinal diagnostic classification models. Educational Measurement: Issues Practice, 38(2), 68-78. Maydeu-Olivares, . (2013). Goodness--fit assessment item response theory models (discussion). Measurement: Interdisciplinary Research Perspectives, 11, 71-137. Schellman, M., & Madison, M. J. (2021, July). Estimating reliability skill transition longitudinal DCMs. Paper presented 2021 International Meeting Psychometric Society. Templin, J., & Bradshaw, L. (2013). Measuring reliability diagnostic classification model examinee estimates. Journal Classification, 30, 251-275. von Davier M. (2008). general diagnostic model applied language testing data. British journal mathematical statistical psychology, 61(2), 287–307.","code":""},{"path":"/reference/tdcm.summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"TDCM results compiler and summarizer. — tdcm.summary","text":"","code":"## Example 1: T = 2, A = 4 data(data.tdcm01, package = \"TDCM\") dat1 <- data.tdcm01$data qmat1 <- data.tdcm01$qmatrix  # estimate TDCM with invariance assumed and full LCDM m1 <- TDCM::tdcm(dat1, qmat1, time.points = 2, invariance = TRUE, dcmrule = \"GDINA\")  # summarize results with tdcm.summary function results1 <- TDCM::tdcm.summary(m1, time.points = 2) results1$item.parameters #>         λ0     λ1,1  λ1,2  λ1,3  λ1,4  λ2,12 λ2,13 λ2,14 λ2,23 λ2,24 #> Item 1  -1.923 2.616   --    --    --    --    --    --    --    --  #> Item 2  -2.071 2.506   --    --    --    --    --    --    --    --  #> Item 3  -1.936 2.506   --    --    --    --    --    --    --    --  #> Item 4  -1.891 1.051 1.471   --    --  1.115   --    --    --    --  #> Item 5  -2.157 1.705   --  1.732   --    --  0.835   --    --    --  #> Item 6  -1.841   --  2.175   --    --    --    --    --    --    --  #> Item 7  -1.841   --  2.272   --    --    --    --    --    --    --  #> Item 8  -1.965   --  2.475   --    --    --    --    --    --    --  #> Item 9  -2.029   --  1.242 1.531   --    --    --    --  1.628   --  #> Item 10 -2.004   --  1.921   --  1.239   --    --    --    --  0.999 #> Item 11 -1.851   --    --  2.349   --    --    --    --    --    --  #> Item 12 -2.045   --    --  2.566   --    --    --    --    --    --  #> Item 13 -2.083   --    --  2.576   --    --    --    --    --    --  #> Item 14 -2.125   --    --  1.739 2.104   --    --    --    --    --  #> Item 15 -1.805 0.777   --  1.31    --    --  1.896   --    --    --  #> Item 16 -2.156   --    --    --  2.736   --    --    --    --    --  #> Item 17 -2.089   --    --    --  2.679   --    --    --    --    --  #> Item 18 -2.087   --    --    --  2.476   --    --    --    --    --  #> Item 19 -2.11  2.219   --    --  1.46    --    --  0.558   --    --  #> Item 20 -2.047   --  2.408   --  1.49    --    --    --    --  0.154 #>         λ2,34 #> Item 1    --  #> Item 2    --  #> Item 3    --  #> Item 4    --  #> Item 5    --  #> Item 6    --  #> Item 7    --  #> Item 8    --  #> Item 9    --  #> Item 10   --  #> Item 11   --  #> Item 12   --  #> Item 13   --  #> Item 14 0.493 #> Item 15   --  #> Item 16   --  #> Item 17   --  #> Item 18   --  #> Item 19   --  #> Item 20   --  results1$growth #>             T1[1] T2[1] #> Attribute 1 0.201 0.372 #> Attribute 2 0.327 0.492 #> Attribute 3 0.397 0.573 #> Attribute 4 0.252 0.696 results1$transition.probabilities #> , , Attribute 1: Time 1 to Time 2 #>  #>        T2 [0] T2 [1] #> T1 [0]  0.678  0.322 #> T1 [1]  0.432  0.568 #>  #> , , Attribute 2: Time 1 to Time 2 #>  #>        T2 [0] T2 [1] #> T1 [0]  0.578  0.422 #> T1 [1]  0.363  0.637 #>  #> , , Attribute 3: Time 1 to Time 2 #>  #>        T2 [0] T2 [1] #> T1 [0]   0.55   0.45 #> T1 [1]   0.24   0.76 #>  #> , , Attribute 4: Time 1 to Time 2 #>  #>        T2 [0] T2 [1] #> T1 [0]  0.365  0.635 #> T1 [1]  0.123  0.877 #>  results1$reliability #>             pt bis info gain polychor ave max tr P(t>.6) P(t>.7) P(t>.8) #> Attribute 1  0.788     0.511    0.925      0.922   0.964   0.929   0.856 #> Attribute 2  0.769     0.546    0.905      0.896   0.923   0.868   0.821 #> Attribute 3  0.728     0.527    0.905      0.878   0.918   0.856   0.750 #> Attribute 4  0.715     0.485    0.891      0.899   0.936   0.883   0.801 #>             P(t>.9) wt pt bis wt info gain #> Attribute 1   0.747     0.822        0.591 #> Attribute 2   0.694     0.792        0.581 #> Attribute 3   0.625     0.757        0.568 #> Attribute 4   0.709     0.772        0.585 head(results1$most.likely.transitions) #>   Attribute 1: T1 to T2 Attribute 2: T1 to T2 Attribute 3: T1 to T2 #> 1     01                    10                    01                #> 2     10                    00                    10                #> 3     00                    11                    01                #> 4     00                    01                    01                #> 5     00                    01                    01                #> 6     00                    10                    01                #>   Attribute 4: T1 to T2 #> 1     11                #> 2     11                #> 3     10                #> 4     01                #> 5     11                #> 6     01                results1$model.fit$Item.RMSEA #>    Item 1    Item 2    Item 3    Item 4    Item 5    Item 6    Item 7  #> 0.1072683 0.1273641 0.1082175 0.1191112 0.1255691 0.1401920 0.1357562  #>    Item 8    Item 9   Item 10   Item 11   Item 12   Item 13   Item 14  #> 0.1130181 0.1208428 0.1135816 0.1318266 0.1110083 0.1104637 0.1190979  #>   Item 15   Item 16   Item 17   Item 18   Item 19   Item 20   Item 21  #> 0.1274363 0.1244858 0.1133979 0.1235323 0.1142053 0.1400732 0.1122910  #>   Item 22   Item 23   Item 24   Item 25   Item 26   Item 27   Item 28  #> 0.1072758 0.1246946 0.1223008 0.1262111 0.1286012 0.1267738 0.1105200  #>   Item 29   Item 30   Item 31   Item 32   Item 33   Item 34   Item 35  #> 0.1164483 0.1158832 0.1303099 0.1289143 0.1225251 0.1096947 0.1357179  #>   Item 36   Item 37   Item 38   Item 39   Item 40  #> 0.1320643 0.1304714 0.1168578 0.1116256 0.1156059"},{"path":"/reference/tdcm_emit.html","id":null,"dir":"Reference","previous_headings":"","what":"Emit tdcm-related message — tdcm_emit","title":"Emit tdcm-related message — tdcm_emit","text":"tdcm_emit function used internally tdcm package ensure messages, warnings, errors emitted way can easily suppressed users package.","code":""},{"path":"/reference/tdcm_emit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Emit tdcm-related message — tdcm_emit","text":"","code":"tdcm_emit(text, label = \"INFO:\", func = base::message, ...)  tdcm_warn(text, ...)  tdcm_stop(text, ...)"},{"path":"/reference/tdcm_emit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Emit tdcm-related message — tdcm_emit","text":"text message text emit, object can coerced \"character\" via [base::.character()]. label label precedes message. default label \"INFO:\". func function use emit message. default func [base::message()].","code":""},{"path":"/reference/tdcm_emit.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Emit tdcm-related message — tdcm_emit","text":"tdcm_warn(): Emit tdcm-related warning message tdcm_stop(): Emit tdcm-related stop message","code":""},{"path":"/news/index.html","id":"tdcm-010","dir":"Changelog","previous_headings":"","what":"tdcm 0.1.0","title":"tdcm 0.1.0","text":"Initial CRAN submission.","code":""},{"path":"/news/index.html","id":"tdcm-0009000","dir":"Changelog","previous_headings":"","what":"tdcm 0.0.0.9000","title":"tdcm 0.0.0.9000","text":"tdcm R package project born!","code":""}]
